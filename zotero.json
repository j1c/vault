[
  {"id":"abbottUnderstandingAnalysis2015","abstract":"This lively introductory text exposes the student to the rewards of a rigorous study of functions of a real variable. In each chapter, informal discussions of questions that give analysis its inherent fascination are followed by precise, but not overly formal, developments of the techniques needed to make sense of them. By focusing on the unifying themes of approximation and the resolution of paradoxes that arise in the transition from the finite to the infinite, the text turns what could be a daunting cascade of definitions and theorems into a coherent and engaging progression of ideas. Acutely aware of the need for rigor, the student is much better prepared to understand what constitutes a proper mathematical proof and how to write one.Fifteen years of classroom experience with the first edition of Understanding Analysis have solidified and refined the central narrative of the second edition. Roughly 150 new exercises join a selection of the best exercises from the first edition, and three more project-style sections have been added. Investigations of Euler’s computation of ζ(2), the Weierstrass Approximation ­ Theorem, and the gamma function are now among the book’s cohort of seminal results serving as motivation and payoff for the beginning student to master the methods of analysis.","accessed":{"date-parts":[[2019,2,5]]},"author":[{"family":"Abbott","given":"Stephen"}],"citation-key":"abbottUnderstandingAnalysis2015","collection-title":"Undergraduate Texts in Mathematics","edition":"2","event-place":"New York","ISBN":"978-1-4939-2711-1","issued":{"date-parts":[[2015]]},"language":"en","publisher":"Springer-Verlag","publisher-place":"New York","source":"www.springer.com","title":"Understanding Analysis","type":"book","URL":"https://www.springer.com/us/book/9781493927111"},
  {"id":"abdiHolmSequentialBonferroni","author":[{"family":"Abdi","given":"Herve"}],"citation-key":"abdiHolmSequentialBonferroni","language":"en","page":"8","source":"Zotero","title":"Holm’s Sequential Bonferroni Procedure","type":"article-journal"},
  {"id":"achardEfficiencyCostEconomical2007","abstract":"Brain anatomical networks are sparse, complex, and have economical small-world properties. We investigated the efficiency and cost of human brain functional networks measured using functional magnetic resonance imaging (fMRI) in a factorial design: two groups of healthy old (N = 11; mean age = 66.5 years) and healthy young (N = 15; mean age = 24.7 years) volunteers were each scanned twice in a no-task or “resting” state following placebo or a single dose of a dopamine receptor antagonist (sulpiride 400 mg). Functional connectivity between 90 cortical and subcortical regions was estimated by wavelet correlation analysis, in the frequency interval 0.06–0.11 Hz, and thresholded to construct undirected graphs. These brain functional networks were small-world and economical in the sense of providing high global and local efficiency of parallel information processing for low connection cost. Efficiency was reduced disproportionately to cost in older people, and the detrimental effects of age on efficiency were localised to frontal and temporal cortical and subcortical regions. Dopamine antagonism also impaired global and local efficiency of the network, but this effect was differentially localised and did not interact with the effect of age. Brain functional networks have economical small-world properties—supporting efficient parallel information transfer at relatively low cost—which are differently impaired by normal aging and pharmacological blockade of dopamine transmission.","accessed":{"date-parts":[[2019,4,24]]},"author":[{"family":"Achard","given":"Sophie"},{"family":"Bullmore","given":"Ed"}],"citation-key":"achardEfficiencyCostEconomical2007","container-title":"PLOS Computational Biology","container-title-short":"PLOS Computational Biology","DOI":"10.1371/journal.pcbi.0030017","ISSN":"1553-7358","issue":"2","issued":{"date-parts":[[2007,2,2]]},"language":"en","page":"e17","source":"PLoS Journals","title":"Efficiency and Cost of Economical Brain Functional Networks","type":"article-journal","URL":"https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.0030017","volume":"3"},
  {"id":"alexanderDiffusionTensorImaging2007","abstract":"Diffusion tensor imaging (DTI) is a promising method for characterizing microstructural changes or differences with neuropathology and treatment. The diffusion tensor may be used to characterize the magnitude, anisotropy and orientation of the diffusion tensor. This paper reviews the biological mechanisms, acquisition and analysis methodology of DTI measurements. The relationships between DTI measures and white matter pathologic features (ischemia, myelination, axonal damage, inflammation, and edema) are summarized. Applications of DTI to tissue characterization in neurotherapeutic applications are reviewed. The interpretations of common DTI measures – mean diffusivity (MD), fractional anisotropy (FA), radial diffusivity (Dr) and axial diffusivity (Da) – are discussed. In particular, FA is highly sensitive to microstructural changes, but not very specific to the type of changes (e.g., radial or axial). In order to maximize the specificity, it is recommended that future studies use multiple diffusion tensor measures (e.g., MD and FA, or Da and Dr) to better characterize the tissue microstructure.","accessed":{"date-parts":[[2019,4,23]]},"author":[{"family":"Alexander","given":"Andrew L."},{"family":"Lee","given":"Jee Eun"},{"family":"Lazar","given":"Mariana"},{"family":"Field","given":"Aaron S."}],"citation-key":"alexanderDiffusionTensorImaging2007","container-title":"Neurotherapeutics : the journal of the American Society for Experimental NeuroTherapeutics","container-title-short":"Neurotherapeutics","DOI":"10.1016/j.nurt.2007.05.011","ISSN":"1933-7213","issue":"3","issued":{"date-parts":[[2007,7]]},"page":"316-329","PMCID":"PMC2041910","PMID":"17599699","source":"PubMed Central","title":"Diffusion Tensor Imaging of the Brain","type":"article-journal","URL":"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2041910/","volume":"4"},
  {"id":"anscombeGraphsStatisticalAnalysis1973","accessed":{"date-parts":[[2020,4,6]]},"author":[{"family":"Anscombe","given":"F. J."}],"citation-key":"anscombeGraphsStatisticalAnalysis1973","container-title":"The American Statistician","container-title-short":"The American Statistician","DOI":"10.1080/00031305.1973.10478966","ISSN":"0003-1305, 1537-2731","issue":"1","issued":{"date-parts":[[1973,2]]},"language":"en","page":"17-21","source":"DOI.org (Crossref)","title":"Graphs in Statistical Analysis","type":"article-journal","URL":"http://www.tandfonline.com/doi/abs/10.1080/00031305.1973.10478966","volume":"27"},
  {"id":"arroyo-relionNetworkClassificationApplications2017","abstract":"While statistical analysis of a single network has received a lot of attention in recent years, with a focus on social networks, analysis of a sample of networks presents its own challenges which require a different set of analytic tools. Here we study the problem of classification of networks with labeled nodes, motivated by applications in neuroimaging. Brain networks are constructed from imaging data to represent functional connectivity between regions of the brain, and previous work has shown the potential of such networks to distinguish between various brain disorders, giving rise to a network classification problem. Existing approaches tend to either treat all edge weights as a long vector, ignoring the network structure, or focus on graph topology as represented by summary measures while ignoring the edge weights. Our goal is to design a classification method that uses both the individual edge information and the network structure of the data in a computationally efficient way, and that can produce a parsimonious and interpretable representation of differences in brain connectivity patterns between classes. We propose a graph classification method that uses edge weights as predictors but incorporates the network nature of the data via penalties that promote sparsity in the number of nodes, in addition to the usual sparsity penalties that encourage selection of edges. We implement the method via efficient convex optimization and provide a detailed analysis of data from two fMRI studies of schizophrenia.","accessed":{"date-parts":[[2019,9,5]]},"author":[{"family":"Arroyo-Relión","given":"Jesús D."},{"family":"Kessler","given":"Daniel"},{"family":"Levina","given":"Elizaveta"},{"family":"Taylor","given":"Stephan F."}],"citation-key":"arroyo-relionNetworkClassificationApplications2017","container-title":"arXiv:1701.08140 [stat]","issued":{"date-parts":[[2017,1,27]]},"source":"arXiv.org","title":"Network classification with applications to brain connectomics","type":"article-journal","URL":"http://arxiv.org/abs/1701.08140"},
  {"id":"arroyoInferenceMultipleHeterogeneous2019","abstract":"The development of models for multiple heterogeneous network data is of critical importance both in statistical network theory and across multiple application domains. Although single-graph inference is well-studied, multiple graph inference is largely unexplored, in part because of the challenges inherent in appropriately modeling graph differences and yet retaining sufficient model simplicity to render estimation feasible. This paper addresses exactly this gap, by introducing a new model, the common subspace independent-edge (COSIE) multiple random graph model, which describes a heterogeneous collection of networks with a shared latent structure on the vertices but potentially different connectivity patterns for each graph. The COSIE model encompasses many popular network representations, including the stochastic blockmodel. The model is both flexible enough to meaningfully account for important graph differences and tractable enough to allow for accurate inference in multiple networks. In particular, a joint spectral embedding of adjacency matrices - the multiple adjacency spectral embedding (MASE) - leads, in a COSIE model, to simultaneous consistent estimation of underlying parameters for each graph. Under mild additional assumptions, MASE estimates satisfy asymptotic normality and yield improvements for graph eigenvalue estimation. In both simulated and real data, the COSIE model and the MASE embedding can be deployed for a number of subsequent network inference tasks, including dimensionality reduction, classification, hypothesis testing and community detection. Specifically, when MASE is applied to a dataset of connectomes constructed through diffusion magnetic resonance imaging, the result is an accurate classification of brain scans by patient and a meaningful determination of heterogeneity across scans of different subjects.","accessed":{"date-parts":[[2019,8,5]]},"author":[{"family":"Arroyo","given":"Jesús"},{"family":"Athreya","given":"Avanti"},{"family":"Cape","given":"Joshua"},{"family":"Chen","given":"Guodong"},{"family":"Priebe","given":"Carey E."},{"family":"Vogelstein","given":"Joshua T."}],"citation-key":"arroyoInferenceMultipleHeterogeneous2019","container-title":"arXiv:1906.10026 [cs, math, stat]","issued":{"date-parts":[[2019,6,24]]},"source":"arXiv.org","title":"Inference for multiple heterogeneous networks with a common invariant subspace","type":"article-journal","URL":"http://arxiv.org/abs/1906.10026"},
  {"id":"athreyaEstimationInferenceLatent2018","abstract":"We define a latent structure model (LSM) random graph as a random dot product graph (RDPG) in which the latent position distribution incorporates both probabilistic and geometric constraints, delineated by a family of underlying distributions on some fixed Euclidean space, and a structural support submanifold from which the latent positions for the graph are drawn. For a one-dimensional latent structure model with known structural support, we show how spectral estimates of the latent positions of an RDPG can be used for efficient estimation of the paramaters of the LSM. We describe how to estimate or learn the structural support in cases where it is unknown, with an illustrative focus on graphs with latent positions along the Hardy-Weinberg curve. Finally, we use the latent structure model formulation to test bilateral homology in the Drosophila connectome.","accessed":{"date-parts":[[2020,4,9]]},"author":[{"family":"Athreya","given":"Avanti"},{"family":"Tang","given":"Minh"},{"family":"Park","given":"Youngser"},{"family":"Priebe","given":"Carey E."}],"citation-key":"athreyaEstimationInferenceLatent2018","container-title":"arXiv:1806.01401 [stat]","issued":{"date-parts":[[2018,6,22]]},"source":"arXiv.org","title":"On estimation and inference in latent structure random graphs","type":"article-journal","URL":"http://arxiv.org/abs/1806.01401"},
  {"id":"athreyaSemiparametricTwoSampleHypothesis2017","abstract":"Two-sample hypothesis testing for random graphs arises naturally in neuroscience, social networks, and machine learning. In this article, we consider a semiparametric problem of two-sample hypothesis testing for a class of latent position random graphs. We formulate a notion of consistency in this context and propose a valid test for the hypothesis that two finite-dimensional random dot product graphs on a common vertex set have the same generating latent positions or have generating latent positions that are scaled or diagonal transformations of one another. Our test statistic is a function of a spectral decomposition of the adjacency matrix for each graph and our test procedure is consistent across a broad range of alternatives. We apply our test procedure to real biological data: in a test-retest dataset of neural connectome graphs, we are able to distinguish between scans from different subjects; and in the C. elegans connectome, we are able to distinguish between chemical and electrical networks. The latter example is a concrete demonstration that our test can have power even for small-sample sizes. We conclude by discussing the relationship between our test procedure and generalized likelihood ratio tests. Supplementary materials for this article are available online.","accessed":{"date-parts":[[2019,1,25]]},"author":[{"family":"Athreya","given":"Avanti"},{"family":"Sussman","given":"Daniel L."},{"family":"Lyzinski","given":"Vince"},{"family":"Park","given":"Youngser"},{"family":"Priebe","given":"Carey E."}],"citation-key":"athreyaSemiparametricTwoSampleHypothesis2017","container-title":"Journal of Computational and Graphical Statistics","container-title-short":"Journal of Computational and Graphical Statistics","DOI":"10.1080/10618600.2016.1193505","ISSN":"1061-8600","issue":"2","issued":{"date-parts":[[2017,4,3]]},"page":"344-354","source":"amstat.tandfonline.com (Atypon)","title":"A Semiparametric Two-Sample Hypothesis Testing Problem for Random Graphs AU  - Tang, Minh","type":"article-journal","URL":"https://amstat.tandfonline.com/doi/full/10.1080/10618600.2016.1193505","volume":"26"},
  {"id":"athreyaStatisticalInferenceRandom2018","accessed":{"date-parts":[[2019,1,25]]},"author":[{"family":"Athreya","given":"Avanti"},{"family":"Fishkind","given":"Donniell E."},{"family":"Tang","given":"Minh"},{"family":"Priebe","given":"Carey E."},{"family":"Park","given":"Youngser"},{"family":"Vogelstein","given":"Joshua T."},{"family":"Levin","given":"Keith"},{"family":"Lyzinski","given":"Vince"},{"family":"Qin","given":"Yichen"},{"family":"Sussman","given":"Daniel L."}],"citation-key":"athreyaStatisticalInferenceRandom2018","container-title":"Journal of Machine Learning Research","issue":"226","issued":{"date-parts":[[2018]]},"page":"1-92","source":"jmlr.org","title":"Statistical Inference on Random Dot Product Graphs: a Survey","title-short":"Statistical Inference on Random Dot Product Graphs","type":"article-journal","URL":"http://jmlr.org/papers/v18/17-448.html","volume":"18"},
  {"id":"avdiukhinMultiDimensionalBalancedGraph2019","abstract":"Motivated by performance optimization of large-scale graph processing systems that distribute the graph across multiple machines, we consider the balanced graph partitioning problem. Compared to the previous work, we study the multi-dimensional variant when balance according to multiple weight functions is required. As we demonstrate by experimental evaluation, such multi-dimensional balance is important for achieving performance improvements for typical distributed graph processing workloads. We propose a new scalable technique for the multidimensional balanced graph partitioning problem. The method is based on applying randomized projected gradient descent to a non-convex continuous relaxation of the objective. We show how to implement the new algorithm efficiently in both theory and practice utilizing various approaches for projection. Experiments with large-scale social networks containing up to hundreds of billions of edges indicate that our algorithm has superior performance compared with the state-of-the-art approaches.","accessed":{"date-parts":[[2019,3,6]]},"author":[{"family":"Avdiukhin","given":"Dmitrii"},{"family":"Pupyrev","given":"Sergey"},{"family":"Yaroslavtsev","given":"Grigory"}],"citation-key":"avdiukhinMultiDimensionalBalancedGraph2019","container-title":"arXiv:1902.03522 [cs]","issued":{"date-parts":[[2019,2,9]]},"source":"arXiv.org","title":"Multi-Dimensional Balanced Graph Partitioning via Projected Gradient Descent","type":"article-journal","URL":"http://arxiv.org/abs/1902.03522"},
  {"id":"axlerLinearAlgebraDone2015","abstract":"This best-selling textbook for a second course in linear algebra is aimed at undergrad math majors and graduate students. The novel approach taken here banishes determinants to the end of the book. The text focuses on the central goal of linear algebra: understanding the structure of linear operators on finite-dimensional vector spaces. The author has taken unusual care to motivate concepts and to simplify proofs. A variety of interesting exercises in each chapter helps students understand and manipulate the objects of linear algebra.The third edition contains major improvements and revisions throughout the book. More than 300 new exercises have been added since the previous edition. Many new examples have been added to illustrate the key ideas of linear algebra. New topics covered in the book include product spaces, quotient spaces, and dual spaces. Beautiful new formatting creates pages with an unusually pleasant appearance in both print and electronic versions.No prerequisites are assumed other than the usual demand for suitable mathematical maturity. Thus the text starts by discussing vector spaces, linear independence, span, basis, and dimension. The book then deals with linear maps, eigenvalues, and eigenvectors. Inner-product spaces are introduced, leading to the finite-dimensional spectral theorem and its consequences. Generalized eigenvectors are then used to provide insight into the structure of a linear operator.","accessed":{"date-parts":[[2019,2,11]]},"author":[{"family":"Axler","given":"Sheldon"}],"citation-key":"axlerLinearAlgebraDone2015","collection-title":"Undergraduate Texts in Mathematics","edition":"3","ISBN":"978-3-319-11079-0","issued":{"date-parts":[[2015]]},"language":"en","publisher":"Springer International Publishing","source":"www.springer.com","title":"Linear Algebra Done Right","type":"book","URL":"https://www.springer.com/us/book/9783319110790"},
  {"id":"bacciuGentleIntroductionDeep2019","abstract":"The adaptive processing of graph data is a long-standing research topic which has been lately consolidated as a theme of major interest in the deep learning community. The snap increase in the amount and breadth of related research has come at the price of little systematization of knowledge and attention to earlier literature. This work is designed as a tutorial introduction to the field of deep learning for graphs. It favours a consistent and progressive introduction of the main concepts and architectural aspects over an exposition of the most recent literature, for which the reader is referred to available surveys. The paper takes a top-down view to the problem, introducing a generalized formulation of graph representation learning based on a local and iterative approach to structured information processing. It introduces the basic building blocks that can be combined to design novel and effective neural models for graphs. The methodological exposition is complemented by a discussion of interesting research challenges and applications in the field.","accessed":{"date-parts":[[2020,1,27]]},"author":[{"family":"Bacciu","given":"Davide"},{"family":"Errica","given":"Federico"},{"family":"Micheli","given":"Alessio"},{"family":"Podda","given":"Marco"}],"citation-key":"bacciuGentleIntroductionDeep2019","container-title":"arXiv:1912.12693 [cs, stat]","issued":{"date-parts":[[2019,12,29]]},"source":"arXiv.org","title":"A Gentle Introduction to Deep Learning for Graphs","type":"article-journal","URL":"http://arxiv.org/abs/1912.12693"},
  {"id":"balakrishnanLocalWhiteMatter2018","abstract":"Large bundles of myelinated axons, called white matter, anatomically connect disparate brain regions together and compose the structural core of the human connectome. We recently proposed a method of measuring the local integrity along the length of each white matter fascicle, termed the local connectome [1]. If communication efficiency is fundamentally constrained by the integrity along the entire length of a white matter bundle [2], then variability in the functional dynamics of brain networks should be associated with variability in the local connectome. We test this prediction using two statistical approaches that are capable of handling the high dimensionality of data. First, by performing statistical inference on distance-based correlations, we show that similarity in the local connectome between individuals is significantly correlated with similarity in their patterns of functional connectivity. Second, by employing variable selection using sparse canonical correlation analysis and cross-validation, we show that segments of the local connectome are predictive of certain patterns of functional brain dynamics. These results are consistent with the hypothesis that structural variability along axon bundles constrains communication between disparate brain regions.","author":[{"family":"Balakrishnan","given":"S."},{"family":"Choe","given":"Y. J."},{"family":"Singh","given":"A."},{"family":"Vettel","given":"J."},{"family":"Verstynen","given":"T."}],"citation-key":"balakrishnanLocalWhiteMatter2018","container-title":"2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","DOI":"10.1109/SMC.2018.00110","event-title":"2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","issued":{"date-parts":[[2018,10]]},"page":"595-602","source":"IEEE Xplore","title":"Local White Matter Architecture Defines Functional Brain Dynamics","type":"paper-conference"},
  {"id":"bassettSmallworldBrainNetworks2006","abstract":"Many complex networks have a small-world topology characterized by dense local clustering or cliquishness of connections between neighboring nodes yet a short path length between any (distant) pair of nodes due to the existence of relatively few long-range connections. This is an attractive model for the organization of brain anatomical and functional networks because a small-world topology can support both segregated/specialized and distributed/integrated information processing. Moreover, small-world networks are economical, tending to minimize wiring costs while supporting high dynamical complexity. The authors introduce some of the key mathematical concepts in graph theory required for small-world analysis and review how these methods have been applied to quantification of cortical connectivity matrices derived from anatomical tract-tracing studies in the macaque monkey and the cat. The evolution of small-world networks is discussed in terms of a selection pressure to deliver cost-effective information-processing systems. The authors illustrate how these techniques and concepts are increasingly being applied to the analysis of human brain functional networks derived from electroencephalography/magnetoencephalography and fMRI experiments. Finally, the authors consider the relevance of small-world models for understanding the emergence of complex behaviors and the resilience of brain systems to pathological attack by disease or aberrant development. They conclude that small-world models provide a powerful and versatile approach to understanding the structure and function of human brain systems.","author":[{"family":"Bassett","given":"Danielle Smith"},{"family":"Bullmore","given":"Ed"}],"citation-key":"bassettSmallworldBrainNetworks2006","container-title":"The Neuroscientist: A Review Journal Bringing Neurobiology, Neurology and Psychiatry","container-title-short":"Neuroscientist","DOI":"10.1177/1073858406293182","ISSN":"1073-8584","issue":"6","issued":{"date-parts":[[2006,12]]},"language":"eng","page":"512-523","PMID":"17079517","source":"PubMed","title":"Small-world brain networks","type":"article-journal","volume":"12"},
  {"id":"battagliaRelationalInductiveBiases2018","abstract":"Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between \"hand-engineering\" and \"end-to-end\" learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have released an open-source software library for building graph networks, with demonstrations of how to use them in practice.","accessed":{"date-parts":[[2019,1,31]]},"author":[{"family":"Battaglia","given":"Peter W."},{"family":"Hamrick","given":"Jessica B."},{"family":"Bapst","given":"Victor"},{"family":"Sanchez-Gonzalez","given":"Alvaro"},{"family":"Zambaldi","given":"Vinicius"},{"family":"Malinowski","given":"Mateusz"},{"family":"Tacchetti","given":"Andrea"},{"family":"Raposo","given":"David"},{"family":"Santoro","given":"Adam"},{"family":"Faulkner","given":"Ryan"},{"family":"Gulcehre","given":"Caglar"},{"family":"Song","given":"Francis"},{"family":"Ballard","given":"Andrew"},{"family":"Gilmer","given":"Justin"},{"family":"Dahl","given":"George"},{"family":"Vaswani","given":"Ashish"},{"family":"Allen","given":"Kelsey"},{"family":"Nash","given":"Charles"},{"family":"Langston","given":"Victoria"},{"family":"Dyer","given":"Chris"},{"family":"Heess","given":"Nicolas"},{"family":"Wierstra","given":"Daan"},{"family":"Kohli","given":"Pushmeet"},{"family":"Botvinick","given":"Matt"},{"family":"Vinyals","given":"Oriol"},{"family":"Li","given":"Yujia"},{"family":"Pascanu","given":"Razvan"}],"citation-key":"battagliaRelationalInductiveBiases2018","container-title":"arXiv:1806.01261 [cs, stat]","issued":{"date-parts":[[2018,6,4]]},"source":"arXiv.org","title":"Relational inductive biases, deep learning, and graph networks","type":"article-journal","URL":"http://arxiv.org/abs/1806.01261"},
  {"id":"behrensHumanConnectomics2012","abstract":"Recent advances in non-invasive neuroimaging have enabled the measurement of connections between distant regions in the living human brain, thus opening up a new field of research: Human connectomics. Different imaging modalities allow the mapping of structural connections (axonal fibre tracts) as well as functional connections (correlations in time series), and individual variations in these connections may be related to individual variations in behaviour and cognition. Connectivity analysis has already led to a number of new insights about brain organization. For example, segregated brain regions may be identified by their unique patterns of connectivity, structural and functional connectivity may be compared to elucidate how dynamic interactions arise from the anatomical substrate, and the architecture of large-scale networks connecting sets of brain regions may be analysed in detail. The combined analysis of structural and functional networks has begun to reveal components or modules with distinct patterns of connections that become engaged in different cognitive tasks. Collectively, advances in human connectomics open up the possibility of studying how brain connections mediate regional brain function and thence behaviour.","accessed":{"date-parts":[[2019,1,25]]},"author":[{"family":"Behrens","given":"Timothy EJ"},{"family":"Sporns","given":"Olaf"}],"citation-key":"behrensHumanConnectomics2012","collection-title":"Neurotechnology","container-title":"Current Opinion in Neurobiology","container-title-short":"Current Opinion in Neurobiology","DOI":"10.1016/j.conb.2011.08.005","ISSN":"0959-4388","issue":"1","issued":{"date-parts":[[2012,2,1]]},"page":"144-153","source":"ScienceDirect","title":"Human connectomics","type":"article-journal","URL":"http://www.sciencedirect.com/science/article/pii/S0959438811001449","volume":"22"},
  {"id":"benjaminiControllingFalseDiscovery1995","abstract":"The common approach to the multiplicity problem calls for controlling the familywise error rate (FWER). This approach, though, has faults, and we point out a few. A different approach to problems of multiple significance testing is presented. It calls for controlling the expected proportion of falsely rejected hypotheses-the false discovery rate. This error rate is equivalent to the FWER when all hypotheses are true but is smaller otherwise. Therefore, in problems where the control of the false discovery rate rather than that of the FWER is desired, there is potential for a gain in power. A simple sequential Bonferroni-type procedure is proved to control the false discovery rate for independent test statistics, and a simulation study shows that the gain in power is substantial. The use of the new procedure and the appropriateness of the criterion are illustrated with examples.","accessed":{"date-parts":[[2022,10,10]]},"author":[{"family":"Benjamini","given":"Yoav"},{"family":"Hochberg","given":"Yosef"}],"citation-key":"benjaminiControllingFalseDiscovery1995","container-title":"Journal of the Royal Statistical Society. Series B (Methodological)","ISSN":"0035-9246","issue":"1","issued":{"date-parts":[[1995]]},"page":"289-300","publisher":"[Royal Statistical Society, Wiley]","source":"JSTOR","title":"Controlling the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing","title-short":"Controlling the False Discovery Rate","type":"article-journal","URL":"https://www.jstor.org/stable/2346101","volume":"57"},
  {"id":"binkiewiczCovariateassistedSpectralClustering2017","abstract":"Summary.  Biological and social systems consist of myriad interacting units. The interactions can be represented in the form of a graph or network. Measurements","accessed":{"date-parts":[[2019,3,8]]},"author":[{"family":"Binkiewicz","given":"N."},{"family":"Vogelstein","given":"J. T."},{"family":"Rohe","given":"K."}],"citation-key":"binkiewiczCovariateassistedSpectralClustering2017","container-title":"Biometrika","container-title-short":"Biometrika","DOI":"10.1093/biomet/asx008","ISSN":"0006-3444","issue":"2","issued":{"date-parts":[[2017,6,1]]},"language":"en","page":"361-377","source":"academic.oup.com","title":"Covariate-assisted spectral clustering","type":"article-journal","URL":"https://academic.oup.com/biomet/article/104/2/361/3074977","volume":"104"},
  {"id":"bloklandGeneticEnvironmentalInfluences2012","abstract":"Because brain structure and function are affected in neurological and psychiatric disorders, it is important to disentangle the sources of variation in these phenotypes. Over the past 15 years, twin studies have found evidence for both genetic and environmental influences on neuroimaging phenotypes, but considerable variation across studies makes it difficult to draw clear conclusions about the relative magnitude of these influences. Here we performed the first meta-analysis of structural MRI data from 48 studies on >1,250 twin pairs, and diffusion tensor imaging data from 10 studies on 444 twin pairs. The proportion of total variance accounted for by genes (A), shared environment (C), and unshared environment (E), was calculated by averaging A, C, and E estimates across studies from independent twin cohorts and weighting by sample size. The results indicated that additive genetic estimates were significantly different from zero for all meta-analyzed phenotypes, with the exception of fractional anisotropy (FA) of the callosal splenium, and cortical thickness (CT) of the uncus, left parahippocampal gyrus, and insula. For many phenotypes there was also a significant influence of C. We now have good estimates of heritability for many regional and lobar CT measures, in addition to the global volumes. Confidence intervals are wide and number of individuals small for many of the other phenotypes. In conclusion, while our meta-analysis shows that imaging measures are strongly influenced by genes, and that novel phenotypes such as CT measures, FA measures, and brain activation measures look especially promising, replication across independent samples and demographic groups is necessary.","accessed":{"date-parts":[[2019,4,22]]},"author":[{"family":"Blokland","given":"Gabriëlla A. M."},{"family":"Zubicaray","given":"Greig I.","dropping-particle":"de"},{"family":"McMahon","given":"Katie L."},{"family":"Wright","given":"Margaret J."}],"citation-key":"bloklandGeneticEnvironmentalInfluences2012","container-title":"Twin Research and Human Genetics","DOI":"10.1017/thg.2012.11","ISSN":"1839-2628, 1832-4274","issue":"3","issued":{"date-parts":[[2012,6]]},"language":"en","page":"351-371","source":"Cambridge Core","title":"Genetic and Environmental Influences on Neuroimaging Phenotypes: A Meta-Analytical Perspective on Twin Imaging Studies","title-short":"Genetic and Environmental Influences on Neuroimaging Phenotypes","type":"article-journal","URL":"https://www.cambridge.org/core/journals/twin-research-and-human-genetics/article/genetic-and-environmental-influences-on-neuroimaging-phenotypes-a-metaanalytical-perspective-on-twin-imaging-studies/09AC680E62998D75CCB9DA7AA266EB8A","volume":"15"},
  {"id":"bloklandHeritabilityWorkingMemory2011","abstract":"Although key to understanding individual variation in task-related brain activation, the genetic contribution to these individual differences remains largely unknown. Here we report voxel-by-voxel genetic model fitting in a large sample of 319 healthy, young adult, human identical and fraternal twins (mean ± SD age, 23.6 ± 1.8 years) who performed an n-back working memory task during functional magnetic resonance imaging (fMRI) at a high magnetic field (4 tesla). Patterns of task-related brain response (BOLD signal difference of 2-back minus 0-back) were significantly heritable, with the highest estimates (40–65%) in the inferior, middle, and superior frontal gyri, left supplementary motor area, precentral and postcentral gyri, middle cingulate cortex, superior medial gyrus, angular gyrus, superior parietal lobule, including precuneus, and superior occipital gyri. Furthermore, high test-retest reliability for a subsample of 40 twins indicates that nongenetic variance in the fMRI brain response is largely due to unique environmental influences rather than measurement error. Individual variations in activation of the working memory network are therefore significantly influenced by genetic factors. By establishing the heritability of cognitive brain function in a large sample that affords good statistical power, and using voxel-by-voxel analyses, this study provides the necessary evidence for task-related brain activation to be considered as an endophenotype for psychiatric or neurological disorders, and represents a substantial new contribution to the field of neuroimaging genetics. These genetic brain maps should facilitate discovery of gene variants influencing cognitive brain function through genome-wide association studies, potentially opening up new avenues in the treatment of brain disorders.","accessed":{"date-parts":[[2019,1,25]]},"author":[{"family":"Blokland","given":"Gabriëlla A. M."},{"family":"McMahon","given":"Katie L."},{"family":"Thompson","given":"Paul M."},{"family":"Martin","given":"Nicholas G."},{"family":"Zubicaray","given":"Greig I.","dropping-particle":"de"},{"family":"Wright","given":"Margaret J."}],"citation-key":"bloklandHeritabilityWorkingMemory2011","container-title":"Journal of Neuroscience","container-title-short":"J. Neurosci.","DOI":"10.1523/JNEUROSCI.5334-10.2011","ISSN":"0270-6474, 1529-2401","issue":"30","issued":{"date-parts":[[2011,7,27]]},"language":"en","license":"Copyright © 2011 the authors 0270-6474/11/3110882-09$15.00/0","page":"10882-10890","PMID":"21795540","source":"www.jneurosci.org","title":"Heritability of Working Memory Brain Activation","type":"article-journal","URL":"http://www.jneurosci.org/content/31/30/10882","volume":"31"},
  {"id":"bohlkenHeritabilityStructuralBrain2014","abstract":"Individual variation in structural brain network topology has been associated with heritable behavioral phenotypes such as intelligence and schizophrenia, making it a candidate endophenotype. However, little is known about the genetic influences on individual variation in structural brain network topology. Moreover, the extent to which structural brain network topology overlaps with heritability for integrity and volume of white matter remains unknown. In this study, structural network topology was examined using diffusion tensor imaging at 3T. Binary connections between 82 structurally defined brain regions per subject were traced, allowing for estimation of individual topological network properties. Heritability of normalized characteristic path length (λ), normalized clustering coefficient (γ), microstructural integrity (FA), and volume of the white matter were estimated using a twin design, including 156 adult twins from the newly acquired U-TWIN cohort. Both γ and λ were estimated to be under substantial genetic influence. The heritability of γ was estimated to be 68%, the heritability estimate for λ was estimated to be 57%. Genetic influences on network measures were found to be partly overlapping with volumetric and microstructural properties of white matter, but the largest component of genetic variance was unique to both network traits. Normalized clustering coefficient and normalized characteristic path length are substantially heritable, and influenced by independent genetic factors that are largely unique to network measures, but partly also implicated in white matter directionality and volume. Thus, network measures provide information about genetic influence on brain structure, independent of global white matter characteristics such as volume and microstructural directionality. Hum Brain Mapp 35:5295–5305, 2014. © 2014 Wiley Periodicals, Inc.","accessed":{"date-parts":[[2019,4,24]]},"author":[{"family":"Bohlken","given":"Marc M."},{"family":"Mandl","given":"René C. W."},{"family":"Brouwer","given":"Rachel M."},{"family":"Heuvel","given":"Martijn P.","dropping-particle":"van den"},{"family":"Hedman","given":"Anna M."},{"family":"Kahn","given":"René S."},{"family":"Pol","given":"Hilleke E. Hulshoff"}],"citation-key":"bohlkenHeritabilityStructuralBrain2014","container-title":"Human Brain Mapping","DOI":"10.1002/hbm.22550","ISSN":"1097-0193","issue":"10","issued":{"date-parts":[[2014]]},"language":"en","license":"Copyright © 2014 Wiley Periodicals, Inc.","page":"5295-5305","source":"Wiley Online Library","title":"Heritability of structural brain network topology: A DTI study of 156 twins","title-short":"Heritability of structural brain network topology","type":"article-journal","URL":"https://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.22550","volume":"35"},
  {"id":"bretzGraphicalApproachSequentially2009","abstract":"For clinical trials with multiple treatment arms or endpoints a variety of sequentially rejective, weighted Bonferroni-type tests have been proposed, such as gatekeeping procedures, fixed sequence tests, and fallback procedures. They allow to map the difference in importance as well as the relationship between the various research questions onto an adequate multiple test procedure. Since these procedures rely on the closed test principle, they usually require the explicit specification of a large number of intersection hypotheses tests. The underlying test strategy may therefore be difficult to communicate. We propose a simple iterative graphical approach to construct and perform such Bonferroni-type tests. The resulting multiple test procedures are represented by directed, weighted graphs, where each node corresponds to an elementary hypothesis, together with a simple algorithm to generate such graphs while sequentially testing the individual hypotheses. The approach is illustrated with the visualization of several common gatekeeping strategies. A case study is used to illustrate how the methods from this article can be used to tailor a multiple test procedure to given study objectives. Copyright © 2008 John Wiley & Sons, Ltd.","accessed":{"date-parts":[[2022,10,18]]},"author":[{"family":"Bretz","given":"Frank"},{"family":"Maurer","given":"Willi"},{"family":"Brannath","given":"Werner"},{"family":"Posch","given":"Martin"}],"citation-key":"bretzGraphicalApproachSequentially2009","container-title":"Statistics in Medicine","DOI":"10.1002/sim.3495","ISSN":"1097-0258","issue":"4","issued":{"date-parts":[[2009]]},"language":"en","note":"_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.3495","page":"586-604","source":"Wiley Online Library","title":"A graphical approach to sequentially rejective multiple test procedures","type":"article-journal","URL":"https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.3495","volume":"28"},
  {"id":"brinAnatomyLargeScaleHypertextual1998","abstract":"In this paper, we present Google, a prototype of a large-scale search engine which makes heavy use of the structure present in hypertext. Google is designed to crawl and index the Web efficiently and produce much more satisfying search results than existing systems. The  prototype with a full text and hyperlink database of at least 24 million pages is available at http://google.stanford.edu/. To engineer a search  engine is a challenging task. Search engines index tens to hundreds of millions of web pages involving a comparable number of distinct terms. They answer tens of millions of queries every day. Despite the importance of large-scale search engines on the web, very little academic research has been done on them. Furthermore, due to rapid advance in technology and web proliferation, creating a web search  engine today is very different from three years ago. This paper provides an in-depth description of our large-scale web search engine -- the first such detailed public description we know of to date. Apart from the problems of scaling traditional search techniques to data of this magnitude, there are new technical challenges involved with using the additional information present in hypertext to produce better search results. This paper addresses this question of how to build a practical large-scale system which can exploit the additional information present in hypertext. Also we look at the problem of how to effectively deal with uncontrolled hypertext collections where anyone can publish anything they want.","accessed":{"date-parts":[[2019,2,11]]},"author":[{"family":"Brin","given":"S."},{"family":"Page","given":"L."}],"citation-key":"brinAnatomyLargeScaleHypertextual1998","event-place":"Brisbane, Australia","event-title":"Seventh International World-Wide Web Conference (WWW 1998)","issued":{"date-parts":[[1998]]},"publisher-place":"Brisbane, Australia","source":"ilpubs.stanford.edu:8090","title":"The Anatomy of a Large-Scale Hypertextual Web Search Engine","type":"paper-conference","URL":"http://ilpubs.stanford.edu:8090/361/"},
  {"id":"bullmoreComplexBrainNetworks2009","abstract":"Recent developments in the quantitative analysis of complex networks, based largely on graph theory, have been rapidly translated to studies of brain network organization. The brain's structural and functional systems have features of complex networks — such as small-world topology, highly connected hubs and modularity — both at the whole-brain scale of human neuroimaging and at a cellular scale in non-human animals. In this article, we review studies investigating complex brain networks in diverse experimental modalities (including structural and functional MRI, diffusion tensor imaging, magnetoencephalography and electroencephalography in humans) and provide an accessible introduction to the basic principles of graph theory. We also highlight some of the technical challenges and key questions to be addressed by future developments in this rapidly moving field.","accessed":{"date-parts":[[2019,4,24]]},"author":[{"family":"Bullmore","given":"Ed"},{"family":"Sporns","given":"Olaf"}],"citation-key":"bullmoreComplexBrainNetworks2009","container-title":"Nature Reviews Neuroscience","DOI":"10.1038/nrn2575","ISSN":"1471-0048","issue":"3","issued":{"date-parts":[[2009,3]]},"language":"en","license":"2009 Nature Publishing Group","page":"186-198","source":"www.nature.com","title":"Complex brain networks: graph theoretical analysis of structural and functional systems","title-short":"Complex brain networks","type":"article-journal","URL":"https://www.nature.com/articles/nrn2575","volume":"10"},
  {"id":"capeSpectralEmbeddingPerformance2018","abstract":"Statistical inference on graphs often proceeds via spectral methods involving low-dimensional embeddings of matrix-valued graph representations, such as the graph Laplacian or adjacency matrix. In this paper, we analyze the asymptotic information-theoretic relative performance of Laplacian spectral embedding and adjacency spectral embedding for block assignment recovery in stochastic block model graphs by way of Chernoff information. We investigate the relationship between spectral embedding performance and underlying network structure (e.g.~homogeneity, affinity, core-periphery, (un)balancedness) via a comprehensive treatment of the two-block stochastic block model and the class of $K$-block models exhibiting homogeneous balanced affinity structure. Our findings support the claim that, for a particular notion of sparsity, loosely speaking, \"Laplacian spectral embedding favors relatively sparse graphs, whereas adjacency spectral embedding favors not-too-sparse graphs.\" We also provide evidence in support of the claim that \"adjacency spectral embedding favors core-periphery network structure.\"","accessed":{"date-parts":[[2020,4,14]]},"author":[{"family":"Cape","given":"Joshua"},{"family":"Tang","given":"Minh"},{"family":"Priebe","given":"Carey E."}],"citation-key":"capeSpectralEmbeddingPerformance2018","container-title":"arXiv:1808.04855 [math, stat]","issued":{"date-parts":[[2018,8,14]]},"source":"arXiv.org","title":"On spectral embedding performance and elucidating network structure in stochastic block model graphs","type":"article-journal","URL":"http://arxiv.org/abs/1808.04855"},
  {"id":"capeTwotoinfinityNormSingular2017","abstract":"The singular value matrix decomposition plays a ubiquitous role throughout statistics and related fields. Myriad applications including clustering, classification, and dimensionality reduction involve studying and exploiting the geometric structure of singular values and singular vectors. This paper provides a novel collection of technical and theoretical tools for studying the geometry of singular subspaces using the two-to-infinity norm. Motivated by preliminary deterministic Procrustes analysis, we consider a general matrix perturbation setting in which we derive a new Procrustean matrix decomposition. Together with flexible machinery developed for the two-to-infinity norm, this allows us to conduct a refined analysis of the induced perturbation geometry with respect to the underlying singular vectors even in the presence of singular value multiplicity. Our analysis yields singular vector entrywise perturbation bounds for a range of popular matrix noise models, each of which has a meaningful associated statistical inference task. In addition, we demonstrate how the two-to-infinity norm is the preferred norm in certain statistical settings. Specific applications discussed in this paper include covariance estimation, singular subspace recovery, and multiple graph inference. Both our Procrustean matrix decomposition and the technical machinery developed for the two-to-infinity norm may be of independent interest.","accessed":{"date-parts":[[2019,2,6]]},"author":[{"family":"Cape","given":"Joshua"},{"family":"Tang","given":"Minh"},{"family":"Priebe","given":"Carey E."}],"citation-key":"capeTwotoinfinityNormSingular2017","container-title":"arXiv:1705.10735 [math, stat]","issued":{"date-parts":[[2017,5,30]]},"source":"arXiv.org","title":"The two-to-infinity norm and singular subspace geometry with applications to high-dimensional statistics","type":"article-journal","URL":"http://arxiv.org/abs/1705.10735"},
  {"id":"chamiMachineLearningGraphs2020","abstract":"There has been a surge of recent interest in learning representations for graph-structured data. Graph representation learning methods have generally fallen into three main categories, based on the availability of labeled data. The first, network embedding (such as shallow graph embedding or graph auto-encoders), focuses on learning unsupervised representations of relational structure. The second, graph regularized neural networks, leverages graphs to augment neural network losses with a regularization objective for semi-supervised learning. The third, graph neural networks, aims to learn differentiable functions over discrete topologies with arbitrary structure. However, despite the popularity of these areas there has been surprisingly little work on unifying the three paradigms. Here, we aim to bridge the gap between graph neural networks, network embedding and graph regularization models. We propose a comprehensive taxonomy of representation learning methods for graph-structured data, aiming to unify several disparate bodies of work. Specifically, we propose a Graph Encoder Decoder Model (GRAPHEDM), which generalizes popular algorithms for semi-supervised learning on graphs (e.g. GraphSage, Graph Convolutional Networks, Graph Attention Networks), and unsupervised learning of graph representations (e.g. DeepWalk, node2vec, etc) into a single consistent approach. To illustrate the generality of this approach, we fit over thirty existing methods into this framework. We believe that this unifying view both provides a solid foundation for understanding the intuition behind these methods, and enables future research in the area.","accessed":{"date-parts":[[2020,5,17]]},"author":[{"family":"Chami","given":"Ines"},{"family":"Abu-El-Haija","given":"Sami"},{"family":"Perozzi","given":"Bryan"},{"family":"Ré","given":"Christopher"},{"family":"Murphy","given":"Kevin"}],"citation-key":"chamiMachineLearningGraphs2020","container-title":"arXiv:2005.03675 [cs, stat]","issued":{"date-parts":[[2020,5,7]]},"source":"arXiv.org","title":"Machine Learning on Graphs: A Model and Comprehensive Taxonomy","title-short":"Machine Learning on Graphs","type":"article-journal","URL":"http://arxiv.org/abs/2005.03675"},
  {"id":"charikarHierarchicalClusteringBetter2018","abstract":"Hierarchical Clustering (HC) is a widely studied problem in exploratory data analysis, usually tackled by simple agglomerative procedures like average-linkage, single-linkage or complete-linkage. In this paper we focus on two objectives, introduced recently to give insight into the performance of average-linkage clustering: a similarity based HC objective proposed by [Moseley and Wang, 2017] and a dissimilarity based HC objective proposed by [Cohen-Addad et al., 2018]. In both cases, we present tight counterexamples showing that average-linkage cannot obtain better than 1/3 and 2/3 approximations respectively (in the worst-case), settling an open question raised in [Moseley and Wang, 2017]. This matches the approximation ratio of a random solution, raising a natural question: can we beat average-linkage for these objectives? We answer this in the affirmative, giving two new algorithms based on semidefinite programming with provably better guarantees.","accessed":{"date-parts":[[2019,3,6]]},"author":[{"family":"Charikar","given":"Moses"},{"family":"Chatziafratis","given":"Vaggos"},{"family":"Niazadeh","given":"Rad"}],"citation-key":"charikarHierarchicalClusteringBetter2018","container-title":"arXiv:1808.02227 [cs]","issued":{"date-parts":[[2018,8,7]]},"source":"arXiv.org","title":"Hierarchical Clustering better than Average-Linkage","type":"article-journal","URL":"http://arxiv.org/abs/1808.02227"},
  {"id":"chenSameStatsDifferent2019","abstract":"Data analysts commonly utilize statistics to summarize large datasets. While it is often sufficient to explore only the summary statistics of a dataset (e.g., min/mean/max), Anscombe's Quartet demonstrates how such statistics can be misleading. We consider a similar problem in the context of graph mining. To study the relationships between different graph properties and summary statistics, we examine low-order non-isomorphic graphs and provide a simple visual analytics system to explore correlations across multiple graph properties. However, for larger graphs, studying the entire space quickly becomes intractable. We use different random graph generation methods to further look into the distribution of graph properties for higher order graphs and investigate the impact of various sampling methodologies. We also describe a method for generating many graphs that are identical over a number of graph properties and statistics yet are clearly different and identifiably distinct.","author":[{"family":"Chen","given":"Hang"},{"family":"Kobourov","given":"Stephen G."},{"family":"Maciejewski","given":"Ross"},{"family":"Lu","given":"Yafeng"},{"family":"Huroyan","given":"Vahan"},{"family":"Soni","given":"Utkarsh"}],"citation-key":"chenSameStatsDifferent2019","container-title":"IEEE Transactions on Visualization and Computer Graphics","DOI":"10.1109/TVCG.2019.2946558","ISSN":"1941-0506","issued":{"date-parts":[[2019]]},"page":"1-1","source":"IEEE Xplore","title":"Same Stats, Different Graphs: Exploring the Space of Graphs in Terms of Graph Properties","title-short":"Same Stats, Different Graphs","type":"article-journal"},
  {"id":"chungGraSPyGraphStatistics2019","abstract":"We introduce GraSPy, a Python library devoted to statistical inference, machine learning, and visualization of random graphs and graph populations. This package provides ﬂexible and easy-to-use algorithms for analyzing and understanding graphs with a scikit-learn compliant API. GraSPy can be downloaded from Python Package Index (PyPi), and is released under the Apache 2.0 open-source license. The documentation and all releases are available at https://neurodata.io/graspy.","author":[{"family":"Chung","given":"Jaewon"},{"family":"Pedigo","given":"Benjamin D"},{"family":"Bridgeford","given":"Eric W"},{"family":"Varjavand","given":"Bijan K"},{"family":"Helm","given":"Hayden S"},{"family":"Vogelstein","given":"Joshua T"}],"citation-key":"chungGraSPyGraphStatistics2019","container-title":"J. Mach. Learn. Res.","issue":"158","issued":{"date-parts":[[2019]]},"language":"en","page":"7","source":"Zotero","title":"GraSPy: Graph Statistics in Python","type":"article-journal","volume":"20"},
  {"id":"ClinesClustersEffect","accessed":{"date-parts":[[2020,7,9]]},"citation-key":"ClinesClustersEffect","title":"Clines, Clusters, and the Effect of Study Design on the Inference of Human Population Structure","type":"webpage","URL":"https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.0010070"},
  {"id":"colcloughHeritabilityMultimodalConnectivity2017","abstract":"Patterns of intrinsic human brain activity exhibit a profile of functional connectivity that is associated with behaviour and cognitive performance, and deteriorates with disease. This paper investigates the relative importance of genetic factors and the common environment between twins in determining this functional connectivity profile. Using functional magnetic resonance imaging (fMRI) on 820 subjects from the Human Connectome Project, and magnetoencephalographic (MEG) recordings from a subset, the heritability of connectivity among 39 cortical regions was estimated. On average over all connections, genes account for about 15% of the observed variance in fMRI connectivity (and about 10% in alpha-band and 20% in beta-band oscillatory power synchronisation), which substantially exceeds the contribution from the environment shared between twins. Therefore, insofar as twins share a common upbringing, it appears that genes, rather than the developmental environment, have the dominant role in determining the coupling of neuronal activity.","accessed":{"date-parts":[[2019,11,21]]},"author":[{"family":"Colclough","given":"Giles L"},{"family":"Smith","given":"Stephen M"},{"family":"Nichols","given":"Thomas E"},{"family":"Winkler","given":"Anderson M"},{"family":"Sotiropoulos","given":"Stamatios N"},{"family":"Glasser","given":"Matthew F"},{"family":"Van Essen","given":"David C"},{"family":"Woolrich","given":"Mark W"}],"citation-key":"colcloughHeritabilityMultimodalConnectivity2017","container-title":"eLife","DOI":"10.7554/eLife.20178","editor":[{"family":"Gallant","given":"Jack L"}],"ISSN":"2050-084X","issued":{"date-parts":[[2017,7,26]]},"page":"e20178","source":"eLife","title":"The heritability of multi-modal connectivity in human brain activity","type":"article-journal","URL":"https://doi.org/10.7554/eLife.20178","volume":"6"},
  {"id":"cuiPANDAPipelineToolbox2013","abstract":"Diffusion magnetic resonance imaging (dMRI) is widely used in both scientific research and clinical practice in in-vivo studies of the human brain. While a number of post-processing packages have been developed, fully automated processing of dMRI datasets remains challenging. Here, we developed a MATLAB toolbox named “Pipeline for Analyzing braiN Diffusion imAges” (PANDA) for fully automated processing of brain diffusion images. The processing modules of a few established packages, including FMRIB Software Library (FSL), Pipeline System for Octave and Matlab (PSOM), Diffusion Toolkit and MRIcron, were employed in PANDA. Using any number of raw dMRI datasets from different subjects, in either DICOM or NIfTI format, PANDA can automatically perform a series of steps to process DICOM/NIfTI to diffusion metrics (e.g., FA and MD) that are ready for statistical analysis at the voxel-level, the atlas-level and the Tract-Based Spatial Statistics (TBSS)-level and can finish the construction of anatomical brain networks for all subjects. In particular, PANDA can process different subjects in parallel, using multiple cores either in a single computer or in a distributed computing environment, thus greatly reducing the time cost when dealing with a large number of datasets. In addition, PANDA has a friendly graphical user interface (GUI), allowing the user to be interactive and to adjust the input/output settings, as well as the processing parameters. As an open-source package, PANDA is freely available at http://www.nitrc.org/projects/panda/. This novel toolbox is expected to substantially simplify the image processing of dMRI datasets and facilitate human structural connectome studies.","accessed":{"date-parts":[[2019,1,25]]},"author":[{"family":"Cui","given":"Zaixu"},{"family":"Zhong","given":"Suyu"},{"family":"Xu","given":"Pengfei"},{"family":"Gong","given":"Gaolang"},{"family":"He","given":"Yong"}],"citation-key":"cuiPANDAPipelineToolbox2013","container-title":"Frontiers in Human Neuroscience","container-title-short":"Front. Hum. Neurosci.","DOI":"10.3389/fnhum.2013.00042","ISSN":"1662-5161","issued":{"date-parts":[[2013]]},"language":"English","source":"Frontiers","title":"PANDA: a pipeline toolbox for analyzing brain diffusion images","title-short":"PANDA","type":"article-journal","URL":"https://www.frontiersin.org/articles/10.3389/fnhum.2013.00042/full","volume":"7"},
  {"id":"daiLearningCombinatorialOptimization2017","abstract":"The design of good heuristics or approximation algorithms for NP-hard combinatorial optimization problems often requires significant specialized knowledge and trial-and-error. Can we automate this challenging, tedious process, and learn the algorithms instead? In many real-world applications, it is typically the case that the same optimization problem is solved again and again on a regular basis, maintaining the same problem structure but differing in the data. This provides an opportunity for learning heuristic algorithms that exploit the structure of such recurring problems. In this paper, we propose a unique combination of reinforcement learning and graph embedding to address this challenge. The learned greedy policy behaves like a meta-algorithm that incrementally constructs a solution, and the action is determined by the output of a graph embedding network capturing the current state of the solution. We show that our framework can be applied to a diverse range of optimization problems over graphs, and learns effective algorithms for the Minimum Vertex Cover, Maximum Cut and Traveling Salesman problems.","accessed":{"date-parts":[[2019,2,1]]},"author":[{"family":"Dai","given":"Hanjun"},{"family":"Khalil","given":"Elias B."},{"family":"Zhang","given":"Yuyu"},{"family":"Dilkina","given":"Bistra"},{"family":"Song","given":"Le"}],"citation-key":"daiLearningCombinatorialOptimization2017","container-title":"arXiv:1704.01665 [cs, stat]","issued":{"date-parts":[[2017,4,5]]},"source":"arXiv.org","title":"Learning Combinatorial Optimization Algorithms over Graphs","type":"article-journal","URL":"http://arxiv.org/abs/1704.01665"},
  {"id":"darrousSimultaneousEstimationBidirectional2021","abstract":"Mendelian Randomisation (MR) is an increasingly popular approach that estimates the causal effect of risk factors on complex human traits. While it has seen several extensions that relax its basic assumptions, most suffer from two major limitations; their under-exploitation of genome-wide markers, and sensitivity to the presence of a heritable confounder of the exposure-outcome relationship. To overcome these limitations, we propose a Latent Heritable Confounder MR (LHC-MR) method applicable to association summary statistics, which estimates bi-directional causal effects, direct heritabilities, and confounder effects while accounting for sample overlap. We demonstrate that LHC-MR outperforms several existing MR methods in a wide range of simulation settings and apply it to summary statistics of 13 complex traits. Besides several concordant results with other MR methods, LHC-MR unravels new mechanisms (how disease diagnosis might lead to improved lifestyle) and reveals new causal effects (e.g. HDL cholesterol being protective against high systolic blood pressure), hidden from standard MR methods due to a heritable confounder of opposite effect direction.","accessed":{"date-parts":[[2022,10,20]]},"author":[{"family":"Darrous","given":"Liza"},{"family":"Mounier","given":"Ninon"},{"family":"Kutalik","given":"Zoltán"}],"citation-key":"darrousSimultaneousEstimationBidirectional2021","container-title":"Nature Communications","container-title-short":"Nat Commun","DOI":"10.1038/s41467-021-26970-w","ISSN":"2041-1723","issue":"1","issued":{"date-parts":[[2021,12,14]]},"language":"en","license":"2021 The Author(s)","number":"1","page":"7274","publisher":"Nature Publishing Group","source":"www.nature.com","title":"Simultaneous estimation of bi-directional causal effects and heritable confounding from GWAS summary statistics","type":"article-journal","URL":"https://www.nature.com/articles/s41467-021-26970-w","volume":"12"},
  {"id":"dimartinoAutismBrainImaging2014","abstract":"Autism spectrum disorders (ASDs) represent a formidable challenge for psychiatry and neuroscience because of their high prevalence, lifelong nature, complexity and substantial heterogeneity. Facing these obstacles requires large-scale multidisciplinary efforts. Although the field of genetics has pioneered data sharing for these reasons, neuroimaging had not kept pace. In response, we introduce the Autism Brain Imaging Data Exchange (ABIDE)—a grassroots consortium aggregating and openly sharing 1112 existing resting-state functional magnetic resonance imaging (R-fMRI) data sets with corresponding structural MRI and phenotypic information from 539 individuals with ASDs and 573 age-matched typical controls (TCs; 7–64 years) (http://fcon_1000.projects.nitrc.org/indi/abide/). Here, we present this resource and demonstrate its suitability for advancing knowledge of ASD neurobiology based on analyses of 360 male subjects with ASDs and 403 male age-matched TCs. We focused on whole-brain intrinsic functional connectivity and also survey a range of voxel-wise measures of intrinsic functional brain architecture. Whole-brain analyses reconciled seemingly disparate themes of both hypo- and hyperconnectivity in the ASD literature; both were detected, although hypoconnectivity dominated, particularly for corticocortical and interhemispheric functional connectivity. Exploratory analyses using an array of regional metrics of intrinsic brain function converged on common loci of dysfunction in ASDs (mid- and posterior insula and posterior cingulate cortex), and highlighted less commonly explored regions such as the thalamus. The survey of the ABIDE R-fMRI data sets provides unprecedented demonstrations of both replication and novel discovery. By pooling multiple international data sets, ABIDE is expected to accelerate the pace of discovery setting the stage for the next generation of ASD studies.","accessed":{"date-parts":[[2022,9,20]]},"author":[{"family":"Di Martino","given":"A."},{"family":"Yan","given":"C.-G."},{"family":"Li","given":"Q."},{"family":"Denio","given":"E."},{"family":"Castellanos","given":"F. X."},{"family":"Alaerts","given":"K."},{"family":"Anderson","given":"J. S."},{"family":"Assaf","given":"M."},{"family":"Bookheimer","given":"S. Y."},{"family":"Dapretto","given":"M."},{"family":"Deen","given":"B."},{"family":"Delmonte","given":"S."},{"family":"Dinstein","given":"I."},{"family":"Ertl-Wagner","given":"B."},{"family":"Fair","given":"D. A."},{"family":"Gallagher","given":"L."},{"family":"Kennedy","given":"D. P."},{"family":"Keown","given":"C. L."},{"family":"Keysers","given":"C."},{"family":"Lainhart","given":"J. E."},{"family":"Lord","given":"C."},{"family":"Luna","given":"B."},{"family":"Menon","given":"V."},{"family":"Minshew","given":"N. J."},{"family":"Monk","given":"C. S."},{"family":"Mueller","given":"S."},{"family":"Müller","given":"R.-A."},{"family":"Nebel","given":"M. B."},{"family":"Nigg","given":"J. T."},{"family":"O'Hearn","given":"K."},{"family":"Pelphrey","given":"K. A."},{"family":"Peltier","given":"S. J."},{"family":"Rudie","given":"J. D."},{"family":"Sunaert","given":"S."},{"family":"Thioux","given":"M."},{"family":"Tyszka","given":"J. M."},{"family":"Uddin","given":"L. Q."},{"family":"Verhoeven","given":"J. S."},{"family":"Wenderoth","given":"N."},{"family":"Wiggins","given":"J. L."},{"family":"Mostofsky","given":"S. H."},{"family":"Milham","given":"M. P."}],"citation-key":"dimartinoAutismBrainImaging2014","container-title":"Molecular Psychiatry","container-title-short":"Mol Psychiatry","DOI":"10.1038/mp.2013.78","ISSN":"1476-5578","issue":"6","issued":{"date-parts":[[2014,6]]},"language":"en","license":"2014 Macmillan Publishers Limited","number":"6","page":"659-667","publisher":"Nature Publishing Group","source":"www.nature.com","title":"The autism brain imaging data exchange: towards a large-scale evaluation of the intrinsic brain architecture in autism","title-short":"The autism brain imaging data exchange","type":"article-journal","URL":"https://www.nature.com/articles/mp201378","volume":"19"},
  {"id":"dimartinoEnhancingStudiesConnectome2017","abstract":"The second iteration of the Autism Brain Imaging Data Exchange (ABIDE II) aims to enhance the scope of brain connectomics research in Autism Spectrum Disorder (ASD). Consistent with the initial ABIDE effort (ABIDE I), that released 1112 datasets in 2012, this new multisite open-data resource is an aggregate of resting state functional magnetic resonance imaging (MRI) and corresponding structural MRI and phenotypic datasets. ABIDE II includes datasets from an additional 487 individuals with ASD and 557 controls previously collected across 16 international institutions. The combination of ABIDE I and ABIDE II provides investigators with 2156 unique cross-sectional datasets allowing selection of samples for discovery and/or replication. This sample size can also facilitate the identification of neurobiological subgroups, as well as preliminary examinations of sex differences in ASD. Additionally, ABIDE II includes a range of psychiatric variables to inform our understanding of the neural correlates of co-occurring psychopathology; 284 diffusion imaging datasets are also included. It is anticipated that these enhancements will contribute to unraveling key sources of ASD heterogeneity.","accessed":{"date-parts":[[2022,9,20]]},"author":[{"family":"Di Martino","given":"Adriana"},{"family":"O’Connor","given":"David"},{"family":"Chen","given":"Bosi"},{"family":"Alaerts","given":"Kaat"},{"family":"Anderson","given":"Jeffrey S."},{"family":"Assaf","given":"Michal"},{"family":"Balsters","given":"Joshua H."},{"family":"Baxter","given":"Leslie"},{"family":"Beggiato","given":"Anita"},{"family":"Bernaerts","given":"Sylvie"},{"family":"Blanken","given":"Laura M. E."},{"family":"Bookheimer","given":"Susan Y."},{"family":"Braden","given":"B. Blair"},{"family":"Byrge","given":"Lisa"},{"family":"Castellanos","given":"F. Xavier"},{"family":"Dapretto","given":"Mirella"},{"family":"Delorme","given":"Richard"},{"family":"Fair","given":"Damien A."},{"family":"Fishman","given":"Inna"},{"family":"Fitzgerald","given":"Jacqueline"},{"family":"Gallagher","given":"Louise"},{"family":"Keehn","given":"R. Joanne Jao"},{"family":"Kennedy","given":"Daniel P."},{"family":"Lainhart","given":"Janet E."},{"family":"Luna","given":"Beatriz"},{"family":"Mostofsky","given":"Stewart H."},{"family":"Müller","given":"Ralph-Axel"},{"family":"Nebel","given":"Mary Beth"},{"family":"Nigg","given":"Joel T."},{"family":"O’Hearn","given":"Kirsten"},{"family":"Solomon","given":"Marjorie"},{"family":"Toro","given":"Roberto"},{"family":"Vaidya","given":"Chandan J."},{"family":"Wenderoth","given":"Nicole"},{"family":"White","given":"Tonya"},{"family":"Craddock","given":"R. Cameron"},{"family":"Lord","given":"Catherine"},{"family":"Leventhal","given":"Bennett"},{"family":"Milham","given":"Michael P."}],"citation-key":"dimartinoEnhancingStudiesConnectome2017","container-title":"Scientific Data","container-title-short":"Sci Data","DOI":"10.1038/sdata.2017.10","ISSN":"2052-4463","issue":"1","issued":{"date-parts":[[2017,3,14]]},"language":"en","license":"2017 The Author(s)","number":"1","page":"170010","publisher":"Nature Publishing Group","source":"www.nature.com","title":"Enhancing studies of the connectome in autism using the autism brain imaging data exchange II","type":"article-journal","URL":"https://www.nature.com/articles/sdata201710","volume":"4"},
  {"id":"dravesBiasVarianceTradeoffsJoint2020","abstract":"Latent position models and their corresponding estimation procedures offer a statistically principled paradigm for multiple network inference by translating multiple network analysis problems to familiar task in multivariate statistics. Latent position estimation is a fundamental task in this framework yet most work focus only on unbiased estimation procedures. We consider the ramifications of utilizing biased latent position estimates in subsequent statistical analysis in exchange for sizable variance reductions in finite networks. We establish an explicit bias-variance tradeoff for latent position estimates produced by the omnibus embedding of arXiv:1705.09355 in the presence of heterogeneous network data. We reveal an analytic bias expression, derive a uniform concentration bound on the residual term, and prove a central limit theorem characterizing the distributional properties of these estimates. These explicit bias and variance expressions enable us to show that the omnibus embedding estimates are often preferable to comparable estimators with respect to mean square error, state sufficient conditions for exact recovery in community detection tasks, and develop a test statistic to determine whether two graphs share the same set of latent positions. These results are demonstrated in several experimental settings where community detection algorithms and hypothesis testing procedures utilizing the biased latent position estimates are competitive, and oftentimes preferable, to unbiased latent position estimates.","accessed":{"date-parts":[[2020,5,11]]},"author":[{"family":"Draves","given":"Benjamin"},{"family":"Sussman","given":"Daniel L."}],"citation-key":"dravesBiasVarianceTradeoffsJoint2020","container-title":"arXiv:2005.02511 [math, stat]","issued":{"date-parts":[[2020,5,5]]},"source":"arXiv.org","title":"Bias-Variance Tradeoffs in Joint Spectral Embeddings","type":"article-journal","URL":"http://arxiv.org/abs/2005.02511"},
  {"id":"efronLargeScaleSimultaneousHypothesis2004","abstract":"Current scientific techniques in genomics and image processing routinely produce hypothesis testing problems with hundreds or thousands of cases to consider simultaneously. This poses new difficulties for the statistician, but also opens new opportunities. In particular, it allows empirical estimation of an appropriate null hypothesis. The empirical null may be considerably more dispersed than the usual theoretical null distribution that would be used for any one case considered separately. An empirical Bayes analysis plan for this situation is developed, using a local version of the false discovery rate to examine the inference issues. Two genomics problems are used as examples to show the importance of correctly choosing the null hypothesis.","accessed":{"date-parts":[[2022,10,10]]},"author":[{"family":"Efron","given":"Bradley"}],"citation-key":"efronLargeScaleSimultaneousHypothesis2004","container-title":"Journal of the American Statistical Association","DOI":"10.1198/016214504000000089","ISSN":"0162-1459","issue":"465","issued":{"date-parts":[[2004,3,1]]},"note":"_eprint: https://doi.org/10.1198/016214504000000089","page":"96-104","publisher":"Taylor & Francis","source":"Taylor and Francis+NEJM","title":"Large-Scale Simultaneous Hypothesis Testing","type":"article-journal","URL":"https://doi.org/10.1198/016214504000000089","volume":"99"},
  {"id":"epastoSingleEmbeddingEnough2019","abstract":"Recent interest in graph embedding methods has focused on learning a single representation for each node in the graph. But can nodes really be best described by a single vector representation? In this work, we propose a method for learning multiple representations of the nodes in a graph (e.g., the users of a social network). Based on a principled decomposition of the ego-network, each representation encodes the role of the node in a different local community in which the nodes participate. These representations allow for improved reconstruction of the nuanced relationships that occur in the graph – a phenomenon that we illustrate through state-of-the-art results on link prediction tasks on a variety of graphs, reducing the error by up to 90%. In addition, we show that these embeddings allow for effective visual analysis of the learned community structure.","author":[{"family":"Epasto","given":"Alessandro"},{"family":"Perozzi","given":"Bryan"}],"citation-key":"epastoSingleEmbeddingEnough2019","issued":{"date-parts":[[2019]]},"language":"en","page":"11","source":"Zotero","title":"Is a Single Embedding Enough? Learning Node Representations that Capture Multiple Social Contexts","type":"article-journal"},
  {"id":"fanDistributedEstimationPrincipal2017","abstract":"Principal component analysis (PCA) is fundamental to statistical machine learning. It extracts latent principal factors that contribute to the most variation of the data. When data are stored across multiple machines, however, communication cost can prohibit the computation of PCA in a central location and distributed algorithms for PCA are thus needed. This paper proposes and studies a distributed PCA algorithm: each node machine computes the top $K$ eigenvectors and transmits them to the central server; the central server then aggregates the information from all the node machines and conducts a PCA based on the aggregated information. We investigate the bias and variance for the resulting distributed estimator of the top $K$ eigenvectors. In particular, we show that for distributions with symmetric innovation, the empirical top eigenspaces are unbiased and hence the distributed PCA is \"unbiased\". We derive the rate of convergence for distributed PCA estimators, which depends explicitly on the effective rank of covariance, eigen-gap, and the number of machines. We show that when the number of machines is not unreasonably large, the distributed PCA performs as well as the whole sample PCA, even without full access of whole data. The theoretical results are verified by an extensive simulation study. We also extend our analysis to the heterogeneous case where the population covariance matrices are different across local machines but share similar top eigen-structures.","accessed":{"date-parts":[[2019,2,24]]},"author":[{"family":"Fan","given":"Jianqing"},{"family":"Wang","given":"Dong"},{"family":"Wang","given":"Kaizheng"},{"family":"Zhu","given":"Ziwei"}],"citation-key":"fanDistributedEstimationPrincipal2017","container-title":"arXiv:1702.06488 [math, stat]","issued":{"date-parts":[[2017,2,21]]},"source":"arXiv.org","title":"Distributed Estimation of Principal Eigenspaces","type":"article-journal","URL":"http://arxiv.org/abs/1702.06488"},
  {"id":"galloMovingCausalityAttentiondeficit2016","abstract":"Summary\nAttention-deficit hyperactivity disorder (ADHD) is a neurodevelopmental disorder characterised by developmentally inappropriate levels of inattention and hyperactivity or impulsivity. The heterogeneity of its clinical manifestations and the differential responses to treatment and varied prognoses have long suggested myriad underlying causes. Over the past decade, clinical and basic research efforts have uncovered many behavioural and neurobiological alterations associated with ADHD, from genes to higher order neural networks. Here, we review the neurobiology of ADHD by focusing on neural circuits implicated in the disorder and discuss how abnormalities in circuitry relate to symptom presentation and treatment. We summarise the literature on genetic variants that are potentially related to the development of ADHD, and how these, in turn, might affect circuit function and relevant behaviours. Whether these underlying neurobiological factors are causally related to symptom presentation remains unresolved. Therefore, we assess efforts aimed at disentangling issues of causality, and showcase the shifting research landscape towards endophenotype refinement in clinical and preclinical settings. Furthermore, we review approaches being developed to understand the neurobiological underpinnings of this complex disorder, including the use of animal models, neuromodulation, and pharmacoimaging studies.","accessed":{"date-parts":[[2019,1,25]]},"author":[{"family":"Gallo","given":"Eduardo F"},{"family":"Posner","given":"Jonathan"}],"citation-key":"galloMovingCausalityAttentiondeficit2016","container-title":"The Lancet Psychiatry","container-title-short":"The Lancet Psychiatry","DOI":"10.1016/S2215-0366(16)00096-1","ISSN":"2215-0366","issue":"6","issued":{"date-parts":[[2016,6,1]]},"page":"555-567","source":"ScienceDirect","title":"Moving towards causality in attention-deficit hyperactivity disorder: overview of neural and genetic mechanisms","title-short":"Moving towards causality in attention-deficit hyperactivity disorder","type":"article-journal","URL":"http://www.sciencedirect.com/science/article/pii/S2215036616000961","volume":"3"},
  {"id":"geHeritabilityAnalysisRepeat2017","abstract":"Heritability is a fundamental metric in population genetics. Existing heritability models lump together stable effects (e.g., due to the subject’s unique environment) and transient effects, such as measurement error. This can result in misleading assessments when comparing the heritability of traits that exhibit different levels of reliability. This paper presents a heritability estimation strategy that can account for transient intrasubject variation using repeat measurements. Using the proposed method, we show that the stable components of functional connectivity within and across well-established large-scale brain networks can be considerably heritable. With the explosive expansion of genomics, health informatics, and digital phenotyping technologies, the proposed model will be significant in dissecting the genetic basis of a wide range of informative but noisy phenotypes.Heritability, defined as the proportion of phenotypic variation attributable to genetic variation, provides important information about the genetic basis of a trait. Existing heritability analysis methods do not discriminate between stable effects (e.g., due to the subject’s unique environment) and transient effects, such as measurement error. This can lead to misleading assessments, particularly when comparing the heritability of traits that exhibit different levels of reliability. Here, we present a linear mixed effects model to conduct heritability analyses that explicitly accounts for intrasubject fluctuations (e.g., due to measurement noise or biological transients) using repeat measurements. We apply the proposed strategy to the analysis of resting-state fMRI measurements—a prototypic data modality that exhibits variable levels of test–retest reliability across space. Our results reveal that the stable components of functional connectivity within and across well-established large-scale brain networks can be considerably heritable. Furthermore, we demonstrate that dissociating intra- and intersubject variation can reveal genetic influence on a phenotype that is not fully captured by conventional heritability analyses.","author":[{"family":"Ge","given":"Tian"},{"family":"Holmes","given":"Avram J."},{"family":"Buckner","given":"Randy L."},{"family":"Smoller","given":"Jordan W."},{"family":"Sabuncu","given":"Mert R."}],"citation-key":"geHeritabilityAnalysisRepeat2017","container-title":"Proceedings of the National Academy of Sciences","DOI":"10.1073/pnas.1700765114","ISSN":"0027-8424","issue":"21","issued":{"date-parts":[[2017]]},"page":"5521–5526","title":"Heritability analysis with repeat measurements and its application to resting-state functional connectivity","type":"article-journal","URL":"https://www.pnas.org/content/114/21/5521","volume":"114"},
  {"id":"GeneticEnvironmentalInfluences","accessed":{"date-parts":[[2019,8,9]]},"citation-key":"GeneticEnvironmentalInfluences","title":"Genetic and environmental influences on the size of specific brain regions in midlife: The VETSA MRI study - ScienceDirect","type":"webpage","URL":"https://www.sciencedirect.com/science/article/pii/S1053811909010222?via%3Dihub"},
  {"id":"GeneticEnvironmentalInfluencesa","accessed":{"date-parts":[[2019,10,28]]},"citation-key":"GeneticEnvironmentalInfluencesa","title":"Genetic and Environmental Influences on Neuroimaging Phenotypes: A Meta-Analytical Perspective on Twin Imaging Studies","type":"webpage","URL":"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4291185/"},
  {"id":"gerlachNetworkApproachTopic2018","abstract":"One of the main computational and scientific challenges in the modern age is to extract useful information from unstructured texts. Topic models are one popular machine-learning approach that infers the latent topical structure of a collection of documents. Despite their success—particularly of the most widely used variant called latent Dirichlet allocation (LDA)—and numerous applications in sociology, history, and linguistics, topic models are known to suffer from severe conceptual and practical problems, for example, a lack of justification for the Bayesian priors, discrepancies with statistical properties of real texts, and the inability to properly choose the number of topics. We obtain a fresh view of the problem of identifying topical structures by relating it to the problem of finding communities in complex networks. We achieve this by representing text corpora as bipartite networks of documents and words. By adapting existing community-detection methods (using a stochastic block model (SBM) with nonparametric priors), we obtain a more versatile and principled framework for topic modeling (for example, it automatically detects the number of topics and hierarchically clusters both the words and documents). The analysis of artificial and real corpora demonstrates that our SBM approach leads to better topic models than LDA in terms of statistical model selection. Our work shows how to formally relate methods from community detection and topic modeling, opening the possibility of cross-fertilization between these two fields.\nA new approach to topic models finds topics through community detection in word-document networks.\nA new approach to topic models finds topics through community detection in word-document networks.","accessed":{"date-parts":[[2019,2,15]]},"author":[{"family":"Gerlach","given":"Martin"},{"family":"Peixoto","given":"Tiago P."},{"family":"Altmann","given":"Eduardo G."}],"citation-key":"gerlachNetworkApproachTopic2018","container-title":"Science Advances","DOI":"10.1126/sciadv.aaq1360","ISSN":"2375-2548","issue":"7","issued":{"date-parts":[[2018,7,1]]},"language":"en","license":"Copyright © 2018 The Authors, some rights reserved; exclusive licensee American Association for the Advancement of Science. No claim to original U.S. Government Works. Distributed under a Creative Commons Attribution NonCommercial License 4.0 (CC BY-NC).. This is an open-access article distributed under the terms of the Creative Commons Attribution-NonCommercial license, which permits use, distribution, and reproduction in any medium, so long as the resultant use is not for commercial advantage and provided the original work is properly cited.","page":"eaaq1360","source":"advances.sciencemag.org","title":"A network approach to topic models","type":"article-journal","URL":"http://advances.sciencemag.org/content/4/7/eaaq1360","volume":"4"},
  {"id":"ghoshdastidarPracticalMethodsGraph2018","abstract":"Hypothesis testing for graphs has been an important tool in applied research fields for more than two decades, and still remains a challenging problem as one often needs to draw inference from few replicates of large graphs. Recent studies in statistics and learning theory have provided some theoretical insights about such high-dimensional graph testing problems, but the practicality of the developed theoretical methods remains an open question. In this paper, we consider the problem of two-sample testing of large graphs. We demonstrate the practical merits and limitations of existing theoretical tests and their bootstrapped variants. We also propose two new tests based on asymptotic distributions. We show that these tests are computationally less expensive and, in some cases, more reliable than the existing methods.","accessed":{"date-parts":[[2020,8,6]]},"author":[{"family":"Ghoshdastidar","given":"Debarghya"},{"family":"Luxburg","given":"Ulrike","non-dropping-particle":"von"}],"citation-key":"ghoshdastidarPracticalMethodsGraph2018","container-title":"arXiv:1811.12752 [cs, stat]","issued":{"date-parts":[[2018,11,30]]},"source":"arXiv.org","title":"Practical methods for graph two-sample testing","type":"article-journal","URL":"http://arxiv.org/abs/1811.12752"},
  {"id":"gopalakrishnanDiscoveryMultiLevelNetwork2022","abstract":"A connectome is a map of the structural and/or functional connections in the brain. This information-rich representation has the potential to transform our understanding of the relationship between patterns in brain connectivity and neurological processes, disorders, and diseases. However, existing computational techniques used to analyze connectomes are oftentimes insufficient for interrogating multi-subject connectomics datasets: most current methods are either solely designed to analyze single connectomes, or leverage heuristic graph statistics that are unable to capture the complete topology of connections between brain regions. To enable more rigorous connectomics analysis, we introduce a set of robust and interpretable statistical hypothesis tests motivated by recent theoretical advances in random graph models. These tests facilitate simultaneous analysis of multiple connectomes across different levels of network topology, enabling the robust and reproducible discovery of hierarchical brain structures that vary in relation with phenotypic profiles. In addition to explaining the theoretical foundations and guarantees of our hypothesis tests, we demonstrate their superiority over current state-of-the-art connectomics methods through extensive simulation studies, as well as synthetic and real-data experiments. Using a set of high-resolution connectomes obtained from genetically distinct mouse strains (including the BTBR mouse -- a standard model of autism -- and three behavioral wild-types), we illustrate how our methods can be used to successfully uncover latent information in multi-subject connectomics data and yield valuable insights into the connective correlates of neurological phenotypes. The code necessary to reproduce the analyses, simulations, and figures presented in this work are available in a series of Jupyter Notebooks (https://github.com/neurodata/MCC).","accessed":{"date-parts":[[2022,9,11]]},"author":[{"family":"Gopalakrishnan","given":"Vivek"},{"family":"Chung","given":"Jaewon"},{"family":"Bridgeford","given":"Eric"},{"family":"Pedigo","given":"Benjamin D."},{"family":"Arroyo","given":"Jesús"},{"family":"Upchurch","given":"Lucy"},{"family":"Johnson","given":"G. Allan"},{"family":"Wang","given":"Nian"},{"family":"Park","given":"Youngser"},{"family":"Priebe","given":"Carey E."},{"family":"Vogelstein","given":"Joshua T."}],"citation-key":"gopalakrishnanDiscoveryMultiLevelNetwork2022","issued":{"date-parts":[[2022,4,13]]},"number":"arXiv:2011.14990","publisher":"arXiv","source":"arXiv.org","title":"Discovery of Multi-Level Network Differences Across Populations of Heterogeneous Connectomes","type":"article","URL":"http://arxiv.org/abs/2011.14990"},
  {"id":"grattarolaChangeDetectionGraph2018","abstract":"The space of graphs is often characterised by a non-trivial geometry, which complicates performing inference in practical applications. A common approach is to use embedding techniques to represent graphs as points in a conventional Euclidean space, but non-Euclidean spaces have often been shown to be better suited for embedding graphs. Among these, constant-curvature Riemannian manifolds (CCMs) offer embedding spaces suitable for studying the statistical properties of a graph distribution, as they provide ways to easily compute metric geodesic distances. In this paper, we focus on the problem of detecting changes in a stream of attributed graphs. To this end, we introduce a novel change detection framework based on neural networks and CCMs that takes into account the non-Euclidean nature of graphs. Our contributions in this work are twofold. First, via a novel approach based on adversarial learning, we compute graph embeddings by training an autoencoder to represent graphs on CCMs. Second, we introduce two novel change detection tests operating on CCMs. We perform experiments on synthetic graph streams, and on sequences of functional networks extracted from intracranial EEG data with the aim of predicting the onset of epileptic seizures. Results show that the proposed methods are able to detect even small changes in the graph-generating process, consistently outperforming approaches based on Euclidean embeddings.","accessed":{"date-parts":[[2019,3,10]]},"author":[{"family":"Grattarola","given":"Daniele"},{"family":"Zambon","given":"Daniele"},{"family":"Alippi","given":"Cesare"},{"family":"Livi","given":"Lorenzo"}],"citation-key":"grattarolaChangeDetectionGraph2018","container-title":"arXiv:1805.06299 [cs, stat]","issued":{"date-parts":[[2018,5,16]]},"source":"arXiv.org","title":"Change Detection in Graph Streams by Learning Graph Embeddings on Constant-Curvature Manifolds","type":"article-journal","URL":"http://arxiv.org/abs/1805.06299"},
  {"id":"hagbergExploringNetworkStructure2008","abstract":"NetworkX is a Python language package for exploration and analysis of networks and network algorithms. The core package provides data structures for representing many types of networks, or graphs, including simple graphs, directed graphs, and graphs with parallel edges and self loops. The nodes in NetworkX graphs can be any (hashable) Python object and edges can contain arbitrary data; this flexibility mades NetworkX ideal for representing networks found in many different scientific fields. In addition to the basic data structures many graph algorithms are implemented for calculating network properties and structure measures: shortest paths, betweenness centrality, clustering, and degree distribution and many more. NetworkX can read and write various graph formats for eash exchange with existing data, and provides generators for many classic graphs and popular graph models, such as the Erdoes-Renyi, Small World, and Barabasi-Albert models, are included. The ease-of-use and flexibility of the Python programming language together with connection to the SciPy tools make NetworkX a powerful tool for scientific computations. We discuss some of our recent work studying synchronization of coupled oscillators to demonstrate how NetworkX enables research in the field of computational networks.","accessed":{"date-parts":[[2022,10,5]]},"author":[{"family":"Hagberg","given":"Aric"},{"family":"Swart","given":"Pieter"},{"family":"Schult","given":"Daniel"}],"citation-key":"hagbergExploringNetworkStructure2008","issued":{"date-parts":[[2008,1,1]]},"language":"English","number":"LA-UR-08-05495; LA-UR-08-5495","publisher":"Los Alamos National Lab. (LANL), Los Alamos, NM (United States)","source":"www.osti.gov","title":"Exploring network structure, dynamics, and function using networkx","type":"report","URL":"https://www.osti.gov/biblio/960616"},
  {"id":"hagmannMappingStructuralCore2008","abstract":"Structurally segregated and functionally specialized regions of the human cerebral cortex are interconnected by a dense network of cortico-cortical axonal pathways. By using diffusion spectrum imaging, we noninvasively mapped these pathways within and across cortical hemispheres in individual human participants. An analysis of the resulting large-scale structural brain networks reveals a structural core within posterior medial and parietal cerebral cortex, as well as several distinct temporal and frontal modules. Brain regions within the structural core share high degree, strength, and betweenness centrality, and they constitute connector hubs that link all major structural modules. The structural core contains brain regions that form the posterior components of the human default network. Looking both within and outside of core regions, we observed a substantial correspondence between structural connectivity and resting-state functional connectivity measured in the same participants. The spatial and topological centrality of the core within cortex suggests an important role in functional integration.","accessed":{"date-parts":[[2019,1,28]]},"author":[{"family":"Hagmann","given":"Patric"},{"family":"Cammoun","given":"Leila"},{"family":"Gigandet","given":"Xavier"},{"family":"Meuli","given":"Reto"},{"family":"Honey","given":"Christopher J."},{"family":"Wedeen","given":"Van J."},{"family":"Sporns","given":"Olaf"}],"citation-key":"hagmannMappingStructuralCore2008","container-title":"PLOS Biology","container-title-short":"PLOS Biology","DOI":"10.1371/journal.pbio.0060159","ISSN":"1545-7885","issue":"7","issued":{"date-parts":[[2008,7,1]]},"language":"en","page":"e159","source":"PLoS Journals","title":"Mapping the Structural Core of Human Cerebral Cortex","type":"article-journal","URL":"https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.0060159","volume":"6"},
  {"id":"hamiltonRepresentationLearningGraphs2017","abstract":"Machine learning on graphs is an important and ubiquitous task with applications ranging from drug design to friendship recommendation in social networks. The primary challenge in this domain is finding a way to represent, or encode, graph structure so that it can be easily exploited by machine learning models. Traditionally, machine learning approaches relied on user-defined heuristics to extract features encoding structural information about a graph (e.g., degree statistics or kernel functions). However, recent years have seen a surge in approaches that automatically learn to encode graph structure into low-dimensional embeddings, using techniques based on deep learning and nonlinear dimensionality reduction. Here we provide a conceptual review of key advancements in this area of representation learning on graphs, including matrix factorization-based methods, random-walk based algorithms, and graph neural networks. We review methods to embed individual nodes as well as approaches to embed entire (sub)graphs. In doing so, we develop a unified framework to describe these recent approaches, and we highlight a number of important applications and directions for future work.","accessed":{"date-parts":[[2019,2,1]]},"author":[{"family":"Hamilton","given":"William L."},{"family":"Ying","given":"Rex"},{"family":"Leskovec","given":"Jure"}],"citation-key":"hamiltonRepresentationLearningGraphs2017","container-title":"arXiv:1709.05584 [cs]","issued":{"date-parts":[[2017,9,16]]},"source":"arXiv.org","title":"Representation Learning on Graphs: Methods and Applications","title-short":"Representation Learning on Graphs","type":"article-journal","URL":"http://arxiv.org/abs/1709.05584"},
  {"id":"harrisArrayProgrammingNumPy2020","abstract":"Array programming provides a powerful, compact and expressive syntax for accessing, manipulating and operating on data in vectors, matrices and higher-dimensional arrays. NumPy is the primary array programming library for the Python language. It has an essential role in research analysis pipelines in fields as diverse as physics, chemistry, astronomy, geoscience, biology, psychology, materials science, engineering, finance and economics. For example, in astronomy, NumPy was an important part of the software stack used in the discovery of gravitational waves1 and in the first imaging of a black hole2. Here we review how a few fundamental array concepts lead to a simple and powerful programming paradigm for organizing, exploring and analysing scientific data. NumPy is the foundation upon which the scientific Python ecosystem is constructed. It is so pervasive that several projects, targeting audiences with specialized needs, have developed their own NumPy-like interfaces and array objects. Owing to its central position in the ecosystem, NumPy increasingly acts as an interoperability layer between such array computation libraries and, together with its application programming interface (API), provides a flexible framework to support the next decade of scientific and industrial analysis.","accessed":{"date-parts":[[2022,10,5]]},"author":[{"family":"Harris","given":"Charles R."},{"family":"Millman","given":"K. Jarrod"},{"family":"Walt","given":"Stéfan J.","non-dropping-particle":"van der"},{"family":"Gommers","given":"Ralf"},{"family":"Virtanen","given":"Pauli"},{"family":"Cournapeau","given":"David"},{"family":"Wieser","given":"Eric"},{"family":"Taylor","given":"Julian"},{"family":"Berg","given":"Sebastian"},{"family":"Smith","given":"Nathaniel J."},{"family":"Kern","given":"Robert"},{"family":"Picus","given":"Matti"},{"family":"Hoyer","given":"Stephan"},{"family":"Kerkwijk","given":"Marten H.","non-dropping-particle":"van"},{"family":"Brett","given":"Matthew"},{"family":"Haldane","given":"Allan"},{"family":"Río","given":"Jaime Fernández","non-dropping-particle":"del"},{"family":"Wiebe","given":"Mark"},{"family":"Peterson","given":"Pearu"},{"family":"Gérard-Marchant","given":"Pierre"},{"family":"Sheppard","given":"Kevin"},{"family":"Reddy","given":"Tyler"},{"family":"Weckesser","given":"Warren"},{"family":"Abbasi","given":"Hameer"},{"family":"Gohlke","given":"Christoph"},{"family":"Oliphant","given":"Travis E."}],"citation-key":"harrisArrayProgrammingNumPy2020","container-title":"Nature","DOI":"10.1038/s41586-020-2649-2","ISSN":"1476-4687","issue":"7825","issued":{"date-parts":[[2020,9]]},"language":"en","license":"2020 The Author(s)","number":"7825","page":"357-362","publisher":"Nature Publishing Group","source":"www.nature.com","title":"Array programming with NumPy","type":"article-journal","URL":"https://www.nature.com/articles/s41586-020-2649-2","volume":"585"},
  {"id":"helmLearningRankCombining2020","abstract":"Learning to rank -- producing a ranked list of items specific to a query and with respect to a set of supervisory items -- is a problem of general interest. The setting we consider is one in which no analytic description of what constitutes a good ranking is available. Instead, we have a collection of representations and supervisory information consisting of a (target item, interesting items set) pair. We demonstrate -- analytically, in simulation, and in real data examples -- that learning to rank via combining representations using an integer linear program is effective when the supervision is as light as \"these few items are similar to your item of interest.\" While this nomination task is of general interest, for specificity we present our methodology from the perspective of vertex nomination in graphs. The methodology described herein is model agnostic.","accessed":{"date-parts":[[2020,8,6]]},"author":[{"family":"Helm","given":"Hayden S."},{"family":"Basu","given":"Amitabh"},{"family":"Athreya","given":"Avanti"},{"family":"Park","given":"Youngser"},{"family":"Vogelstein","given":"Joshua T."},{"family":"Winding","given":"Michael"},{"family":"Zlatic","given":"Marta"},{"family":"Cardona","given":"Albert"},{"family":"Bourke","given":"Patrick"},{"family":"Larson","given":"Jonathan"},{"family":"White","given":"Chris"},{"family":"Priebe","given":"Carey E."}],"citation-key":"helmLearningRankCombining2020","container-title":"arXiv:2005.10700 [cs, stat]","issued":{"date-parts":[[2020,5,19]]},"source":"arXiv.org","title":"Learning to rank via combining representations","type":"article-journal","URL":"http://arxiv.org/abs/2005.10700"},
  {"id":"heuvelAberrantFrontalTemporal2010","abstract":"Brain regions are not independent. They are interconnected by white matter tracts, together forming one integrative complex network. The topology of this network is crucial for efficient information integration between brain regions. Here, we demonstrate that schizophrenia involves an aberrant topology of the structural infrastructure of the brain network. Using graph theoretical analysis, complex structural brain networks of 40 schizophrenia patients and 40 human healthy controls were examined. Diffusion tensor imaging was used to reconstruct the white matter connections of the brain network, with the strength of the connections defined as the level of myelination of the tracts as measured through means of magnetization transfer ratio magnetic resonance imaging. Patients displayed a preserved overall small-world network organization, but focusing on specific brain regions and their capacity to communicate with other regions of the brain revealed significantly longer node-specific path lengths (higher L) of frontal and temporal regions, especially of bilateral inferior/superior frontal cortex and temporal pole regions. These findings suggest that schizophrenia impacts global network connectivity of frontal and temporal brain regions. Furthermore, frontal hubs of patients showed a significant reduction of betweenness centrality, suggesting a less central hub role of these regions in the overall network structure. Together, our findings suggest that schizophrenia patients have a less strongly globally integrated structural brain network with a reduced central role for key frontal hubs, resulting in a limited structural capacity to integrate information across brain regions.","accessed":{"date-parts":[[2019,4,24]]},"author":[{"family":"Heuvel","given":"Martijn P.","dropping-particle":"van den"},{"family":"Mandl","given":"René C. W."},{"family":"Stam","given":"Cornelis J."},{"family":"Kahn","given":"René S."},{"family":"Pol","given":"Hilleke E. Hulshoff"}],"citation-key":"heuvelAberrantFrontalTemporal2010","container-title":"Journal of Neuroscience","container-title-short":"J. Neurosci.","DOI":"10.1523/JNEUROSCI.2874-10.2010","ISSN":"0270-6474, 1529-2401","issue":"47","issued":{"date-parts":[[2010,11,24]]},"language":"en","license":"Copyright © 2010 the authors 0270-6474/10/3015915-12$15.00/0","page":"15915-15926","PMID":"21106830","source":"www.jneurosci.org","title":"Aberrant Frontal and Temporal Complex Network Structure in Schizophrenia: A Graph Theoretical Analysis","title-short":"Aberrant Frontal and Temporal Complex Network Structure in Schizophrenia","type":"article-journal","URL":"http://www.jneurosci.org/content/30/47/15915","volume":"30"},
  {"id":"hochbergMultipleComparisonProcedures1987","accessed":{"date-parts":[[2022,10,18]]},"author":[{"family":"Hochberg","given":"Yosef"},{"family":"Tamhane","given":"Ajit C"}],"citation-key":"hochbergMultipleComparisonProcedures1987","ISBN":"978-0-470-31667-2","issued":{"date-parts":[[1987]]},"language":"en","publisher":"John Wiley & Sons, Ltd","source":"Wiley Online Library","title":"Multiple Comparison Procedures","type":"book","URL":"https://onlinelibrary.wiley.com/doi/abs/10.1002/9780470316672.ch1"},
  {"id":"hollandStochasticBlockmodelsFirst1983","abstract":"A stochastic model is proposed for social networks in which the actors in a network are partitioned into subgroups called blocks. The model provides a stochastic generalization of the blockmodel. Estimation techniques are developed for the special case of a single relation social network, with blocks specified a priori. An extension of the model allows for tendencies toward reciprocation of ties beyond those explained by the partition. The extended model provides a one degree-of-freedom test of the model. A numerical example from the social network literature is used to illustrate the methods.","accessed":{"date-parts":[[2020,2,13]]},"author":[{"family":"Holland","given":"Paul W."},{"family":"Laskey","given":"Kathryn Blackmond"},{"family":"Leinhardt","given":"Samuel"}],"citation-key":"hollandStochasticBlockmodelsFirst1983","container-title":"Social Networks","container-title-short":"Social Networks","DOI":"10.1016/0378-8733(83)90021-7","ISSN":"0378-8733","issue":"2","issued":{"date-parts":[[1983,6,1]]},"language":"en","page":"109-137","source":"ScienceDirect","title":"Stochastic blockmodels: First steps","title-short":"Stochastic blockmodels","type":"article-journal","URL":"http://www.sciencedirect.com/science/article/pii/0378873383900217","volume":"5"},
  {"id":"holmSimpleSequentiallyRejective1979","author":[{"family":"Holm","given":"Sture"}],"citation-key":"holmSimpleSequentiallyRejective1979","container-title":"Scandinavian Journal of Statistics","issue":"2","issued":{"date-parts":[[1979]]},"language":"en","page":"65-70","source":"Zotero","title":"A Simple Sequentially Rejective Multiple Test Procedure","type":"article-journal","URL":"http://www.jstor.org/stable/4615733","volume":"6"},
  {"id":"huntenburgLargeScaleGradientsHuman2018","abstract":"Recent advances in mapping cortical areas in the human brain provide a basis for investigating the significance of their spatial arrangement. Here we describe a dominant gradient in cortical features that spans between sensorimotor and transmodal areas. We propose that this gradient constitutes a core organizing axis of the human cerebral cortex, and describe an intrinsic coordinate system on its basis. Studying the cortex with respect to these intrinsic dimensions can inform our understanding of how the spectrum of cortical function emerges from structural constraints.","accessed":{"date-parts":[[2019,6,21]]},"author":[{"family":"Huntenburg","given":"Julia M."},{"family":"Bazin","given":"Pierre-Louis"},{"family":"Margulies","given":"Daniel S."}],"citation-key":"huntenburgLargeScaleGradientsHuman2018","container-title":"Trends in Cognitive Sciences","container-title-short":"Trends in Cognitive Sciences","DOI":"10.1016/j.tics.2017.11.002","ISSN":"1364-6613","issue":"1","issued":{"date-parts":[[2018,1,1]]},"page":"21-31","source":"ScienceDirect","title":"Large-Scale Gradients in Human Cortical Organization","type":"article-journal","URL":"http://www.sciencedirect.com/science/article/pii/S1364661317302401","volume":"22"},
  {"id":"hunterMatplotlib2DGraphics2007","abstract":"Matplotlib is a 2D graphics package used for Python for application development, interactive scripting,and publication-quality image generation across user interfaces and operating systems","author":[{"family":"Hunter","given":"John D."}],"citation-key":"hunterMatplotlib2DGraphics2007","container-title":"Computing in Science & Engineering","DOI":"10.1109/MCSE.2007.55","ISSN":"1558-366X","issue":"3","issued":{"date-parts":[[2007,5]]},"page":"90-95","source":"IEEE Xplore","title":"Matplotlib: A 2D Graphics Environment","title-short":"Matplotlib","type":"article-journal","volume":"9"},
  {"id":"huthNaturalSpeechReveals2016","abstract":"The meaning of language is represented in regions of the cerebral cortex collectively known as the ‘semantic system’. However, little of the semantic system has been mapped comprehensively, and the semantic selectivity of most regions is unknown. Here we systematically map semantic selectivity across the cortex using voxel-wise modelling of functional MRI (fMRI) data collected while subjects listened to hours of narrative stories. We show that the semantic system is organized into intricate patterns that seem to be consistent across individuals. We then use a novel generative model to create a detailed semantic atlas. Our results suggest that most areas within the semantic system represent information about specific semantic domains, or groups of related concepts, and our atlas shows which domains are represented in each area. This study demonstrates that data-driven methods—commonplace in studies of human neuroanatomy and functional connectivity—provide a powerful and efficient means for mapping functional representations in the brain.","accessed":{"date-parts":[[2019,4,30]]},"author":[{"family":"Huth","given":"Alexander G."},{"family":"Heer","given":"Wendy A.","non-dropping-particle":"de"},{"family":"Griffiths","given":"Thomas L."},{"family":"Theunissen","given":"Frédéric E."},{"family":"Gallant","given":"Jack L."}],"citation-key":"huthNaturalSpeechReveals2016","container-title":"Nature","DOI":"10.1038/nature17637","ISSN":"1476-4687","issue":"7600","issued":{"date-parts":[[2016,4]]},"language":"en","license":"2016 Nature Publishing Group","page":"453-458","source":"www.nature.com","title":"Natural speech reveals the semantic maps that tile human cerebral cortex","type":"article-journal","URL":"https://www.nature.com/articles/nature17637","volume":"532"},
  {"id":"jonesMultilayerRandomDot2020","abstract":"We present an extension of the latent position network model known as the generalised random dot product graph to accommodate multiple graphs with a common node structure, based on a matrix representation of the natural third-order tensor created from the adjacency matrices of these graphs. Theoretical results concerning the asymptotic behaviour of the node representations obtained by spectral embedding are established, showing that after the application of a linear transformation these converge uniformly in the Euclidean norm to the latent positions with a Gaussian error. The flexibility of the model is demonstrated through application to the tasks of latent position recovery and two-graph hypothesis testing, in which it performs favourably compared to existing models. Empirical improvements in link prediction over single graph embeddings are exhibited in a cyber-security example.","accessed":{"date-parts":[[2020,8,6]]},"author":[{"family":"Jones","given":"Andrew"},{"family":"Rubin-Delanchy","given":"Patrick"}],"citation-key":"jonesMultilayerRandomDot2020","container-title":"arXiv:2007.10455 [cs, stat]","issued":{"date-parts":[[2020,7,20]]},"source":"arXiv.org","title":"The multilayer random dot product graph","type":"article-journal","URL":"http://arxiv.org/abs/2007.10455"},
  {"id":"juriaanmReviewMinoltaAuto2019","abstract":"The Minolta Auto Rokkor-PF 55 mm f/2 is a small legacy standard lens from the sixties. Does this lens still deserve a spot in a modern camera bag?","accessed":{"date-parts":[[2020,6,9]]},"author":[{"literal":"JuriaanM"}],"citation-key":"juriaanmReviewMinoltaAuto2019","container-title":"phillipreeve.net","issued":{"date-parts":[[2019,6,20]]},"language":"en-US","section":"Uncategorized","source":"phillipreeve.net","title":"Review: Minolta Auto Rokkor-PF 55 mm f/2","title-short":"Review","type":"post-weblog","URL":"https://phillipreeve.net/blog/review-minolta-auto-rokkor-pf-55-mm-f-2/"},
  {"id":"khaliliaPredictingDiseaseRisks2011","abstract":"We present a method utilizing Healthcare Cost and Utilization Project (HCUP) dataset for predicting disease risk of individuals based on their medical diagnosis history. The presented methodology may be incorporated in a variety of applications such as risk management, tailored health communication and decision support systems in healthcare.","accessed":{"date-parts":[[2019,2,21]]},"author":[{"family":"Khalilia","given":"Mohammed"},{"family":"Chakraborty","given":"Sounak"},{"family":"Popescu","given":"Mihail"}],"citation-key":"khaliliaPredictingDiseaseRisks2011","container-title":"BMC Medical Informatics and Decision Making","container-title-short":"BMC Medical Informatics and Decision Making","DOI":"10.1186/1472-6947-11-51","ISSN":"1472-6947","issue":"1","issued":{"date-parts":[[2011,7,29]]},"page":"51","source":"BioMed Central","title":"Predicting disease risks from highly imbalanced data using random forest","type":"article-journal","URL":"https://doi.org/10.1186/1472-6947-11-51","volume":"11"},
  {"id":"kiarHighThroughputPipelineIdentifies2018","abstract":"<p>Modern scientific discovery depends on collecting large heterogeneous datasets with many sources of variability, and applying domain-specific pipelines from which one can draw insight or clinical utility. For example, macroscale connectomics studies require complex pipelines to process raw functional or diffusion data and estimate connectomes. Individual studies tend to customize pipelines to their needs, raising concerns about their reproducibility, and adding to a longer list of factors that may differ across studies (including sampling, experimental design, and data acquisition protocols), resulting in failures to replicate. Mitigating these issues requires multi-study datasets and the development of pipelines that can be applied across them. We developed NeuroData9s MRI to Graphs (NDMG) pipeline using several functional and diffusion studies, including the Consortium for Reliability and Reproducibility, to estimate connectomes. Without any manual intervention or parameter tuning, NDMG ran on 25 different studies (~6,000 scans) from 15 sites, with each scan resulting in a biologically plausible connectome (as assessed by multiple quality assurance metrics at each processing stage). For each study, the connectomes from NDMG are more similar within than across individuals, indicating that NDMG is preserving biological variability. Moreover, the connectomes exhibit near perfect consistency for certain connectional properties across every scan, individual, study, site, and modality; these include stronger ipsilateral than contralateral connections and stronger homotopic than heterotopic connections. Yet, the magnitude of the differences varied across individuals and studies - much more so when pooling data across sites, even after controlling for study, site, and basic demographic variables (i.e., age, sex, and ethnicity). This indicates that other experimental variables (possibly those not measured or reported) are contributing to this variability, which if not accounted for can limit the value of aggregate datasets, as well as expectations regarding the accuracy of findings and likelihood of replication. We, therefore, provide a set of principles to guide the development of pipelines capable of pooling data across studies while maintaining biological variability and minimizing measurement error. This open science approach provides us with an opportunity to understand and eventually mitigate spurious results for both past and future studies.</p>","accessed":{"date-parts":[[2019,1,25]]},"author":[{"family":"Kiar","given":"Gregory"},{"family":"Bridgeford","given":"Eric"},{"family":"Roncal","given":"Will Gray"},{"family":"Reproducibliity (CoRR)","given":"Consortium for Reliability","dropping-particle":"and"},{"family":"Chandrashekhar","given":"Vikram"},{"family":"Mhembere","given":"Disa"},{"family":"Ryman","given":"Sephira"},{"family":"Zuo","given":"Xi-Nian"},{"family":"Marguiles","given":"Daniel S."},{"family":"Craddock","given":"R. Cameron"},{"family":"Priebe","given":"Carey E."},{"family":"Jung","given":"Rex"},{"family":"Calhoun","given":"Vince"},{"family":"Caffo","given":"Brian"},{"family":"Burns","given":"Randal"},{"family":"Milham","given":"Michael P."},{"family":"Vogelstein","given":"Joshua"}],"citation-key":"kiarHighThroughputPipelineIdentifies2018","container-title":"bioRxiv","DOI":"10.1101/188706","issued":{"date-parts":[[2018,4,24]]},"language":"en","license":"© 2018, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/","page":"188706","source":"www.biorxiv.org","title":"A High-Throughput Pipeline Identifies Robust Connectomes But Troublesome Variability","type":"article-journal","URL":"https://www.biorxiv.org/content/10.1101/188706v6"},
  {"id":"kochunovHeritabilityFractionalAnisotropy2015","abstract":"The degree to which genetic factors influence brain connectivity is beginning to be understood. Large-scale efforts are underway to map the profile of genetic effects in various brain regions. The NIH-funded Human Connectome Project (HCP) is providing data valuable for analyzing the degree of genetic influence underlying brain connectivity revealed by state-of-the-art neuroimaging methods. We calculated the heritability of the fractional anisotropy (FA) measure derived from diffusion tensor imaging (DTI) reconstruction in 481 HCP subjects (194/287 M/F) consisting of 57/60 pairs of mono- and dizygotic twins, and 246 siblings. FA measurements were derived using (Enhancing NeuroImaging Genetics through Meta-Analysis) ENIGMA DTI protocols and heritability estimates were calculated using the SOLAR-Eclipse imaging genetic analysis package. We compared heritability estimates derived from HCP data to those publicly available through the ENIGMA-DTI consortium, which were pooled together from five-family based studies across the US, Europe, and Australia. FA measurements from the HCP cohort for eleven major white matter tracts were highly heritable (h2=0.53–0.90, p<10−5), and were significantly correlated with the joint-analytical estimates from the ENIGMA cohort on the tract and voxel-wise levels. The similarity in regional heritability suggests that the additive genetic contribution to white matter microstructure is consistent across populations and imaging acquisition parameters. It also suggests that the overarching genetic influence provides an opportunity to define a common genetic search space for future gene-discovery studies. Uniquely, the measurements of additive genetic contribution performed in this study can be repeated using online genetic analysis tools provided by the HCP ConnectomeDB web application.","accessed":{"date-parts":[[2019,6,28]]},"author":[{"family":"Kochunov","given":"Peter"},{"family":"Jahanshad","given":"Neda"},{"family":"Marcus","given":"Daniel"},{"family":"Winkler","given":"Anderson"},{"family":"Sprooten","given":"Emma"},{"family":"Nichols","given":"Thomas E."},{"family":"Wright","given":"Susan N."},{"family":"Hong","given":"L. Elliot"},{"family":"Patel","given":"Binish"},{"family":"Behrens","given":"Timothy"},{"family":"Jbabdi","given":"Saad"},{"family":"Andersson","given":"Jesper"},{"family":"Lenglet","given":"Christophe"},{"family":"Yacoub","given":"Essa"},{"family":"Moeller","given":"Steen"},{"family":"Auerbach","given":"Eddie"},{"family":"Ugurbil","given":"Kamil"},{"family":"Sotiropoulos","given":"Stamatios N."},{"family":"Brouwer","given":"Rachel M."},{"family":"Landman","given":"Bennett"},{"family":"Lemaitre","given":"Hervé"},{"family":"Braber","given":"Anouk","non-dropping-particle":"den"},{"family":"Zwiers","given":"Marcel P."},{"family":"Ritchie","given":"Stuart"},{"family":"Hulzen","given":"Kimm","non-dropping-particle":"van"},{"family":"Almasy","given":"Laura"},{"family":"Curran","given":"Joanne"},{"family":"deZubicaray","given":"Greig I."},{"family":"Duggirala","given":"Ravi"},{"family":"Fox","given":"Peter"},{"family":"Martin","given":"Nicholas G."},{"family":"McMahon","given":"Katie L."},{"family":"Mitchell","given":"Braxton"},{"family":"Olvera","given":"Rene L."},{"family":"Peterson","given":"Charles"},{"family":"Starr","given":"John"},{"family":"Sussmann","given":"Jessika"},{"family":"Wardlaw","given":"Joanna"},{"family":"Wright","given":"Margie"},{"family":"Boomsma","given":"Dorret I."},{"family":"Kahn","given":"Rene"},{"family":"Geus","given":"Eco J. C.","non-dropping-particle":"de"},{"family":"Williamson","given":"Douglas E."},{"family":"Hariri","given":"Ahmad"},{"family":"Ent","given":"Dennis","non-dropping-particle":"van 't"},{"family":"Bastin","given":"Mark E."},{"family":"McIntosh","given":"Andrew"},{"family":"Deary","given":"Ian J."},{"family":"Hulshoff pol","given":"Hilleke E."},{"family":"Blangero","given":"John"},{"family":"Thompson","given":"Paul M."},{"family":"Glahn","given":"David C."},{"family":"Van Essen","given":"David C."}],"citation-key":"kochunovHeritabilityFractionalAnisotropy2015","container-title":"NeuroImage","container-title-short":"NeuroImage","DOI":"10.1016/j.neuroimage.2015.02.050","ISSN":"1053-8119","issued":{"date-parts":[[2015,5,1]]},"page":"300-311","source":"ScienceDirect","title":"Heritability of fractional anisotropy in human white matter: A comparison of Human Connectome Project and ENIGMA-DTI data","title-short":"Heritability of fractional anisotropy in human white matter","type":"article-journal","URL":"http://www.sciencedirect.com/science/article/pii/S1053811915001512","volume":"111"},
  {"id":"kohlerSocialScienceMethods2011","abstract":"Twins have been extensively used in economics, sociology and behavioral genetics to investigate the role of genetic endowments on a broad range of social, demographic and economic outcomes. However, the focus in these literatures has been distinct: the economic literature has been primarily concerned with the need to control for unobserved endowments—including as an important subset, genetic endowments—in analyses that attempt to establish the impact of one variable, often schooling, on a variety of economic, demographic and health outcomes. Behavioral genetic analyses have mostly been concerned with decomposing the variation in the outcomes of interest into genetic, shared environmental and non-shared environmental components, with recent multivariate analyses investigating the contributions of genes and the environment to the correlation and causation between variables. Despite the fact that twins studies and the recognition of the role of endowments are central to both of these literatures, they have mostly evolved independently. In this paper we develop formally the relationship between the economic and behavioral genetic approaches to the analyses of twins, and we develop an integrative approach that combines the identification of causal effects, which dominates the economic literature, with the decomposition of variances and covariances into genetic and environmental factors that is the primary goal of behavioral genetic approaches. We apply this integrative ACE-β approach to an illustrative investigation of the impact of schooling on several demographic outcomes such as fertility and nuptiality and health.","accessed":{"date-parts":[[2019,3,8]]},"author":[{"family":"Kohler","given":"Hans-Peter"},{"family":"Behrman","given":"Jere R."},{"family":"Schnittker","given":"Jason"}],"citation-key":"kohlerSocialScienceMethods2011","container-title":"Biodemography and social biology","container-title-short":"Biodemography Soc Biol","ISSN":"1948-5565","issue":"1","issued":{"date-parts":[[2011]]},"page":"88-141","PMCID":"PMC3158495","PMID":"21845929","source":"PubMed Central","title":"Social Science Methods for Twins Data: Integrating Causality, Endowments and Heritability","title-short":"Social Science Methods for Twins Data","type":"article-journal","URL":"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3158495/","volume":"57"},
  {"id":"levinCentralLimitTheorem2017","abstract":"Performing statistical inference on collections of graphs is of import to many disciplines. Graph embedding, in which the vertices of a graph are mapped to vectors in a low-dimensional Euclidean space, has gained traction as a basic tool for graph analysis. Here we describe an omnibus embedding in which multiple graphs on the same vertex set are jointly embedded into a single space with a distinct representation for each graph. We prove a central limit theorem for this omnibus embedding and show that simultaneous embedding into a common space allows comparison of graphs without the need to perform pairwise alignments of graph embeddings. Experimental results demonstrate that the omnibus embedding improves upon existing methods. (Please note: per the D3M workshop organizers' request, this is an extended abstract of a paper that has already been posted to arXiv at https://arxiv.org/abs/1705.09355).","author":[{"family":"Levin","given":"K."},{"family":"Athreya","given":"A."},{"family":"Tang","given":"M."},{"family":"Lyzinski","given":"V."},{"family":"Priebe","given":"C. E."}],"citation-key":"levinCentralLimitTheorem2017","container-title":"2017 IEEE International Conference on Data Mining Workshops (ICDMW)","DOI":"10.1109/ICDMW.2017.132","event-title":"2017 IEEE International Conference on Data Mining Workshops (ICDMW)","issued":{"date-parts":[[2017,11]]},"page":"964-967","source":"IEEE Xplore","title":"A Central Limit Theorem for an Omnibus Embedding of Multiple Random Dot Product Graphs","type":"paper-conference"},
  {"id":"levinCentralLimitTheorem2019","abstract":"Performing statistical analyses on collections of graphs is of import to many disciplines, but principled, scalable methods for multi-sample graph inference are few. Here we describe an \"omnibus\" embedding in which multiple graphs on the same vertex set are jointly embedded into a single space with a distinct representation for each graph. We prove a central limit theorem for this embedding and demonstrate how it streamlines graph comparison, obviating the need for pairwise subspace alignments. The omnibus embedding achieves near-optimal inference accuracy when graphs arise from a common distribution and yet retains discriminatory power as a test procedure for the comparison of different graphs. Moreover, this joint embedding and the accompanying central limit theorem are important for answering multiscale graph inference questions, such as the identification of specific subgraphs or vertices responsible for similarity or difference across networks. We illustrate this with a pair of analyses of connectome data derived from dMRI and fMRI scans of human subjects. In particular, we show that this embedding allows the identification of specific brain regions associated with population-level differences. Finally, we sketch how the omnibus embedding can be used to address pressing open problems, both theoretical and practical, in multisample graph inference.","accessed":{"date-parts":[[2020,5,20]]},"author":[{"family":"Levin","given":"Keith"},{"family":"Athreya","given":"Avanti"},{"family":"Tang","given":"Minh"},{"family":"Lyzinski","given":"Vince"},{"family":"Park","given":"Youngser"},{"family":"Priebe","given":"Carey E."}],"citation-key":"levinCentralLimitTheorem2019","container-title":"arXiv:1705.09355 [stat]","issued":{"date-parts":[[2019,6,25]]},"source":"arXiv.org","title":"A central limit theorem for an omnibus embedding of multiple random graphs and implications for multiscale network inference","type":"article-journal","URL":"http://arxiv.org/abs/1705.09355"},
  {"id":"liemPredictingBrainageMultimodal2017","abstract":"The disparity between the chronological age of an individual and their brain-age measured based on biological information has the potential to offer clinically relevant biomarkers of neurological syndromes that emerge late in the lifespan. While prior brain-age prediction studies have relied exclusively on either structural or functional brain data, here we investigate how multimodal brain-imaging data improves age prediction. Using cortical anatomy and whole-brain functional connectivity on a large adult lifespan sample (N=2354, age 19–82), we found that multimodal data improves brain-based age prediction, resulting in a mean absolute prediction error of 4.29 years. Furthermore, we found that the discrepancy between predicted age and chronological age captures cognitive impairment. Importantly, the brain-age measure was robust to confounding effects: head motion did not drive brain-based age prediction and our models generalized reasonably to an independent dataset acquired at a different site (N=475). Generalization performance was increased by training models on a larger and more heterogeneous dataset. The robustness of multimodal brain-age prediction to confounds, generalizability across sites, and sensitivity to clinically-relevant impairments, suggests promising future application to the early prediction of neurocognitive disorders.","accessed":{"date-parts":[[2020,2,4]]},"author":[{"family":"Liem","given":"Franziskus"},{"family":"Varoquaux","given":"Gaël"},{"family":"Kynast","given":"Jana"},{"family":"Beyer","given":"Frauke"},{"family":"Kharabian Masouleh","given":"Shahrzad"},{"family":"Huntenburg","given":"Julia M."},{"family":"Lampe","given":"Leonie"},{"family":"Rahim","given":"Mehdi"},{"family":"Abraham","given":"Alexandre"},{"family":"Craddock","given":"R. Cameron"},{"family":"Riedel-Heller","given":"Steffi"},{"family":"Luck","given":"Tobias"},{"family":"Loeffler","given":"Markus"},{"family":"Schroeter","given":"Matthias L."},{"family":"Witte","given":"Anja Veronica"},{"family":"Villringer","given":"Arno"},{"family":"Margulies","given":"Daniel S."}],"citation-key":"liemPredictingBrainageMultimodal2017","container-title":"NeuroImage","container-title-short":"NeuroImage","DOI":"10.1016/j.neuroimage.2016.11.005","ISSN":"1053-8119","issued":{"date-parts":[[2017,3,1]]},"language":"en","page":"179-188","source":"ScienceDirect","title":"Predicting brain-age from multimodal imaging data captures cognitive impairment","type":"article-journal","URL":"http://www.sciencedirect.com/science/article/pii/S1053811916306103","volume":"148"},
  {"id":"lunagomezModelingNetworkPopulations2019","abstract":"This article introduces a new class of models for multiple networks. The core idea is to parametrize a distribution on labelled graphs in terms of a Frech\\'{e}t mean graph (which depends on a user-specified choice of metric or graph distance) and a parameter that controls the concentration of this distribution about its mean. Entropy is the natural parameter for such control, varying from a point mass concentrated on the Frech\\'{e}t mean itself to a uniform distribution over all graphs on a given vertex set. We provide a hierarchical Bayesian approach for exploiting this construction, along with straightforward strategies for sampling from the resultant posterior distribution. We conclude by demonstrating the efficacy of our approach via simulation studies and a multiple-network data analysis example drawn from systems biology.","accessed":{"date-parts":[[2019,6,12]]},"author":[{"family":"Lunagómez","given":"Simón"},{"family":"Olhede","given":"Sofia C."},{"family":"Wolfe","given":"Patrick J."}],"citation-key":"lunagomezModelingNetworkPopulations2019","container-title":"arXiv:1904.07367 [stat]","issued":{"date-parts":[[2019,4,15]]},"source":"arXiv.org","title":"Modeling Network Populations via Graph Distances","type":"article-journal","URL":"http://arxiv.org/abs/1904.07367"},
  {"id":"lyzinskiPerfectClusteringStochastic2015","abstract":"Vertex clustering in a stochastic blockmodel graph has wide applicability and has been the subject of extensive research. In thispaper, we provide a short proof that the adjacency spectral embedding can be used to obtain perfect clustering for the stochastic blockmodel and the degree-corrected stochastic blockmodel. We also show an analogous result for the more general random dot product graph model.","accessed":{"date-parts":[[2020,3,9]]},"author":[{"family":"Lyzinski","given":"Vince"},{"family":"Sussman","given":"Daniel"},{"family":"Tang","given":"Minh"},{"family":"Athreya","given":"Avanti"},{"family":"Priebe","given":"Carey"}],"citation-key":"lyzinskiPerfectClusteringStochastic2015","container-title":"arXiv:1310.0532 [stat]","issued":{"date-parts":[[2015,1,15]]},"source":"arXiv.org","title":"Perfect Clustering for Stochastic Blockmodel Graphs via Adjacency Spectral Embedding","type":"article-journal","URL":"http://arxiv.org/abs/1310.0532"},
  {"id":"madhyasthaGeodesicLearningUnsupervised2019","abstract":"Geodesic distance is the shortest path between two points in a Riemannian manifold. Manifold learning algorithms, such as Isomap, seek to learn a manifold that preserves geodesic distances. However, such methods operate on the ambient dimensionality, and are therefore fragile to noise dimensions. We developed an unsupervised random forest method (URerF) to approximately learn geodesic distances in linear and nonlinear manifolds with noise. URerF operates on low-dimensional sparse linear combinations of features, rather than the full observed dimensionality. To choose the optimal split in a computationally efficient fashion, we developed a fast Bayesian Information Criterion statistic for Gaussian mixture models. We introduce geodesic precision-recall curves which quantify performance relative to the true latent manifold. Empirical results on simulated and real data demonstrate that URerF is robust to high-dimensional noise, where as other methods, such as Isomap, UMAP, and FLANN, quickly deteriorate in such settings. In particular, URerF is able to estimate geodesic distances on a real connectome dataset better than other approaches.","accessed":{"date-parts":[[2020,3,23]]},"author":[{"family":"Madhyastha","given":"Meghana"},{"family":"Li","given":"Percy"},{"family":"Browne","given":"James"},{"family":"Strnadova-Neeley","given":"Veronika"},{"family":"Priebe","given":"Carey E."},{"family":"Burns","given":"Randal"},{"family":"Vogelstein","given":"Joshua T."}],"citation-key":"madhyasthaGeodesicLearningUnsupervised2019","container-title":"arXiv:1907.02844 [cs, stat]","issued":{"date-parts":[[2019,7,5]]},"source":"arXiv.org","title":"Geodesic Learning via Unsupervised Decision Forests","type":"article-journal","URL":"http://arxiv.org/abs/1907.02844"},
  {"id":"maier-heinChallengeMappingHuman2017","abstract":"Though tractography is widely used, it has not been systematically validated. Here, authors report results from 20 groups showing that many tractography algorithms produce both valid and invalid bundles.","accessed":{"date-parts":[[2019,2,26]]},"author":[{"family":"Maier-Hein","given":"Klaus H."},{"family":"Neher","given":"Peter F."},{"family":"Houde","given":"Jean-Christophe"},{"family":"Côté","given":"Marc-Alexandre"},{"family":"Garyfallidis","given":"Eleftherios"},{"family":"Zhong","given":"Jidan"},{"family":"Chamberland","given":"Maxime"},{"family":"Yeh","given":"Fang-Cheng"},{"family":"Lin","given":"Ying-Chia"},{"family":"Ji","given":"Qing"},{"family":"Reddick","given":"Wilburn E."},{"family":"Glass","given":"John O."},{"family":"Chen","given":"David Qixiang"},{"family":"Feng","given":"Yuanjing"},{"family":"Gao","given":"Chengfeng"},{"family":"Wu","given":"Ye"},{"family":"Ma","given":"Jieyan"},{"family":"Renjie","given":"H."},{"family":"Li","given":"Qiang"},{"family":"Westin","given":"Carl-Fredrik"},{"family":"Deslauriers-Gauthier","given":"Samuel"},{"family":"González","given":"J. Omar Ocegueda"},{"family":"Paquette","given":"Michael"},{"family":"St-Jean","given":"Samuel"},{"family":"Girard","given":"Gabriel"},{"family":"Rheault","given":"François"},{"family":"Sidhu","given":"Jasmeen"},{"family":"Tax","given":"Chantal M. W."},{"family":"Guo","given":"Fenghua"},{"family":"Mesri","given":"Hamed Y."},{"family":"Dávid","given":"Szabolcs"},{"family":"Froeling","given":"Martijn"},{"family":"Heemskerk","given":"Anneriet M."},{"family":"Leemans","given":"Alexander"},{"family":"Boré","given":"Arnaud"},{"family":"Pinsard","given":"Basile"},{"family":"Bedetti","given":"Christophe"},{"family":"Desrosiers","given":"Matthieu"},{"family":"Brambati","given":"Simona"},{"family":"Doyon","given":"Julien"},{"family":"Sarica","given":"Alessia"},{"family":"Vasta","given":"Roberta"},{"family":"Cerasa","given":"Antonio"},{"family":"Quattrone","given":"Aldo"},{"family":"Yeatman","given":"Jason"},{"family":"Khan","given":"Ali R."},{"family":"Hodges","given":"Wes"},{"family":"Alexander","given":"Simon"},{"family":"Romascano","given":"David"},{"family":"Barakovic","given":"Muhamed"},{"family":"Auría","given":"Anna"},{"family":"Esteban","given":"Oscar"},{"family":"Lemkaddem","given":"Alia"},{"family":"Thiran","given":"Jean-Philippe"},{"family":"Cetingul","given":"H. Ertan"},{"family":"Odry","given":"Benjamin L."},{"family":"Mailhe","given":"Boris"},{"family":"Nadar","given":"Mariappan S."},{"family":"Pizzagalli","given":"Fabrizio"},{"family":"Prasad","given":"Gautam"},{"family":"Villalon-Reina","given":"Julio E."},{"family":"Galvis","given":"Justin"},{"family":"Thompson","given":"Paul M."},{"family":"Requejo","given":"Francisco De Santiago"},{"family":"Laguna","given":"Pedro Luque"},{"family":"Lacerda","given":"Luis Miguel"},{"family":"Barrett","given":"Rachel"},{"family":"Dell’Acqua","given":"Flavio"},{"family":"Catani","given":"Marco"},{"family":"Petit","given":"Laurent"},{"family":"Caruyer","given":"Emmanuel"},{"family":"Daducci","given":"Alessandro"},{"family":"Dyrby","given":"Tim B."},{"family":"Holland-Letz","given":"Tim"},{"family":"Hilgetag","given":"Claus C."},{"family":"Stieltjes","given":"Bram"},{"family":"Descoteaux","given":"Maxime"}],"citation-key":"maier-heinChallengeMappingHuman2017","container-title":"Nature Communications","DOI":"10.1038/s41467-017-01285-x","ISSN":"2041-1723","issue":"1","issued":{"date-parts":[[2017,11,7]]},"language":"En","license":"2017 The Author(s)","page":"1349","source":"www.nature.com","title":"The challenge of mapping the human connectome based on diffusion tractography","type":"article-journal","URL":"https://www.nature.com/articles/s41467-017-01285-x","volume":"8"},
  {"id":"markatouDistanceBasedStatisticalInference2021","abstract":"Statistical distances, divergences, and similar quantities have an extensive history and play an important role in the statistical and related scientific literature. This role shows up in estimation, where we often use estimators based on minimizing a distance. Distances also play a prominent role in hypothesis testing and in model selection. We review the statistical properties of distances that are often used in scientific work, present their properties, and show how they compare to each other. We discuss an approximation framework for model-based inference using statistical distances. Emphasis is placed on identifying in what sense and which statistical distances can be interpreted as loss functions and used for model assessment. We review a special class of distances, the class of quadratic distances, connect it with the classical goodness-of-fit paradigm, and demonstrate its use in the problem of assessing model fit. These methods can be used in analyzing very large samples.","accessed":{"date-parts":[[2022,10,5]]},"author":[{"family":"Markatou","given":"Marianthi"},{"family":"Karlis","given":"Dimitrios"},{"family":"Ding","given":"Yuxin"}],"citation-key":"markatouDistanceBasedStatisticalInference2021","container-title":"Annual Review of Statistics and Its Application","DOI":"10.1146/annurev-statistics-031219-041228","issue":"1","issued":{"date-parts":[[2021]]},"note":"_eprint: https://doi.org/10.1146/annurev-statistics-031219-041228","page":"301-327","source":"Annual Reviews","title":"Distance-Based Statistical Inference","type":"article-journal","URL":"https://doi.org/10.1146/annurev-statistics-031219-041228","volume":"8"},
  {"id":"mckinneyPandasFoundationalPython2011","abstract":"In this paper we will discuss pandas, a Python library of rich data structures and tools for working with structured data sets common to statistics, ﬁnance, social sciences, and many other ﬁelds. The library provides integrated, intuitive routines for performing common data manipulations and analysis on such data sets. It aims to be the foundational layer for the future of statistical computing in Python. It serves as a strong complement to the existing scientiﬁc Python stack while implementing and improving upon the kinds of data manipulation tools found in other statistical programming languages such as R. In addition to detailing its design and features of pandas, we will discuss future avenues of work and growth opportunities for statistics and data analysis applications in the Python language.","author":[{"family":"McKinney","given":"Wes"}],"citation-key":"mckinneyPandasFoundationalPython2011","container-title":"Python for high performance and scientific computing","issue":"9","issued":{"date-parts":[[2011]]},"language":"en","page":"1–9","publisher":"Seattle","source":"Zotero","title":"pandas: a Foundational Python Library for Data Analysis and Statistics","type":"article-journal","volume":"14"},
  {"id":"mesulamSensationCognition1998","accessed":{"date-parts":[[2019,4,30]]},"author":[{"family":"Mesulam","given":"M."}],"citation-key":"mesulamSensationCognition1998","container-title":"Brain","DOI":"10.1093/brain/121.6.1013","ISSN":"14602156","issue":"6","issued":{"date-parts":[[1998,6,1]]},"language":"en","page":"1013-1052","source":"Crossref","title":"From sensation to cognition","type":"article-journal","URL":"https://academic.oup.com/brain/article-lookup/doi/10.1093/brain/121.6.1013","volume":"121"},
  {"id":"mhembereComputingScalableMultivariate2013","abstract":"Graphs are quickly emerging as a leading abstraction for the representation of data. One important application domain originates from an emerging discipline called “connectomics”. Connectomics studies the brain as a graph; vertices correspond to neurons (or collections thereof) and edges correspond to structural or functional connections between them. To explore the variability of connectomes-to address both basic science questions regarding the structure of the brain, and medical health questions about psychiatry and neurology-one can study the topological properties of these brain-graphs. We define multivariate glocal graph invariants: these are features of the graph that capture various local and global topological properties of the graphs. We show that the collection of features can collectively be computed via a combination of daisy-chaining, sparse matrix representation and computations, and efficient approximations. Our custom open-source Python package serves as a back-end to a Web-service that we have created to enable researchers to upload graphs, and download the corresponding invariants in a number of different formats. Moreover, we built this package to support distributed processing on multicore machines. This is therefore an enabling technology for network science, lowering the barrier of entry by providing tools to biologists and analysts who otherwise lack these capabilities. As a demonstration, we run our code on 120 brain-graphs, each with approximately 16M vertices and up to 90M edges.","author":[{"family":"Mhembere","given":"Disa"},{"family":"Gray Roncal","given":"William"},{"family":"Sussman","given":"Daniel"},{"family":"Priebe","given":"Carey E."},{"family":"Jung","given":"Rex"},{"family":"Ryman","given":"Sephira"},{"family":"Vogelstein","given":"R. Jacob"},{"family":"Vogelstein","given":"Joshua T."},{"family":"Burns","given":"Randal"}],"citation-key":"mhembereComputingScalableMultivariate2013","container-title":"2013 IEEE Global Conference on Signal and Information Processing","DOI":"10.1109/GlobalSIP.2013.6736874","event-title":"2013 IEEE Global Conference on Signal and Information Processing","issued":{"date-parts":[[2013,12]]},"page":"297-300","source":"IEEE Xplore","title":"Computing scalable multivariate glocal invariants of large (brain-) graphs","type":"paper-conference"},
  {"id":"micchelliUniversalKernels2006","abstract":"In this paper we investigate conditions on the features of a continuous kernel so that it may approximate an arbitrary continuous target function uniformly on any compact subset of the input space. A number of concrete examples are given of kernels with this universal approximating property.","accessed":{"date-parts":[[2019,2,22]]},"author":[{"family":"Micchelli","given":"Charles A."},{"family":"Xu","given":"Yuesheng"},{"family":"Zhang","given":"Haizhang"}],"citation-key":"micchelliUniversalKernels2006","container-title":"J. Mach. Learn. Res.","ISSN":"1532-4435","issued":{"date-parts":[[2006,12]]},"page":"2651–2667","source":"ACM Digital Library","title":"Universal Kernels","type":"article-journal","URL":"http://dl.acm.org/citation.cfm?id=1248547.1248642","volume":"7"},
  {"id":"micheloyannisGraphbasedNetworkAnalysis2012","abstract":"Over the last few years, many studies have been published using modern network analysis of the brain. Researchers and practical doctors alike should understand this method and its results on the brain evaluation at rest, during activation and in brain disease. The studies are noninvasive and usually performed with elecroencephalographic, magnetoencephalographic, magnetic resonance imaging and diffusion tensor imaging brain recordings. Different tools for analysis have been developed, although the methods are in their early stages. The results of these analyses are of special value. Studies of these tools in schizophrenia are important because widespread and local network disturbances can be evaluated by assessing integration, segregation and several structural and functional properties. With the help of network analyses, the main findings in schizophrenia are lower optimum network organization, less efficiently wired networks, less local clustering, less hierarchical organization and signs of disconnection. There are only about twenty five relevant papers on the subject today. Only a few years of study of these methods have produced interesting results and it appears promising that the development of these methods will present important knowledge for both the preclinical signs of schizophrenia and the methods’ therapeutic effects.","accessed":{"date-parts":[[2019,4,24]]},"author":[{"family":"Micheloyannis","given":"Sifis"}],"citation-key":"micheloyannisGraphbasedNetworkAnalysis2012","container-title":"World Journal of Psychiatry","container-title-short":"World J Psychiatry","DOI":"10.5498/wjp.v2.i1.1","ISSN":"2220-3206","issue":"1","issued":{"date-parts":[[2012,2,22]]},"page":"1-12","PMCID":"PMC3782171","PMID":"24175163","source":"PubMed Central","title":"Graph-based network analysis in schizophrenia","type":"article-journal","URL":"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3782171/","volume":"2"},
  {"id":"mirakhorliGraphBasedMethodAnomaly2019","abstract":"Functional neuroimaging techniques using resting-state functional MRI\n(rs-fMRI) have accelerated progress in brain disorders and dysfunction studies.\nSince, there are the slight differences between healthy and disorder brains,\ninvestigation in the complex topology of human brain functional networks is\ndifficult and complicated task with the growth of evaluation criteria.\nRecently, graph theory and deep learning applications have spread widely to\nunderstanding human cognitive functions that are linked to gene expression and\nrelated distributed spatial patterns. Irregular graph analysis has been widely\napplied in many brain recognition domains, these applications might involve\nboth node-centric and graph-centric tasks. In this paper, we discuss about\nindividual Variational Autoencoder and Graph Convolutional Network (GCN) for\nthe region of interest identification areas of brain which do not have normal\nconnection when apply certain tasks. Here, we identified a framework of Graph\nAuto-Encoder (GAE) with hyper sphere distributer for functional data analysis\nin brain imaging studies that is underlying non-Euclidean structure, in\nlearning of strong rigid graphs among large scale data. In addition, we\ndistinguish the possible mode correlations in abnormal brain connections.\nKeywords: Functional brain networks, Graph theory, Generative Models,\nresting-state fMRI, VAE&GAN.","accessed":{"date-parts":[[2019,4,25]]},"author":[{"family":"Mirakhorli","given":"Jalal"},{"family":"Mirakhorli","given":"Mojgan"}],"citation-key":"mirakhorliGraphBasedMethodAnomaly2019","issued":{"date-parts":[[2019,4,15]]},"language":"en","source":"arxiv.org","title":"Graph-Based Method for Anomaly Detection in Functional Brain Network using Variational Autoencoder","type":"article-journal","URL":"https://arxiv.org/abs/1904.07163v3"},
  {"id":"miranda-dominguezHeritabilityHumanConnectome2018","abstract":"Recent progress in resting-state neuroimaging demonstrates that the brain exhibits highly individualized patterns of functional connectivity—a “connectotype.” How these individualized patterns may be constrained by environment and genetics is unknown. Here we ask whether the connectotype is familial and heritable. Using a novel approach to estimate familiality via a machine-learning framework, we analyzed resting-state fMRI scans from two well-characterized samples of child and adult siblings. First we show that individual connectotypes were reliably identified even several years after the initial scanning timepoint. Familial relationships between participants, such as siblings versus those who are unrelated, were also accurately characterized. The connectotype demonstrated substantial heritability driven by high-order systems including the fronto-parietal, dorsal attention, ventral attention, cingulo-opercular, and default systems. This work suggests that shared genetics and environment contribute toward producing complex, individualized patterns of distributed brain activity, rather than constraining local aspects of function. These insights offer new strategies for characterizing individual aberrations in brain function and evaluating heritability of brain networks., By using machine learning and two independent datasets, this report shows that the brain’s individualized functional connectome or connectotype is familial and heritable. First we expand previous findings showing that by using a model-based approach to characterize functional connectivity, we can reliably identify and track individual brain signatures—a functional “fingerprint” or “connectotype” for the human brain—in both children and adults. Such signatures can also be used to characterize familial and heritable patterns of brain connectivity, even using limited data. Most heritable systems include the fronto-parietal, dorsal attention, ventral attention, cingulo-opercular, and default systems. Our proposed approach offers new strategies for characterizing normative development as well as altered patterns of brain connectivity and assists in characterizing the associations between genetic and epigenetic factors with brain function.","accessed":{"date-parts":[[2019,1,25]]},"author":[{"family":"Miranda-Dominguez","given":"Oscar"},{"family":"Feczko","given":"Eric"},{"family":"Grayson","given":"David S."},{"family":"Walum","given":"Hasse"},{"family":"Nigg","given":"Joel T."},{"family":"Fair","given":"Damien A."}],"citation-key":"miranda-dominguezHeritabilityHumanConnectome2018","container-title":"Network Neuroscience (Cambridge, Mass.)","container-title-short":"Netw Neurosci","DOI":"10.1162/netn_a_00029","ISSN":"2472-1751","issue":"2","issued":{"date-parts":[[2018,6,1]]},"page":"175-199","PMCID":"PMC6130446","PMID":"30215032","source":"PubMed Central","title":"Heritability of the human connectome: A connectotyping study","title-short":"Heritability of the human connectome","type":"article-journal","URL":"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6130446/","volume":"2"},
  {"id":"muIdentifyingUnobservedHeterogeneity2020","abstract":"Both observed and unobserved vertex heterogeneity can influence block structure in graphs. To assess these effects on block recovery, we present a comparative analysis of two model-based spectral algorithms for clustering vertices in stochastic blockmodel graphs with vertex covariates. The first algorithm directly estimates the induced block assignments by investigating the estimated block connectivity probability matrix including the vertex covariate effect. The second algorithm estimates the vertex covariate effect and then estimates the induced block assignments after accounting for this effect. We employ Chernoff information to analytically compare the algorithms' performance and derive the Chernoff ratio formula for some special models of interest. Analytic results and simulations suggest that, in general, the second algorithm is preferred: we can better estimate the induced block assignments by first estimating the vertex covariate effect. In addition, real data experiments on a diffusion MRI connectome data set indicate that the second algorithm has the advantages of revealing underlying block structure and taking observed vertex heterogeneity into account in real applications. Our findings emphasize the importance of distinguishing between observed and unobserved factors that can affect block structure in graphs.","accessed":{"date-parts":[[2020,8,6]]},"author":[{"family":"Mu","given":"Cong"},{"family":"Mele","given":"Angelo"},{"family":"Hao","given":"Lingxin"},{"family":"Cape","given":"Joshua"},{"family":"Athreya","given":"Avanti"},{"family":"Priebe","given":"Carey E."}],"citation-key":"muIdentifyingUnobservedHeterogeneity2020","container-title":"arXiv:2007.02156 [cs, math, stat]","issued":{"date-parts":[[2020,7,4]]},"source":"arXiv.org","title":"On identifying unobserved heterogeneity in stochastic blockmodel graphs with vertex covariates","type":"article-journal","URL":"http://arxiv.org/abs/2007.02156"},
  {"id":"nathNormsInfiniteDimensional","abstract":"It is well known that on a ﬁnite dimensional linear space, any two norms are always equivalent. But, is the converse also true? That is if all norms on a linear space X are equivalent, then is X necessarily ﬁnite dimensional? In this article, we try to ﬁnd the answer to this question.","author":[{"family":"Nath","given":"Bhagya Jyoti"}],"citation-key":"nathNormsInfiniteDimensional","language":"en","page":"6","source":"Zotero","title":"Norms on Inﬁnite Dimensional Space","type":"article-journal"},
  {"id":"ozakiUsingNonNormalSEM2011","abstract":"One of the biggest problems in classical twin studies is that it cannot estimate additive genetic (A), non-additive genetic (D), shared environmental (C), and non-shared environmental (E) effects, simultaneously, because the model, referred to as the ACDE model, has negative degrees of freedom when using Structural Equation Modeling (SEM). Therefore, instead of the ACDE model, the ACE model or the ADE model is actually used. However, using the ACE or ADE models almost always leads to biased estimates. In the present paper, the univariate ACDE model is developed using non-normal Structural Equation Modeling (nnSEM). In SEM, (1st- and) 2nd-order moments, namely, (means and) covariances are used as information. However, nnSEM uses higher-order moments as well as (1st- and) 2nd-order moments. nnSEM has a number of advantages over SEM. One of which is that nnSEM can specify models that cannot be specified using SEM because of the negative degrees of freedom. Simulation studies have shown that the proposed method can decrease the biases. There are other factors that have possible effects on phenotypes, such as higher-order epistasis. Since the proposed method cannot estimate these effects, further research on developing a more exhaustive model is needed.","accessed":{"date-parts":[[2022,9,5]]},"author":[{"family":"Ozaki","given":"Koken"},{"family":"Toyoda","given":"Hideki"},{"family":"Iwama","given":"Norikazu"},{"family":"Kubo","given":"Saori"},{"family":"Ando","given":"Juko"}],"citation-key":"ozakiUsingNonNormalSEM2011","container-title":"Behavior Genetics","container-title-short":"Behav Genet","DOI":"10.1007/s10519-010-9386-5","ISSN":"1573-3297","issue":"2","issued":{"date-parts":[[2011,3,1]]},"language":"en","page":"329-339","source":"Springer Link","title":"Using Non-Normal SEM to Resolve the ACDE Model in the Classical Twin Design","type":"article-journal","URL":"https://doi.org/10.1007/s10519-010-9386-5","volume":"41"},
  {"id":"pantazisImportanceBeingCorrelated2020","abstract":"Spectral inference on multiple networks is a rapidly-developing subfield of graph statistics. Recent work has demonstrated that joint, or simultaneous, spectral embedding of multiple independent network realizations can deliver more accurate estimation than individual spectral decompositions of those same networks. Little attention has been paid, however, to the network correlation that such joint embedding procedures necessarily induce. In this paper, we present a detailed analysis of induced correlation in a {\\em generalized omnibus} embedding for multiple networks. We show that our embedding procedure is flexible and robust, and, moreover, we prove a central limit theorem for this embedding and explicitly compute the limiting covariance. We examine how this covariance can impact inference in a network time series, and we construct an appropriately calibrated omnibus embedding that can detect changes in real biological networks that previous embedding procedures could not discern. Our analysis confirms that the effect of induced correlation can be both subtle and transformative, with import in theory and practice.","accessed":{"date-parts":[[2020,8,7]]},"author":[{"family":"Pantazis","given":"Konstantinos"},{"family":"Athreya","given":"Avanti"},{"family":"Frost","given":"William N."},{"family":"Hill","given":"Evan S."},{"family":"Lyzinski","given":"Vince"}],"citation-key":"pantazisImportanceBeingCorrelated2020","container-title":"arXiv:2008.00163 [stat]","issued":{"date-parts":[[2020,7,31]]},"source":"arXiv.org","title":"The Importance of Being Correlated: Implications of Dependence in Joint Spectral Inference across Multiple Networks","title-short":"The Importance of Being Correlated","type":"article-journal","URL":"http://arxiv.org/abs/2008.00163"},
  {"id":"pavlovicMultiSubjectStochasticBlockmodels","abstract":"Recently, there has been a renewed interest in the class of Stochastic Blockmodels (SBM) and their applications to multi-subject brain networks. In our most recent work, we have considered an extension of the classical SBM, termed Heterogeneous SBM (Het-SBM), that models subject variability in the cluster-connectivity profiles through the addition of a logistic regression model with subject-specific covariates on the level of each block. Although this model has proved to be useful in both the clustering and inference aspects of multi-subject brain network data, including eshing out differences in connectivity between patients and controls, it does not account for dependencies that may exist within subjects. To overcome this limitation, we propose an extension of Het-SBM, termed Het-Mixed-SBM, in which we model the within-subject dependencies by adding subject- and block-level random intercepts in the embedded logistic regression model. Using synthetic data, we investigate the accuracy of the partitions estimated by our proposed model as well as the validity of inference procedures based on the Wald and permutation tests. Finally, we illustrate the model by analysing the resting-state fMRI networks of 99 healthy volunteers from the Human Connectome Project (HCP) using covariates like age, gender and IQ to explain the clustering patterns observed in the data.","accessed":{"date-parts":[[2020,6,17]]},"author":[{"family":"Pavlović","given":"Dragana M."},{"family":"Guillaume","given":"Bryan R. L."},{"family":"Afyouni","given":"Soroosh"},{"family":"Nichols","given":"Thomas E."}],"citation-key":"pavlovicMultiSubjectStochasticBlockmodels","container-title":"Statistica Neerlandica","DOI":"10.1111/stan.12219","ISSN":"1467-9574","issue":"n/a","language":"en","license":"This article is protected by copyright. All rights reserved.","note":"_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/stan.12219","source":"Wiley Online Library","title":"Multi-Subject Stochastic Blockmodels with Mixed Effects for Adaptive Analysis of Individual Differences in Human Brain Network Cluster Structure","type":"article-journal","URL":"https://onlinelibrary.wiley.com/doi/abs/10.1111/stan.12219","volume":"n/a"},
  {"id":"pavlovicMultiSubjectStochasticBlockmodels2019","abstract":"<p>There is great interest in elucidating the cluster structure of brain networks in terms of modules, blocks or clusters of similar nodes. However, it is currently challenging to handle data on multiple subjects since most of the existing methods are applicable only on a subject-by-subject basis or for analysis of a group average network. The main limitation of per-subject models is that there is no obvious way to combine the results for group comparisons, and of group-averaged models that they do not reflect the variability between subjects. Here, we propose two novel extensions of the classical Stochastic Blockmodel (SBM) that use a mixture model to estimate blocks or clusters of connected nodes, combined with a regression model to capture the effects on cluster structure of individual differences on subject-level covariates. Multi-subject Stochastic Blockmodels (MS-SBM) can flexibly account for between-subject variability in terms of a homogenous or heterogeneous effect on connectivity of covariates such as age or diagnostic status. Using synthetic data, representing a range of block sizes and cluster structures, we investigate the accuracy of the estimated MS-SBM parameters as well as the validity of inference procedures based on Wald, likelihood ratio and Monte Carlo permutation tests. We show that multi-subject SBMs recover the true cluster structure of synthetic networks more accurately and adaptively than standard methods for modular decomposition. Permutation tests of MS-SBM parameters were more robustly valid for statistical inference and Type I error control than tests based on standard asymptotic assumptions. Applied to analysis of multi-subject resting state fMRI networks (13 healthy volunteers; 12 people with schizophrenia; N = 268 brain regions), we show that the Heterogeneous Stochastic Blockmodel estimates \"core-on-modules\" architecture. The intra-block and inter-block connection weights vary between individual participants and can be modelled as a logistic function of subject-level covariates like age or diagnostic status. Multi-subject Stochastic Blockmodels are likely to be useful tools for statistical analysis of individual differences in human brain graphs and other networks whose prior cluster structure needs to be estimated from the data.</p>","accessed":{"date-parts":[[2019,6,21]]},"author":[{"family":"Pavlović","given":"Dragana M."},{"family":"Guillaume","given":"Bryan R. L."},{"family":"Towlson","given":"Emma K."},{"family":"Kuek","given":"Nicole M. Y."},{"family":"Afyouni","given":"Soroosh"},{"family":"Vértes","given":"Petra E."},{"family":"Yeo","given":"Thomas B. T."},{"family":"Bullmore","given":"Edward T."},{"family":"Nichols","given":"Thomas E."}],"citation-key":"pavlovicMultiSubjectStochasticBlockmodels2019","container-title":"bioRxiv","DOI":"10.1101/672071","issued":{"date-parts":[[2019,6,14]]},"language":"en","license":"© 2019, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.","page":"672071","source":"www.biorxiv.org","title":"Multi-Subject Stochastic Blockmodels for Adaptive Analysis of Individual Differences in Human Brain Network Cluster Structure","type":"article-journal","URL":"https://www.biorxiv.org/content/10.1101/672071v1"},
  {"id":"pillowSpatiotemporalCorrelationsVisual2008","accessed":{"date-parts":[[2020,7,23]]},"author":[{"family":"Pillow","given":"Jonathan W."},{"family":"Shlens","given":"Jonathon"},{"family":"Paninski","given":"Liam"},{"family":"Sher","given":"Alexander"},{"family":"Litke","given":"Alan M."},{"family":"Chichilnisky","given":"E. J."},{"family":"Simoncelli","given":"Eero P."}],"citation-key":"pillowSpatiotemporalCorrelationsVisual2008","container-title":"Nature","container-title-short":"Nature","DOI":"10.1038/nature07140","ISSN":"0028-0836, 1476-4687","issue":"7207","issued":{"date-parts":[[2008,8]]},"language":"en","page":"995-999","source":"DOI.org (Crossref)","title":"Spatio-temporal correlations and visual signalling in a complete neuronal population","type":"article-journal","URL":"http://www.nature.com/articles/nature07140","volume":"454"},
  {"id":"posthumaAssociationBrainVolume2002","accessed":{"date-parts":[[2022,9,8]]},"author":[{"family":"Posthuma","given":"Daniëlle"},{"family":"De Geus","given":"Eco J. C."},{"family":"Baaré","given":"Wim F. C."},{"family":"Pol","given":"Hilleke E. Hulshoff"},{"family":"Kahn","given":"René S."},{"family":"Boomsma","given":"Dorret I."}],"citation-key":"posthumaAssociationBrainVolume2002","container-title":"Nature Neuroscience","container-title-short":"Nat Neurosci","DOI":"10.1038/nn0202-83","ISSN":"1546-1726","issue":"2","issued":{"date-parts":[[2002,2]]},"language":"en","license":"2002 Nature Publishing Group","number":"2","page":"83-84","publisher":"Nature Publishing Group","source":"www.nature.com","title":"The association between brain volume and intelligence is of genetic origin","type":"article-journal","URL":"https://www.nature.com/articles/nn0202-83","volume":"5"},
  {"id":"priebeTwoTruthsPhenomenon2018","abstract":"Clustering is concerned with coherently grouping observations without any explicit concept of true groupings. Spectral graph clustering - clustering the vertices of a graph based on their spectral embedding - is commonly approached via K-means (or, more generally, Gaussian mixture model) clustering composed with either Laplacian or Adjacency spectral embedding (LSE or ASE). Recent theoretical results provide new understanding of the problem and solutions, and lead us to a 'Two Truths' LSE vs. ASE spectral graph clustering phenomenon convincingly illustrated here via a diffusion MRI connectome data set: the different embedding methods yield different clustering results, with LSE capturing left hemisphere/right hemisphere affinity structure and ASE capturing gray matter/white matter core-periphery structure.","accessed":{"date-parts":[[2019,1,27]]},"author":[{"family":"Priebe","given":"Carey E."},{"family":"Park","given":"Youngser"},{"family":"Vogelstein","given":"Joshua T."},{"family":"Conroy","given":"John M."},{"family":"Lyzinski","given":"Vince"},{"family":"Tang","given":"Minh"},{"family":"Athreya","given":"Avanti"},{"family":"Cape","given":"Joshua"},{"family":"Bridgeford","given":"Eric"}],"citation-key":"priebeTwoTruthsPhenomenon2018","container-title":"arXiv:1808.07801 [cs, stat]","issued":{"date-parts":[[2018,8,23]]},"source":"arXiv.org","title":"On a 'Two Truths' Phenomenon in Spectral Graph Clustering","type":"article-journal","URL":"http://arxiv.org/abs/1808.07801"},
  {"id":"rosenbergClinesClustersEffect2005","abstract":"Previously, we observed that without using prior information about individual sampling locations, a clustering algorithm applied to multilocus genotypes from worldwide human populations produced genetic clusters largely coincident with major geographic regions. It has been argued, however, that the degree of clustering is diminished by use of samples with greater uniformity in geographic distribution, and that the clusters we identified were a consequence of uneven sampling along genetic clines. Expanding our earlier dataset from 377 to 993 markers, we systematically examine the influence of several study design variables—sample size, number of loci, number of clusters, assumptions about correlations in allele frequencies across populations, and the geographic dispersion of the sample—on the “clusteredness” of individuals. With all other variables held constant, geographic dispersion is seen to have comparatively little effect on the degree of clustering. Examination of the relationship between genetic and geographic distance supports a view in which the clusters arise not as an artifact of the sampling scheme, but from small discontinuous jumps in genetic distance for most population pairs on opposite sides of geographic barriers, in comparison with genetic distance for pairs on the same side. Thus, analysis of the 993-locus dataset corroborates our earlier results: if enough markers are used with a sufficiently large worldwide sample, individuals can be partitioned into genetic clusters that match major geographic subdivisions of the globe, with some individuals from intermediate geographic locations having mixed membership in the clusters that correspond to neighboring regions.","accessed":{"date-parts":[[2020,7,9]]},"author":[{"family":"Rosenberg","given":"Noah A."},{"family":"Mahajan","given":"Saurabh"},{"family":"Ramachandran","given":"Sohini"},{"family":"Zhao","given":"Chengfeng"},{"family":"Pritchard","given":"Jonathan K."},{"family":"Feldman","given":"Marcus W."}],"citation-key":"rosenbergClinesClustersEffect2005","container-title":"PLOS Genetics","container-title-short":"PLOS Genetics","DOI":"10.1371/journal.pgen.0010070","ISSN":"1553-7404","issue":"6","issued":{"date-parts":[[2005,12,9]]},"language":"en","page":"e70","publisher":"Public Library of Science","source":"PLoS Journals","title":"Clines, Clusters, and the Effect of Study Design on the Inference of Human Population Structure","type":"article-journal","URL":"https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.0010070","volume":"1"},
  {"id":"rubin-delanchyStatisticalInterpretationSpectral2017","abstract":"A generalisation of a latent position network model known as the random dot product graph model is considered. The resulting model may be of independent interest because it has the unique property of representing a mixture of connectivity behaviours as the corresponding convex combination in latent space. We show that, whether the normalised Laplacian or adjacency matrix is used, the vector representations of nodes obtained by spectral embedding provide strongly consistent latent position estimates with asymptotically Gaussian error. Direct methodological consequences follow from the observation that the well-known mixed membership and standard stochastic block models are special cases where the latent positions live respectively inside or on the vertices of a simplex. Estimation via spectral embedding can therefore be achieved by respectively estimating this simplicial support, or fitting a Gaussian mixture model. In the latter case, the use of $K$-means, as has been previously recommended, is suboptimal and for identifiability reasons unsound. Empirical improvements in link prediction, as well as the potential to uncover much richer latent structure (than available under the mixed membership or standard stochastic block models) are demonstrated in a cyber-security example.","accessed":{"date-parts":[[2019,2,24]]},"author":[{"family":"Rubin-Delanchy","given":"Patrick"},{"family":"Priebe","given":"Carey E."},{"family":"Tang","given":"Minh"},{"family":"Cape","given":"Joshua"}],"citation-key":"rubin-delanchyStatisticalInterpretationSpectral2017","container-title":"arXiv:1709.05506 [cs, stat]","issued":{"date-parts":[[2017,9,16]]},"source":"arXiv.org","title":"A statistical interpretation of spectral embedding: the generalised random dot product graph","title-short":"A statistical interpretation of spectral embedding","type":"article-journal","URL":"http://arxiv.org/abs/1709.05506"},
  {"id":"rubin-delanchyStatisticalInterpretationSpectral2020","abstract":"A generalisation of a latent position network model known as the random dot product graph is considered. We show that, whether the normalised Laplacian or adjacency matrix is used, the vector representations of nodes obtained by spectral embedding, using the largest eigenvalues by magnitude, provide strongly consistent latent position estimates with asymptotically Gaussian error, up to indefinite orthogonal transformation. The mixed membership and standard stochastic block models constitute special cases where the latent positions live respectively inside or on the vertices of a simplex, crucially, without assuming the underlying block connectivity probability matrix is positive-definite. Estimation via spectral embedding can therefore be achieved by respectively estimating this simplicial support, or fitting a Gaussian mixture model. In the latter case, the use of $K$-means (with Euclidean distance), as has been previously recommended, is suboptimal and for identifiability reasons unsound. Indeed, Euclidean distances and angles are not preserved under indefinite orthogonal transformation, and we show stochastic block model examples where such quantities vary appreciably. Empirical improvements in link prediction (over the random dot product graph), as well as the potential to uncover richer latent structure (than posited under the mixed membership or standard stochastic block models) are demonstrated in a cyber-security example.","accessed":{"date-parts":[[2020,4,9]]},"author":[{"family":"Rubin-Delanchy","given":"Patrick"},{"family":"Cape","given":"Joshua"},{"family":"Tang","given":"Minh"},{"family":"Priebe","given":"Carey E."}],"citation-key":"rubin-delanchyStatisticalInterpretationSpectral2020","container-title":"arXiv:1709.05506 [cs, stat]","issued":{"date-parts":[[2020,1,8]]},"source":"arXiv.org","title":"A statistical interpretation of spectral embedding: the generalised random dot product graph","title-short":"A statistical interpretation of spectral embedding","type":"article-journal","URL":"http://arxiv.org/abs/1709.05506"},
  {"id":"rubinEvaluationsOptimalDiscovery2016","abstract":"The Optimal Discovery Procedure (ODP) is a method for simultaneous hypothesis testing that attempts to gain power relative to more standard techniques by exploiting multivariate structure [1]. Specializing to the example of testing whether components of a Gaussian mean vector are zero, we compare the power of the ODP to a Bonferroni-style method and to the Benjamini-Hochberg method when the testing procedures aim to respectively control certain Type I error rate measures, such as the expected number of false positives or the false discovery rate. We show through theoretical results, numerical comparisons, and two microarray examples that when the rejection regions for the ODP test statistics are chosen such that the procedure is guaranteed to uniformly control a Type I error rate measure, the technique is generally less powerful than competing methods. We contrast and explain these results in light of previously proven optimality theory for the ODP. We also compare the ordering given by the ODP test statistics to the standard rankings based on sorting univariate p -values from smallest to largest. In the cases we considered the standard ordering was superior, and ODP rankings were adversely impacted by correlation.","accessed":{"date-parts":[[2022,10,19]]},"author":[{"family":"Rubin","given":"Daniel B."}],"citation-key":"rubinEvaluationsOptimalDiscovery2016","container-title":"The International Journal of Biostatistics","DOI":"10.1515/ijb-2015-0027","ISSN":"1557-4679","issue":"1","issued":{"date-parts":[[2016,5,1]]},"language":"en","page":"21-29","publisher":"De Gruyter","source":"www.degruyter.com","title":"Evaluations of the Optimal Discovery Procedure for Multiple Testing","type":"article-journal","URL":"https://www.degruyter.com/document/doi/10.1515/ijb-2015-0027/html","volume":"12"},
  {"id":"satoConstantTimeGraph2019","abstract":"Recent advancements in graph neural networks (GNN) have led to state-of-the-art performance in various applications including chemo-informatics, question answering systems, and recommendation systems, to name a few. However, making these methods scalable to huge graphs such as web-mining remains a challenge. In particular, the existing methods for accelerating GNN are either not theoretically guaranteed in terms of approximation error or require at least linear time computation cost. In this paper, we propose a constant time approximation algorithm for the inference and training of GNN that theoretically guarantees arbitrary precision with arbitrary probability. The key advantage of the proposed algorithm is that the complexity is completely independent of the number of nodes, edges, and neighbors of the input. To the best of our knowledge, this is the first constant time approximation algorithm for GNN with theoretical guarantee. Through experiments using synthetic and real-world datasets, we evaluate our proposed approximation algorithm and show that the algorithm can successfully approximate GNN in constant time.","accessed":{"date-parts":[[2019,1,31]]},"author":[{"family":"Sato","given":"Ryoma"},{"family":"Yamada","given":"Makoto"},{"family":"Kashima","given":"Hisashi"}],"citation-key":"satoConstantTimeGraph2019","container-title":"arXiv:1901.07868 [cs, stat]","issued":{"date-parts":[[2019,1,23]]},"source":"arXiv.org","title":"Constant Time Graph Neural Networks","type":"article-journal","URL":"http://arxiv.org/abs/1901.07868"},
  {"id":"shenHeritabilityGeneticCorrelation2016","abstract":"The aim of this study is to investigate the genetic influence on the cerebral cortex, based on the analyses of heritability and genetic correlation between grey matter (GM) thickness, derived from structural MR images (sMRI), and associated white matter (WM) connections obtained from diffusion MRI (dMRI). We measured on sMRI the cortical thickness (CT) from a large twin imaging cohort using a surface-based approach (N = 308, average age 22.8 ± 2.3 SD). An ACE model was employed to compute the heritability of CT. WM connections were estimated based on probabilistic tractography using fiber orientation distributions (FOD) from dMRI. We then fitted the ACE model to estimate the heritability of CT and FOD peak measures along WM fiber tracts. The WM fiber tracts where genetic influence was detected were mapped onto the cortical surface. Bivariate genetic modeling was performed to estimate the cross-trait genetic correlation between the CT and the FOD-based connectivity of the tracts associated with the cortical regions. We found some cortical regions displaying heritable and genetically correlated GM thickness and WM connectivity, forming networks under stronger genetic influence. Significant heritability and genetic correlations between the CT and WM connectivity were found in regions including the right postcentral gyrus, left posterior cingulate gyrus, right middle temporal gyri, suggesting common genetic factors influencing both GM and WM. Hum Brain Mapp 37:2331–2347, 2016. © 2016 Wiley Periodicals, Inc.","accessed":{"date-parts":[[2019,2,12]]},"author":[{"family":"Shen","given":"Kai-Kai"},{"family":"Doré","given":"Vincent"},{"family":"Rose","given":"Stephen"},{"family":"Fripp","given":"Jurgen"},{"family":"McMahon","given":"Katie L."},{"family":"Zubicaray","given":"Greig I.","dropping-particle":"de"},{"family":"Martin","given":"Nicholas G."},{"family":"Thompson","given":"Paul M."},{"family":"Wright","given":"Margaret J."},{"family":"Salvado","given":"Olivier"}],"citation-key":"shenHeritabilityGeneticCorrelation2016","container-title":"Human Brain Mapping","DOI":"10.1002/hbm.23177","ISSN":"1097-0193","issue":"6","issued":{"date-parts":[[2016]]},"language":"en","license":"© 2016 Wiley Periodicals, Inc.","page":"2331-2347","source":"Wiley Online Library","title":"Heritability and genetic correlation between the cerebral cortex and associated white matter connections","type":"article-journal","URL":"https://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.23177","volume":"37"},
  {"id":"shiradoAssortativeMixingResource2019","abstract":"Resource sharing can impose an economic trade-off: One person acquiring resources may mean that another cannot. However, if individuals value the social process itself that is a feature of economic exchanges, socio-structural manipulations might improve collective welfare. Using a series of online experiments with 600 subjects arrayed into 40 groups, we explore the welfare impact of 2 network interventions. We manipulated the degree assortativity of the groups (who were engaged in resource sharing) while keeping the number of people and connections fixed. Distinctly, we also manipulated the distribution of sharable resources by basing endowments on network degree. We show that structural manipulation (implementing degree assortativity) can facilitate the reciprocity that is achievable in exchanges and consequently affect group-level satisfaction. We also show that individuals are more satisfied with exchanges when each node is unequally endowed with resources that are proportional to the number of potential recipients, which again facilitates reciprocity. Collective welfare in settings involving resource sharing can be enhanced without the need for extra resources.","accessed":{"date-parts":[[2019,10,24]]},"author":[{"family":"Shirado","given":"Hirokazu"},{"family":"Iosifidis","given":"George"},{"family":"Christakis","given":"Nicholas A."}],"citation-key":"shiradoAssortativeMixingResource2019","container-title":"Proceedings of the National Academy of Sciences","container-title-short":"PNAS","DOI":"10.1073/pnas.1911606116","ISSN":"0027-8424, 1091-6490","issued":{"date-parts":[[2019,10,17]]},"language":"en","license":"Copyright © 2019 the Author(s). Published by PNAS.. https://creativecommons.org/licenses/by-nc-nd/4.0/This open access article is distributed under Creative Commons Attribution-NonCommercial-NoDerivatives License 4.0 (CC BY-NC-ND).","page":"201911606","PMID":"31636181","source":"www.pnas.org","title":"Assortative mixing and resource inequality enhance collective welfare in sharing networks","type":"article-journal","URL":"https://www.pnas.org/content/early/2019/10/16/1911606116"},
  {"id":"shumanEmergingFieldSignal2013","abstract":"In applications such as social, energy, transportation, sensor, and neuronal networks, high-dimensional data naturally reside on the vertices of weighted graphs. The emerging field of signal processing on graphs merges algebraic and spectral graph theoretic concepts with computational harmonic analysis to process such signals on graphs. In this tutorial overview, we outline the main challenges of the area, discuss different ways to define graph spectral domains, which are the analogs to the classical frequency domain, and highlight the importance of incorporating the irregular structures of graph data domains when processing signals on graphs. We then review methods to generalize fundamental operations such as filtering, translation, modulation, dilation, and downsampling to the graph setting and survey the localized, multiscale transforms that have been proposed to efficiently extract information from high-dimensional data on graphs. We conclude with a brief discussion of open issues and possible extensions.","author":[{"family":"Shuman","given":"D. I."},{"family":"Narang","given":"S. K."},{"family":"Frossard","given":"P."},{"family":"Ortega","given":"A."},{"family":"Vandergheynst","given":"P."}],"citation-key":"shumanEmergingFieldSignal2013","container-title":"IEEE Signal Processing Magazine","DOI":"10.1109/MSP.2012.2235192","ISSN":"1053-5888","issue":"3","issued":{"date-parts":[[2013,5]]},"page":"83-98","source":"IEEE Xplore","title":"The emerging field of signal processing on graphs: Extending high-dimensional data analysis to networks and other irregular domains","title-short":"The emerging field of signal processing on graphs","type":"article-journal","volume":"30"},
  {"id":"sinzStimulusDomainTransfer2018","abstract":"<p>To better understand the representations in visual cortex, we need to generate better predictions of neural activity in awake animals presented with their ecological input: natural video. Despite recent advances in models for static images, models for predicting responses to natural video are scarce and standard linear-nonlinear models perform poorly. We developed a new deep recurrent network architecture that predicts inferred spiking activity of thousands of mouse V1 neurons simultaneously recorded with two-photon microscopy, while accounting for confounding factors such as the animal9s gaze position and brain state changes related to running state and pupil dilation. Powerful system identification models provide an opportunity to gain insight into cortical functions through in silico experiments that can subsequently be tested in the brain. However, in many cases this approach requires that the model is able to generalize to stimulus statistics that it was not trained on, such as band-limited noise and other parameterized stimuli. We investigated these domain transfer properties in our model and find that our model trained on natural images is able to correctly predict the orientation tuning of neurons in responses to artificial noise stimuli. Finally, we show that we can fully generalize from movies to noise and maintain high predictive performance on both stimulus domains by fine-tuning only the final layer9s weights on a network otherwise trained on natural movies. The converse, however, is not true.</p>","accessed":{"date-parts":[[2019,1,31]]},"author":[{"family":"Sinz","given":"Fabian H."},{"family":"Ecker","given":"Alexander S."},{"family":"Fahey","given":"Paul G."},{"family":"Walker","given":"Edgar Y."},{"family":"Cobos","given":"Erick"},{"family":"Froudarakis","given":"Emmanouil"},{"family":"Yatsenko","given":"Dimitri"},{"family":"Pitkow","given":"Xaq"},{"family":"Reimer","given":"Jacob"},{"family":"Tolias","given":"Andreas S."}],"citation-key":"sinzStimulusDomainTransfer2018","container-title":"bioRxiv","DOI":"10.1101/452672","issued":{"date-parts":[[2018,12,22]]},"language":"en","license":"© 2018, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NoDerivs 4.0 International), CC BY-ND 4.0, as described at http://creativecommons.org/licenses/by-nd/4.0/","page":"452672","source":"www.biorxiv.org","title":"Stimulus domain transfer in recurrent models for large scale cortical population prediction on video","type":"article-journal","URL":"https://www.biorxiv.org/content/10.1101/452672v3"},
  {"id":"sotiropoulosBuildingConnectomesUsing2016","abstract":"Why has diffusion MRI become a principal modality for mapping connectomes in vivo? How do different image acquisition parameters, fiber tracking algorithms and other methodological choices affect connectome estimation? What are the main factors that dictate the success and failure of connectome reconstruction? These are some of the key questions that we aim to address in this review. We provide an overview of the key methods that can be used to estimate the nodes and edges of macroscale connectomes, and we discuss open problems and inherent limitations. We argue that diffusion MRI-based connectome mapping methods are still in their infancy and caution against blind application of deep white matter tractography due to the challenges inherent to connectome reconstruction. We review a number of studies that provide evidence of useful microstructural and network properties that can be extracted in various independent and biologically relevant contexts. Finally, we highlight some of the key deficiencies of current macroscale connectome mapping methodologies and motivate future developments.","accessed":{"date-parts":[[2019,1,25]]},"author":[{"family":"Sotiropoulos","given":"Stamatios N."},{"family":"Zalesky","given":"Andrew"}],"citation-key":"sotiropoulosBuildingConnectomesUsing2016","container-title":"NMR in Biomedicine","DOI":"10.1002/nbm.3752","ISSN":"1099-1492","issue":"0","issued":{"date-parts":[[2016]]},"language":"en","license":"© 2017 The Authors. NMR in Biomedicine published by John Wiley & Sons Ltd.","page":"e3752","source":"Wiley Online Library","title":"Building connectomes using diffusion MRI: why, how and but","title-short":"Building connectomes using diffusion MRI","type":"article-journal","URL":"https://onlinelibrary.wiley.com/doi/abs/10.1002/nbm.3752","volume":"0"},
  {"id":"steinFourierAnalysisIntroduction2003","abstract":"This first volume, a three-part introduction to the subject, is intended for students with a beginning knowledge of mathematical analysis who are motivated to discover the ideas that shape Fourier analysis. It begins with the simple conviction that Fourier arrived at in the early nineteenth century when studying problems in the physical sciences--that an arbitrary function can be written as an infinite sum of the most basic trigonometric functions. The first part implements this idea in terms of notions of convergence and summability of Fourier series, while highlighting applications such as the isoperimetric inequality and equidistribution. The second part deals with the Fourier transform and its applications to classical partial differential equations and the Radon transform; a clear introduction to the subject serves to avoid technical difficulties. The book closes with Fourier theory for finite abelian groups, which is applied to prime numbers in arithmetic progression. In organizing their exposition, the authors have carefully balanced an emphasis on key conceptual insights against the need to provide the technical underpinnings of rigorous analysis. Students of mathematics, physics, engineering and other sciences will find the theory and applications covered in this volume to be of real interest. The Princeton Lectures in Analysis represents a sustained effort to introduce the core areas of mathematical analysis while also illustrating the organic unity between them. Numerous examples and applications throughout its four planned volumes, of which Fourier Analysis is the first, highlight the far-reaching consequences of certain ideas in analysis to other fields of mathematics and a variety of sciences. Stein and Shakarchi move from an introduction addressing Fourier series and integrals to in-depth considerations of complex analysis; measure and integration theory, and Hilbert spaces; and, finally, further topics such as functional analysis, distributions and elements of probability theory.","author":[{"family":"Stein","given":"Elias M."},{"family":"Shakarchi","given":"Rami"}],"citation-key":"steinFourierAnalysisIntroduction2003","ISBN":"978-1-4008-3123-4","issued":{"date-parts":[[2003]]},"language":"en","number-of-pages":"328","publisher":"Princeton University Press","source":"Google Books","title":"Fourier Analysis: An Introduction","title-short":"Fourier Analysis","type":"book"},
  {"id":"strichartzWayAnalysis2000","abstract":"The Way of Analysis gives a thorough account of real analysis in one or several variables, from the construction of the real number system to an introduction of the Lebesgue integral. The text provides proofs of all main results, as well as motivations, examples, applications, exercises, and formal chapter summaries. Additionally, there are three chapters on application of analysis, ordinary differential equations, Fourier series, and curves and surfaces to show how the techniques of analysis are used in concrete settings.","author":[{"family":"Strichartz","given":"Robert S."}],"citation-key":"strichartzWayAnalysis2000","ISBN":"978-0-7637-1497-0","issued":{"date-parts":[[2000]]},"language":"en","number-of-pages":"764","publisher":"Jones & Bartlett Learning","source":"Google Books","title":"The Way of Analysis","type":"book"},
  {"id":"sussmanConsistentAdjacencySpectral2012","abstract":"We present a method to estimate block membership of nodes in a random graph generated by a stochastic blockmodel. We use an embedding procedure motivated by the random dot product graph model, a particular example of the latent position model. The embedding associates each node with a vector; these vectors are clustered via minimization of a square error criterion. We prove that this method is consistent for assigning nodes to blocks, as only a negligible number of nodes will be misassigned. We prove consistency of the method for directed and undirected graphs. The consistent block assignment makes possible consistent parameter estimation for a stochastic blockmodel. We extend the result in the setting where the number of blocks grows slowly with the number of nodes. Our method is also computationally feasible even for very large graphs. We compare our method with Laplacian spectral clustering through analysis of simulated data and a graph derived from Wikipedia documents.","accessed":{"date-parts":[[2020,2,13]]},"author":[{"family":"Sussman","given":"Daniel L."},{"family":"Tang","given":"Minh"},{"family":"Fishkind","given":"Donniell E."},{"family":"Priebe","given":"Carey E."}],"citation-key":"sussmanConsistentAdjacencySpectral2012","container-title":"Journal of the American Statistical Association","container-title-short":"Journal of the American Statistical Association","DOI":"10.1080/01621459.2012.699795","ISSN":"0162-1459","issue":"499","issued":{"date-parts":[[2012,9,1]]},"page":"1119-1128","source":"amstat.tandfonline.com (Atypon)","title":"A Consistent Adjacency Spectral Embedding for Stochastic Blockmodel Graphs","type":"article-journal","URL":"https://amstat.tandfonline.com/doi/full/10.1080/01621459.2012.699795","volume":"107"},
  {"id":"tangNonparametricTwosampleHypothesis2015","abstract":"We consider the problem of testing whether two finite-dimensional random dot product graphs have generating latent positions that are independently drawn from the same distribution, or distributions that are related via scaling or projection. We propose a test statistic that is a kernel-based function of the adjacency spectral embedding for each graph. We obtain a limiting distribution for our test statistic under the null and we show that our test procedure is consistent across a broad range of alternatives.","accessed":{"date-parts":[[2020,5,20]]},"author":[{"family":"Tang","given":"Minh"},{"family":"Athreya","given":"Avanti"},{"family":"Sussman","given":"Daniel L."},{"family":"Lyzinski","given":"Vince"},{"family":"Priebe","given":"Carey E."}],"citation-key":"tangNonparametricTwosampleHypothesis2015","container-title":"arXiv:1409.2344 [math, stat]","issued":{"date-parts":[[2015,11,12]]},"source":"arXiv.org","title":"A nonparametric two-sample hypothesis testing problem for random dot product graphs","type":"article-journal","URL":"http://arxiv.org/abs/1409.2344"},
  {"id":"tangNonparametricTwosampleHypothesis2017","abstract":"We consider the problem of testing whether two independent finite-dimensional random dot product graphs have generating latent positions that are drawn from the same distribution, or distributions that are related via scaling or projection. We propose a test statistic that is a kernel-based function of the estimated latent positions obtained from the adjacency spectral embedding for each graph. We show that our test statistic using the estimated latent positions converges to the test statistic obtained using the true but unknown latent positions and hence that our proposed test procedure is consistent across a broad range of alternatives. Our proof of consistency hinges upon a novel concentration inequality for the suprema of an empirical process in the estimated latent positions setting.","accessed":{"date-parts":[[2019,1,25]]},"author":[{"family":"Tang","given":"Minh"},{"family":"Athreya","given":"Avanti"},{"family":"Sussman","given":"Daniel L."},{"family":"Lyzinski","given":"Vince"},{"family":"Priebe","given":"Carey E."}],"citation-key":"tangNonparametricTwosampleHypothesis2017","container-title":"Bernoulli","container-title-short":"Bernoulli","DOI":"10.3150/15-BEJ789","ISSN":"1350-7265","issue":"3","issued":{"date-parts":[[2017,8]]},"language":"EN","page":"1599-1630","source":"Project Euclid","title":"A nonparametric two-sample hypothesis testing problem for random graphs","type":"article-journal","URL":"https://projecteuclid.org/euclid.bj/1489737619","volume":"23"},
  {"id":"tangUniversallyConsistentVertex2013","abstract":"In this work we show that, using the eigen-decomposition of the adjacency matrix, we can consistently estimate feature maps for latent position graphs with positive definite link function κκ\\kappa, provided that the latent positions are i.i.d. from some distribution FFF. We then consider the exploitation task of vertex classification where the link function κκ\\kappa belongs to the class of universal kernels and class labels are observed for a number of vertices tending to infinity and that the remaining vertices are to be classified. We show that minimization of the empirical φφ\\varphi-risk for some convex surrogate φφ\\varphi of 0–1 loss over a class of linear classifiers with increasing complexities yields a universally consistent classifier, that is, a classification rule with error converging to Bayes optimal for any distribution FFF.","accessed":{"date-parts":[[2019,2,22]]},"author":[{"family":"Tang","given":"Minh"},{"family":"Sussman","given":"Daniel L."},{"family":"Priebe","given":"Carey E."}],"citation-key":"tangUniversallyConsistentVertex2013","container-title":"The Annals of Statistics","container-title-short":"Ann. Statist.","DOI":"10.1214/13-AOS1112","ISSN":"0090-5364, 2168-8966","issue":"3","issued":{"date-parts":[[2013,6]]},"language":"EN","page":"1406-1430","source":"Project Euclid","title":"Universally consistent vertex classification for latent positions graphs","type":"article-journal","URL":"https://projecteuclid.org/euclid.aos/1375362554","volume":"41"},
  {"id":"tomitaRandomProjectionForests2015","abstract":"Ensemble methods---particularly those based on decision trees---have recently demonstrated superior performance in a variety of machine learning settings. We introduce a generalization of many existing decision tree methods called \"Random Projection Forests\" (RPF), which is any decision forest that uses (possibly data dependent and random) linear projections. Using this framework, we introduce a special case, called \"Lumberjack\", using very sparse random projections, that is, linear combinations of a small subset of features. Lumberjack obtains statistically significantly improved accuracy over Random Forests, Gradient Boosted Trees, and other approaches on a standard benchmark suites for classification with varying dimension, sample size, and number of classes. To illustrate how, why, and when Lumberjack outperforms other methods, we conduct extensive simulated experiments, in vectors, images, and nonlinear manifolds. Lumberjack typically yields improved performance over existing decision trees ensembles, while mitigating computational efficiency and scalability, and maintaining interpretability. Lumberjack can easily be incorporated into other ensemble methods such as boosting to obtain potentially similar gains.","accessed":{"date-parts":[[2019,1,25]]},"author":[{"family":"Tomita","given":"Tyler M."},{"family":"Browne","given":"James"},{"family":"Shen","given":"Cencheng"},{"family":"Patsolic","given":"Jesse L."},{"family":"Yim","given":"Jason"},{"family":"Priebe","given":"Carey E."},{"family":"Burns","given":"Randal"},{"family":"Maggioni","given":"Mauro"},{"family":"Vogelstein","given":"Joshua T."}],"citation-key":"tomitaRandomProjectionForests2015","container-title":"arXiv:1506.03410 [cs, stat]","issued":{"date-parts":[[2015,6,10]]},"source":"arXiv.org","title":"Random Projection Forests","type":"article-journal","URL":"http://arxiv.org/abs/1506.03410"},
  {"id":"tooleyInfluenceNeighborhoodSES2019","abstract":"Higher socioeconomic status (SES) in childhood is associated with increased cognitive abilities, higher academic achievement, and decreased incidence of mental illness later in development. Accumulating evidence suggests that these effects may be due to changes in brain development induced by environmental factors. While prior work has mapped the associations between neighborhood SES and brain structure, little is known about the relationship between SES and intrinsic neural dynamics. Here, we capitalize upon a large community-based sample (Philadelphia Neurodevelopmental Cohort, ages 8-22 years, n=1012) to examine developmental changes in functional brain network topology as estimated from resting state functional magnetic resonance imaging data. We quantitatively characterize this topology using a local measure of network segregation known as the clustering coefficient, and find that it accounts for a greater degree of SES-associated variance than meso-scale segregation captured by modularity. While whole-brain clustering increased with age, high-SES youth displayed faster increases in clustering than low-SES youth, and this effect was most pronounced for regions in the limbic, somatomotor, and ventral attention systems. The effect of SES on developmental increases in clustering was strongest for connections of intermediate physical length, consistent with faster decreases in local connectivity in these regions in low-SES youth, and tracked changes in BOLD signal complexity in the form of regional homogeneity. Our findings suggest that neighborhood SES may fundamentally alter intrinsic patterns of inter-regional interactions in the human brain in a manner that is consistent with greater segregation of information processing in late childhood and adolescence.","accessed":{"date-parts":[[2019,6,11]]},"author":[{"family":"Tooley","given":"Ursula A."},{"family":"Mackey","given":"Allyson P."},{"family":"Ciric","given":"Rastko"},{"family":"Ruparel","given":"Kosha"},{"family":"Moore","given":"Tyler M."},{"family":"Gur","given":"Ruben C."},{"family":"Gur","given":"Raquel E."},{"family":"Satterthwaite","given":"Theodore D."},{"family":"Bassett","given":"Danielle S."}],"citation-key":"tooleyInfluenceNeighborhoodSES2019","container-title":"Cerebral Cortex","DOI":"10.1093/cercor/bhz066","ISSN":"1047-3211, 1460-2199","issued":{"date-parts":[[2019,4,11]]},"source":"arXiv.org","title":"Influence of Neighborhood SES on Functional Brain Network Development","type":"article-journal","URL":"http://arxiv.org/abs/1807.07687"},
  {"id":"vanessenWUMinnHumanConnectome2013","abstract":"The Human Connectome Project consortium led by Washington University, University of Minnesota, and Oxford University is undertaking a systematic effort to map macroscopic human brain circuits and their relationship to behavior in a large population of healthy adults. This overview article focuses on progress made during the first half of the 5-year project in refining the methods for data acquisition and analysis. Preliminary analyses based on a finalized set of acquisition and preprocessing protocols demonstrate the exceptionally high quality of the data from each modality. The first quarterly release of imaging and behavioral data via the ConnectomeDB database demonstrates the commitment to making HCP datasets freely accessible. Altogether, the progress to date provides grounds for optimism that the HCP datasets and associated methods and software will become increasingly valuable resources for characterizing human brain connectivity and function, their relationship to behavior, and their heritability and genetic underpinnings.","accessed":{"date-parts":[[2019,1,25]]},"author":[{"family":"Van Essen","given":"David C."},{"family":"Smith","given":"Stephen M."},{"family":"Barch","given":"Deanna M."},{"family":"Behrens","given":"Timothy E. J."},{"family":"Yacoub","given":"Essa"},{"family":"Ugurbil","given":"Kamil"}],"citation-key":"vanessenWUMinnHumanConnectome2013","collection-title":"Mapping the Connectome","container-title":"NeuroImage","container-title-short":"NeuroImage","DOI":"10.1016/j.neuroimage.2013.05.041","ISSN":"1053-8119","issued":{"date-parts":[[2013,10,15]]},"page":"62-79","source":"ScienceDirect","title":"The WU-Minn Human Connectome Project: An overview","title-short":"The WU-Minn Human Connectome Project","type":"article-journal","URL":"http://www.sciencedirect.com/science/article/pii/S1053811913005351","volume":"80"},
  {"id":"virtanenSciPyFundamentalAlgorithms2020","abstract":"SciPy is an open-source scientific computing library for the Python programming language. Since its initial release in 2001, SciPy has become a de facto standard for leveraging scientific algorithms in Python, with over 600 unique code contributors, thousands of dependent packages, over 100,000 dependent repositories and millions of downloads per year. In this work, we provide an overview of the capabilities and development practices of SciPy 1.0 and highlight some recent technical developments.","accessed":{"date-parts":[[2022,10,5]]},"author":[{"family":"Virtanen","given":"Pauli"},{"family":"Gommers","given":"Ralf"},{"family":"Oliphant","given":"Travis E."},{"family":"Haberland","given":"Matt"},{"family":"Reddy","given":"Tyler"},{"family":"Cournapeau","given":"David"},{"family":"Burovski","given":"Evgeni"},{"family":"Peterson","given":"Pearu"},{"family":"Weckesser","given":"Warren"},{"family":"Bright","given":"Jonathan"},{"family":"Walt","given":"Stéfan J.","non-dropping-particle":"van der"},{"family":"Brett","given":"Matthew"},{"family":"Wilson","given":"Joshua"},{"family":"Millman","given":"K. Jarrod"},{"family":"Mayorov","given":"Nikolay"},{"family":"Nelson","given":"Andrew R. J."},{"family":"Jones","given":"Eric"},{"family":"Kern","given":"Robert"},{"family":"Larson","given":"Eric"},{"family":"Carey","given":"C. J."},{"family":"Polat","given":"İlhan"},{"family":"Feng","given":"Yu"},{"family":"Moore","given":"Eric W."},{"family":"VanderPlas","given":"Jake"},{"family":"Laxalde","given":"Denis"},{"family":"Perktold","given":"Josef"},{"family":"Cimrman","given":"Robert"},{"family":"Henriksen","given":"Ian"},{"family":"Quintero","given":"E. A."},{"family":"Harris","given":"Charles R."},{"family":"Archibald","given":"Anne M."},{"family":"Ribeiro","given":"Antônio H."},{"family":"Pedregosa","given":"Fabian"},{"family":"Mulbregt","given":"Paul","non-dropping-particle":"van"}],"citation-key":"virtanenSciPyFundamentalAlgorithms2020","container-title":"Nature Methods","container-title-short":"Nat Methods","DOI":"10.1038/s41592-019-0686-2","ISSN":"1548-7105","issue":"3","issued":{"date-parts":[[2020,3]]},"language":"en","license":"2020 The Author(s)","number":"3","page":"261-272","publisher":"Nature Publishing Group","source":"www.nature.com","title":"SciPy 1.0: fundamental algorithms for scientific computing in Python","title-short":"SciPy 1.0","type":"article-journal","URL":"https://www.nature.com/articles/s41592-019-0686-2","volume":"17"},
  {"id":"vogelsteinConnectalCodingDiscovering2019","accessed":{"date-parts":[[2020,4,6]]},"author":[{"family":"Vogelstein","given":"Joshua T"},{"family":"Bridgeford","given":"Eric W"},{"family":"Pedigo","given":"Benjamin D"},{"family":"Chung","given":"Jaewon"},{"family":"Levin","given":"Keith"},{"family":"Mensh","given":"Brett"},{"family":"Priebe","given":"Carey E"}],"citation-key":"vogelsteinConnectalCodingDiscovering2019","container-title":"Current Opinion in Neurobiology","container-title-short":"Current Opinion in Neurobiology","DOI":"10.1016/j.conb.2019.04.005","ISSN":"09594388","issued":{"date-parts":[[2019,4]]},"language":"en","page":"199-212","source":"DOI.org (Crossref)","title":"Connectal coding: discovering the structures linking cognitive phenotypes to individual histories","title-short":"Connectal coding","type":"article-journal","URL":"https://linkinghub.elsevier.com/retrieve/pii/S0959438818301430","volume":"55"},
  {"id":"vogelsteinDiscoveringDecipheringRelationships2016","abstract":"Understanding the relationships between different properties of data, such as whether a connectome or genome has information about disease status, is becoming increasingly important in modern biological datasets. While existing approaches can test whether two properties are related, they often require unfeasibly large sample sizes in real data scenarios, and do not provide any insight into how or why the procedure reached its decision. Our approach, \"Multiscale Graph Correlation\" (MGC), is a dependence test that juxtaposes previously disparate data science techniques, including k-nearest neighbors, kernel methods (such as support vector machines), and multiscale analysis (such as wavelets). Other methods typically require double or triple the number samples to achieve the same statistical power as MGC in a benchmark suite including high-dimensional and nonlinear relationships - spanning polynomial (linear, quadratic, cubic), trigonometric (sinusoidal, circular, ellipsoidal, spiral), geometric (square, diamond, W-shape), and other functions, with dimensionality ranging from 1 to 1000. Moreover, MGC uniquely provides a simple and elegant characterization of the potentially complex latent geometry underlying the relationship, providing insight while maintaining computational efficiency. In several real data applications, including brain imaging and cancer genetics, MGC is the only method that can both detect the presence of a dependency and provide specific guidance for the next experiment and/or analysis to conduct.","accessed":{"date-parts":[[2019,2,11]]},"author":[{"family":"Vogelstein","given":"Joshua T."},{"family":"Bridgeford","given":"Eric"},{"family":"Wang","given":"Qing"},{"family":"Priebe","given":"Carey E."},{"family":"Maggioni","given":"Mauro"},{"family":"Shen","given":"Cencheng"}],"citation-key":"vogelsteinDiscoveringDecipheringRelationships2016","container-title":"arXiv:1609.05148 [stat]","issued":{"date-parts":[[2016,9,16]]},"source":"arXiv.org","title":"Discovering and Deciphering Relationships Across Disparate Data Modalities","type":"article-journal","URL":"http://arxiv.org/abs/1609.05148"},
  {"id":"vogelsteinGraphClassificationUsing2012","abstract":"This manuscript considers the following \"graph classification\" question: given a collection of graphs and associated classes, how can one predict the class of a newly observed graph? To address this question we propose a statistical model for graph/class pairs. This model naturally leads to a set of estimators to identify the class-conditional signal, or \"signal-subgraph,\" defined as the collection of edges that are probabilistically different between the classes. The estimators admit classifiers which are asymptotically optimal and efficient, but differ by their assumption about the \"coherency\" of the signal-subgraph (coherency is the extent to which the signal-edges \"stick together\" around a common subset of vertices). Via simulation, the best estimator is shown to be not just a function of the coherency of the model, but also the number of training samples. These estimators are employed to address a contemporary neuroscience question: can we classify \"connectomes\" (brain-graphs) according to sex? The answer is yes, and significantly better than all benchmark algorithms considered. Synthetic data analysis demonstrates that even when the model is correct, given the relatively small number of training samples, the estimated signal-subgraph should be taken with a grain of salt. We conclude by discussing several possible extensions.","accessed":{"date-parts":[[2020,4,3]]},"author":[{"family":"Vogelstein","given":"Joshua T."},{"family":"Gray","given":"William R."},{"family":"Vogelstein","given":"R. Jacob"},{"family":"Priebe","given":"Carey E."}],"citation-key":"vogelsteinGraphClassificationUsing2012","container-title":"arXiv:1108.1427 [stat]","issued":{"date-parts":[[2012,7,11]]},"source":"arXiv.org","title":"Graph Classification using Signal-Subgraphs: Applications in Statistical Connectomics","title-short":"Graph Classification using Signal-Subgraphs","type":"article-journal","URL":"http://arxiv.org/abs/1108.1427"},
  {"id":"vonluxburgTutorialSpectralClustering2007","abstract":"In recent years, spectral clustering has become one of the most popular modern clustering algorithms. It is simple to implement, can be solved efficiently by standard linear algebra software, and very often outperforms traditional clustering algorithms such as the k-means algorithm. On the first glance spectral clustering appears slightly mysterious, and it is not obvious to see why it works at all and what it really does. The goal of this tutorial is to give some intuition on those questions. We describe different graph Laplacians and their basic properties, present the most common spectral clustering algorithms, and derive those algorithms from scratch by several different approaches. Advantages and disadvantages of the different spectral clustering algorithms are discussed.","accessed":{"date-parts":[[2019,3,8]]},"author":[{"family":"Luxburg","given":"Ulrike","non-dropping-particle":"von"}],"citation-key":"vonluxburgTutorialSpectralClustering2007","container-title":"arXiv:0711.0189 [cs]","issued":{"date-parts":[[2007,11,1]]},"source":"arXiv.org","title":"A Tutorial on Spectral Clustering","type":"article-journal","URL":"http://arxiv.org/abs/0711.0189"},
  {"id":"walkerInceptionVisualCortex2018","abstract":"<p>Much of our knowledge about sensory processing in the brain is based on quasi-linear models and the stimuli that optimally drive them. However, sensory information processing is nonlinear, even in primary sensory areas, and optimizing sensory input is difficult due to the high-dimensional input space. We developed inception loops, a closed-loop experimental paradigm that combines in vivo recordings with in silico nonlinear response modeling to identify the Most Exciting Images (MEIs) for neurons in mouse V1. When presented back to the brain, MEIs indeed drove their target cells significantly better than the best stimuli identified by linear models. The MEIs exhibited complex spatial features that deviated from the textbook ideal of V1 as a bank of Gabor filters. Inception loops represent a widely applicable new approach to dissect the neural mechanisms of sensation.</p>","accessed":{"date-parts":[[2019,1,31]]},"author":[{"family":"Walker","given":"Edgar Y."},{"family":"Sinz","given":"Fabian H."},{"family":"Froudarakis","given":"Emmanouil"},{"family":"Fahey","given":"Paul G."},{"family":"Muhammad","given":"Taliah"},{"family":"Ecker","given":"Alexander S."},{"family":"Cobos","given":"Erick"},{"family":"Reimer","given":"Jacob"},{"family":"Pitkow","given":"Xaq"},{"family":"Tolias","given":"Andreas S."}],"citation-key":"walkerInceptionVisualCortex2018","container-title":"bioRxiv","DOI":"10.1101/506956","issued":{"date-parts":[[2018,12,28]]},"language":"en","license":"© 2018, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/","page":"506956","source":"www.biorxiv.org","title":"Inception in visual cortex: in vivo-silico loops reveal most exciting images","title-short":"Inception in visual cortex","type":"article-journal","URL":"https://www.biorxiv.org/content/10.1101/506956v1"},
  {"id":"wangNodeSpecificHeritabilityMouse2019","abstract":"MRI provides an opportunity to link neuroanatomic phenotypes to genetic expression. Genome-wide associative studies in the ENIGMA consortium and the UK Biobank have demonstrated significant links between brain structure and specific genes. Similar studies in rodents are challenging because of the scale. We report whole brain diffusion connectomes of four strains of mice (C57BL/6J, DBA/2J, CAST/EiJ, and BTBR) at spatial resolution 20,000 times higher than the human connectome. We derived volumes and scalar diffusion metrics for 322 regions of the brain. Volume was the most heritable trait followed by FA, RD, and AD. These traits were heritable in > 60% of the regions when comparing all four strains. Many were also highly heritable when the BTBR was not included. Using a unique statistical approach to limit false discovery allowed us to identify a number of specific brain nodes in which connectivity was highly heritable.","accessed":{"date-parts":[[2019,8,12]]},"author":[{"family":"Wang","given":"Nian"},{"family":"Anderson","given":"Robert J"},{"family":"Ashbrook","given":"David G"},{"family":"Gopalakrishnan","given":"Vivek"},{"family":"Park","given":"Youngser"},{"family":"Priebe","given":"Carey E"},{"family":"Qi","given":"Yi"},{"family":"Vogelstein","given":"Joshua T"},{"family":"Williams","given":"Robert W"},{"family":"Johnson","given":"G Allan"}],"citation-key":"wangNodeSpecificHeritabilityMouse2019","container-title":"bioRxiv","DOI":"10.1101/701755","issued":{"date-parts":[[2019,7,16]]},"language":"en","source":"DataCite","title":"Node-Specific Heritability in the Mouse Connectome","type":"article-journal","URL":"http://biorxiv.org/lookup/doi/10.1101/701755"},
  {"id":"wangSignalSubgraphEstimation2018","abstract":"Graph classification and regression have wide applications in a variety of domains. A graph is a complex and high-dimensional object, which poses great challenges to traditional machine learning algorithms. Accurately and efficiently locating a small signal subgraph dependent on the label of interest can dramatically improve the performance of subsequent statistical inference. Moreover, estimating a signal subgraph can aid humans with interpreting these results. We present a vertex screening method to identify the signal subgraph when given multiple graphs and associated labels. The method utilizes distance-based correlation to screen the vertices, and allows the subsequent classification and regression to be performed on a small induced subgraph. We demonstrate that this method is consistent in recovering signal vertices and leads to better classification performance via theory and numerical experiments. We apply the vertex screening algorithm on human and murine graphs derived from functional and structural magnetic resonance images to analyze the site effects and sex differences.","accessed":{"date-parts":[[2019,1,30]]},"author":[{"family":"Wang","given":"Shangsi"},{"family":"Shen","given":"Cencheng"},{"family":"Badea","given":"Alexandra"},{"family":"Priebe","given":"Carey E."},{"family":"Vogelstein","given":"Joshua T."}],"citation-key":"wangSignalSubgraphEstimation2018","container-title":"arXiv:1801.07683 [stat]","issued":{"date-parts":[[2018,1,23]]},"source":"arXiv.org","title":"Signal Subgraph Estimation Via Vertex Screening","type":"article-journal","URL":"http://arxiv.org/abs/1801.07683"},
  {"id":"wangStatisticalTestsFunctional2018","abstract":"Fingerprinting of functional connectomes is an increasingly standard measure of reproducibility in functional magnetic resonance imaging connectomics. In such studies, one attempts to match a subject’s ﬁrst session image with their second, in a blinded fashion, in a group of subjects measured twice. The number or percentage of correct matches is usually reported as a statistic. In this manuscript, we investigate the statistical tests of matching based on exchangeability assumption in the ﬁngerprinting analysis. We show that a nearly universal Poisson(1) approximation applies for different matching schemes. We theoretically investigate the permutation tests and explore the issue that the test is overly sensitive to uninteresting directions in the alternative hypothesis, such as clustering due to familial status or demographics. We perform a numerical study on two functional magnetic resonance imaging (fMRI) resting state datasets, the Human Connectome Project (HCP) and the Baltimore Longitudinal Study of Aging (BLSA). These datasets are instructive, as the HCP includes techinical replications of long scans and includes monozygotic and dyzogotic twins as well as non-twin siblings. In contrast, the BLSA study incorporates more typical length resting state scans in a longitudinal study. Finally, a study of single regional connections is performed on the HCP data.","accessed":{"date-parts":[[2020,4,13]]},"author":[{"family":"Wang","given":"Zeyi"},{"family":"Sair","given":"Haris"},{"family":"Crainiceanu","given":"Ciprian"},{"family":"Lindquist","given":"Martin"},{"family":"Landman","given":"Bennett A."},{"family":"Resnick","given":"Susan"},{"family":"Vogelstein","given":"Joshua T."},{"family":"Caffo","given":"Brian"}],"citation-key":"wangStatisticalTestsFunctional2018","DOI":"10.1101/443556","genre":"preprint","issued":{"date-parts":[[2018,10,15]]},"language":"en","publisher":"Neuroscience","source":"DOI.org (Crossref)","title":"On statistical tests of functional connectome fingerprinting","type":"report","URL":"http://biorxiv.org/lookup/doi/10.1101/443556"},
  {"id":"wangStochasticBlockmodelsDirected1987","abstract":"Holland and Leinhardt (1981) proposed the p 1 model for the analysis of binary directed graph data in network studies. Such a model provides information about the “attractiveness” and “expansiveness” of the individual nodes in the network, as well as the tendency of a pair of nodes to reciprocate relational ties. When the nodes are a priori partitioned into subgroups based on attributes such as race and sex, the density of ties from one subgroup to another can differ considerably from that relating another pair of subgroups, thus creating a situation called blocking in social networks. The p 1 model completely ignores this extra piece of information and is, therefore, unable to explain the block structure. Blockmodels that are simple extensions of the p 1 model are proposed specifically for such data. An iterative scaling algorithm is presented for fitting the model parameters by maximum likelihood. The methodology is illustrated in detail on two empirical examples.","accessed":{"date-parts":[[2020,2,13]]},"author":[{"family":"Wang","given":"Yuchung J."},{"family":"Wong","given":"George Y."}],"citation-key":"wangStochasticBlockmodelsDirected1987","container-title":"Journal of the American Statistical Association","container-title-short":"Journal of the American Statistical Association","DOI":"10.1080/01621459.1987.10478385","ISSN":"0162-1459","issue":"397","issued":{"date-parts":[[1987,3,1]]},"page":"8-19","source":"amstat.tandfonline.com (Atypon)","title":"Stochastic Blockmodels for Directed Graphs","type":"article-journal","URL":"https://amstat.tandfonline.com/doi/abs/10.1080/01621459.1987.10478385","volume":"82"},
  {"id":"waskomSeabornStatisticalData2021","author":[{"family":"Waskom","given":"Michael L."}],"citation-key":"waskomSeabornStatisticalData2021","container-title":"Journal of Open Source Software","DOI":"10.21105/joss.03021","issue":"60","issued":{"date-parts":[[2021]]},"page":"3021","publisher":"The Open Journal","title":"seaborn: statistical data visualization","type":"article-journal","URL":"https://doi.org/10.21105/joss.03021","volume":"6"},
  {"id":"xiaLinkedDimensionsPsychopathology2018","abstract":"Co-morbidity and symptom overlap make it difficult to associate psychiatric disorders with unique neural signatures. Here, the authors use a data-driven approach to show that the symptom dimensions of mood, psychosis, fear and externalizing behavior exhibit unique patterns of functional dysconnectivity.","accessed":{"date-parts":[[2019,2,8]]},"author":[{"family":"Xia","given":"Cedric Huchuan"},{"family":"Ma","given":"Zongming"},{"family":"Ciric","given":"Rastko"},{"family":"Gu","given":"Shi"},{"family":"Betzel","given":"Richard F."},{"family":"Kaczkurkin","given":"Antonia N."},{"family":"Calkins","given":"Monica E."},{"family":"Cook","given":"Philip A."},{"family":"Garza","given":"Angel García","dropping-particle":"de la"},{"family":"Vandekar","given":"Simon N."},{"family":"Cui","given":"Zaixu"},{"family":"Moore","given":"Tyler M."},{"family":"Roalf","given":"David R."},{"family":"Ruparel","given":"Kosha"},{"family":"Wolf","given":"Daniel H."},{"family":"Davatzikos","given":"Christos"},{"family":"Gur","given":"Ruben C."},{"family":"Gur","given":"Raquel E."},{"family":"Shinohara","given":"Russell T."},{"family":"Bassett","given":"Danielle S."},{"family":"Satterthwaite","given":"Theodore D."}],"citation-key":"xiaLinkedDimensionsPsychopathology2018","container-title":"Nature Communications","DOI":"10.1038/s41467-018-05317-y","ISSN":"2041-1723","issue":"1","issued":{"date-parts":[[2018,8,1]]},"language":"En","license":"2018 The Author(s)","page":"3003","source":"www.nature.com","title":"Linked dimensions of psychopathology and connectivity in functional brain networks","type":"article-journal","URL":"https://www.nature.com/articles/s41467-018-05317-y","volume":"9"},
  {"id":"xieMultiModalDistanceMetric","abstract":"Multi-modal data is dramatically increasing with the fast growth of social media. Learning a good distance measure for data with multiple modalities is of vital importance for many applications, including retrieval, clustering, classiﬁcation and recommendation. In this paper, we propose an effective and scalable multi-modal distance metric learning framework. Based on the multi-wing harmonium model, our method provides a principled way to embed data of arbitrary modalities into a single latent space, of which an optimal distance metric can be learned under proper supervision, i.e., by minimizing the distance between similar pairs whereas maximizing the distance between dissimilar pairs. The parameters are learned by jointly optimizing the data likelihood under the latent space model and the loss induced by distance supervision, thereby our method seeks a balance between explaining the data and providing an effective distance metric, which naturally avoids overﬁtting. We apply our general framework to text/image data and present empirical results on retrieval and classiﬁcation to demonstrate the effectiveness and scalability.","author":[{"family":"Xie","given":"Pengtao"},{"family":"Xing","given":"Eric P"}],"citation-key":"xieMultiModalDistanceMetric","language":"en","page":"7","source":"Zotero","title":"Multi-Modal Distance Metric Learning","type":"article-journal"},
  {"id":"xieUncorrelationEvennessNew2017","abstract":"Latent space models (LSMs) provide a principled and effective way to extract hidden patterns from observed data. To cope with two challenges in LSMs: (1) how to capture infrequent patterns when pat...","accessed":{"date-parts":[[2019,2,15]]},"author":[{"family":"Xie","given":"Pengtao"},{"family":"Singh","given":"Aarti"},{"family":"Xing","given":"Eric P."}],"citation-key":"xieUncorrelationEvennessNew2017","container-title":"International Conference on Machine Learning","event-title":"International Conference on Machine Learning","issued":{"date-parts":[[2017,7,17]]},"language":"en","page":"3811-3820","source":"proceedings.mlr.press","title":"Uncorrelation and Evenness: a New Diversity-Promoting Regularizer","title-short":"Uncorrelation and Evenness","type":"paper-conference","URL":"http://proceedings.mlr.press/v70/xie17b.html"},
  {"id":"xinyiCapsuleGraphNeural2018","abstract":"The high-quality node embeddings learned from the Graph Neural Networks (GNNs) have been applied to a wide range of node-based applications and some of them have achieved state-of-the-art (SOTA)...","accessed":{"date-parts":[[2019,3,27]]},"author":[{"family":"Xinyi","given":"Zhang"},{"family":"Chen","given":"Lihui"}],"citation-key":"xinyiCapsuleGraphNeural2018","issued":{"date-parts":[[2018,9,27]]},"source":"openreview.net","title":"Capsule Graph Neural Network","type":"article-journal","URL":"https://openreview.net/forum?id=Byl8BnRcYm"},
  {"id":"xuGraphWaveletNeural2018","abstract":"We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcomings of previous spectral graph CNN...","accessed":{"date-parts":[[2019,3,18]]},"author":[{"family":"Xu","given":"Bingbing"},{"family":"Shen","given":"Huawei"},{"family":"Cao","given":"Qi"},{"family":"Qiu","given":"Yunqi"},{"family":"Cheng","given":"Xueqi"}],"citation-key":"xuGraphWaveletNeural2018","issued":{"date-parts":[[2018,9,27]]},"source":"openreview.net","title":"Graph Wavelet Neural Network","type":"article-journal","URL":"https://openreview.net/forum?id=H1ewdiR5tQ"},
  {"id":"yamashitaHarmonizationRestingstateFunctional2019","abstract":"When collecting large amounts of neuroimaging data associated with psychiatric disorders, images must be acquired from multiple sites because of the limited capacity of a single site. However, site differences represent a barrier when acquiring multisite neuroimaging data. We utilized a traveling-subject dataset in conjunction with a multisite, multidisorder dataset to demonstrate that site differences are composed of biological sampling bias and engineering measurement bias. The effects on resting-state functional MRI connectivity based on pairwise correlations because of both bias types were greater than or equal to psychiatric disorder differences. Furthermore, our findings indicated that each site can sample only from a subpopulation of participants. This result suggests that it is essential to collect large amounts of neuroimaging data from as many sites as possible to appropriately estimate the distribution of the grand population. Finally, we developed a novel harmonization method that removed only the measurement bias by using a traveling-subject dataset and achieved the reduction of the measurement bias by 29% and improvement of the signal-to-noise ratios by 40%. Our results provide fundamental knowledge regarding site effects, which is important for future research using multisite, multidisorder resting-state functional MRI data.","accessed":{"date-parts":[[2022,9,23]]},"author":[{"family":"Yamashita","given":"Ayumu"},{"family":"Yahata","given":"Noriaki"},{"family":"Itahashi","given":"Takashi"},{"family":"Lisi","given":"Giuseppe"},{"family":"Yamada","given":"Takashi"},{"family":"Ichikawa","given":"Naho"},{"family":"Takamura","given":"Masahiro"},{"family":"Yoshihara","given":"Yujiro"},{"family":"Kunimatsu","given":"Akira"},{"family":"Okada","given":"Naohiro"},{"family":"Yamagata","given":"Hirotaka"},{"family":"Matsuo","given":"Koji"},{"family":"Hashimoto","given":"Ryuichiro"},{"family":"Okada","given":"Go"},{"family":"Sakai","given":"Yuki"},{"family":"Morimoto","given":"Jun"},{"family":"Narumoto","given":"Jin"},{"family":"Shimada","given":"Yasuhiro"},{"family":"Kasai","given":"Kiyoto"},{"family":"Kato","given":"Nobumasa"},{"family":"Takahashi","given":"Hidehiko"},{"family":"Okamoto","given":"Yasumasa"},{"family":"Tanaka","given":"Saori C."},{"family":"Kawato","given":"Mitsuo"},{"family":"Yamashita","given":"Okito"},{"family":"Imamizu","given":"Hiroshi"}],"citation-key":"yamashitaHarmonizationRestingstateFunctional2019","container-title":"PLOS Biology","container-title-short":"PLOS Biology","DOI":"10.1371/journal.pbio.3000042","ISSN":"1545-7885","issue":"4","issued":{"date-parts":[[2019,4,18]]},"language":"en","page":"e3000042","publisher":"Public Library of Science","source":"PLoS Journals","title":"Harmonization of resting-state functional MRI data across multiple imaging sites via the separation of site differences into sampling bias and measurement bias","type":"article-journal","URL":"https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3000042","volume":"17"},
  {"id":"youngRandomDotProduct2007","abstract":"Inspired by the recent interest in combining geometry with random graph models, we explore in this paper two generalizations of the random dot product graph model proposed by Kraetzl, Nickel and Scheinerman, and Tucker [1,2]. In particular we consider the properties of clustering, diameter and degree distribution with respect to these models. Additionally we explore the conductance of these models and show that in a geometric sense, the conductance is constant.","author":[{"family":"Young","given":"Stephen J."},{"family":"Scheinerman","given":"Edward R."}],"citation-key":"youngRandomDotProduct2007","collection-title":"Lecture Notes in Computer Science","container-title":"Algorithms and Models for the Web-Graph","editor":[{"family":"Bonato","given":"Anthony"},{"family":"Chung","given":"Fan R. K."}],"ISBN":"978-3-540-77004-6","issued":{"date-parts":[[2007]]},"language":"en","page":"138-149","publisher":"Springer Berlin Heidelberg","source":"Springer Link","title":"Random Dot Product Graph Models for Social Networks","type":"paper-conference"},
  {"id":"yuUsefulVariantDavis2014","abstract":"The Davis--Kahan theorem is used in the analysis of many statistical procedures to bound the distance between subspaces spanned by population eigenvectors and their sample versions. It relies on an eigenvalue separation condition between certain relevant population and sample eigenvalues. We present a variant of this result that depends only on a population eigenvalue separation condition, making it more natural and convenient for direct application in statistical contexts, and improving the bounds in some cases. We also provide an extension to situations where the matrices under study may be asymmetric or even non-square, and where interest is in the distance between subspaces spanned by corresponding singular vectors.","accessed":{"date-parts":[[2019,2,6]]},"author":[{"family":"Yu","given":"Yi"},{"family":"Wang","given":"Tengyao"},{"family":"Samworth","given":"Richard J."}],"citation-key":"yuUsefulVariantDavis2014","container-title":"arXiv:1405.0680 [math, stat]","issued":{"date-parts":[[2014,5,4]]},"source":"arXiv.org","title":"A useful variant of the Davis--Kahan theorem for statisticians","type":"article-journal","URL":"http://arxiv.org/abs/1405.0680"},
  {"id":"zhangMappingPopulationbasedStructural2018","abstract":"Advances in understanding the structural connectomes of human brain require improved approaches for the construction, comparison and integration of high-dimensional whole-brain tractography data from a large number of individuals. This article develops a population-based structural connectome (PSC) mapping framework to address these challenges. PSC simultaneously characterizes a large number of white matter bundles within and across different subjects by registering different subjects’ brains based on coarse cortical parcellations, compressing the bundles of each connection, and extracting novel connection weights. A robust tractography algorithm and streamline post-processing techniques, including dilation of gray matter regions, streamline cutting, and outlier streamline removal are applied to improve the robustness of the extracted structural connectomes. The developed PSC framework can be used to reproducibly extract binary networks, weighted networks and streamline-based brain connectomes. We apply the PSC to Human Connectome Project data to illustrate its application in characterizing normal variations and heritability of structural connectomes in healthy subjects.","accessed":{"date-parts":[[2019,7,24]]},"author":[{"family":"Zhang","given":"Zhengwu"},{"family":"Descoteaux","given":"Maxime"},{"family":"Zhang","given":"Jingwen"},{"family":"Girard","given":"Gabriel"},{"family":"Chamberland","given":"Maxime"},{"family":"Dunson","given":"David"},{"family":"Srivastava","given":"Anuj"},{"family":"Zhu","given":"Hongtu"}],"citation-key":"zhangMappingPopulationbasedStructural2018","container-title":"NeuroImage","container-title-short":"NeuroImage","DOI":"10.1016/j.neuroimage.2017.12.064","ISSN":"1053-8119","issued":{"date-parts":[[2018,5,15]]},"page":"130-145","source":"ScienceDirect","title":"Mapping population-based structural connectomes","type":"article-journal","URL":"http://www.sciencedirect.com/science/article/pii/S1053811917310881","volume":"172"},
  {"id":"zhuAutomaticDimensionalitySelection2006","abstract":"Most dimension reduction techniques produce ordered coordinates so that only the first few coordinates need be considered in subsequent analyses. The choice of how many coordinates to use is often made with a visual heuristic, i.e., by making a scree plot and looking for a “big gap” or an “elbow.” In this article, we present a simple and automatic procedure to accomplish this goal by maximizing a simple profile likelihood function. We give a wide variety of both simulated and real examples.","accessed":{"date-parts":[[2020,2,2]]},"author":[{"family":"Zhu","given":"Mu"},{"family":"Ghodsi","given":"Ali"}],"citation-key":"zhuAutomaticDimensionalitySelection2006","container-title":"Computational Statistics & Data Analysis","container-title-short":"Computational Statistics & Data Analysis","DOI":"10.1016/j.csda.2005.09.010","ISSN":"0167-9473","issue":"2","issued":{"date-parts":[[2006,11,15]]},"language":"en","page":"918-930","source":"ScienceDirect","title":"Automatic dimensionality selection from the scree plot via the use of profile likelihood","type":"article-journal","URL":"http://www.sciencedirect.com/science/article/pii/S0167947305002343","volume":"51"},
  {"id":"zhuClassWeightsRandom2018","abstract":"The classification in class imbalanced data has drawn significant interest in medical application. Most existing methods are prone to categorize the samples into the majority class, resulting in bias, in particular the insufficient identification of minority class. A kind of novel approach, class weights random forest is introduced to address the problem, by assigning individual weights for each class instead of a single weight. The validation test on UCI data sets demonstrates that for imbalanced medical data, the proposed method enhanced the overall performance of the classifier while producing high accuracy in identifying both majority and minority class.","author":[{"family":"Zhu","given":"M."},{"family":"Xia","given":"J."},{"family":"Jin","given":"X."},{"family":"Yan","given":"M."},{"family":"Cai","given":"G."},{"family":"Yan","given":"J."},{"family":"Ning","given":"G."}],"citation-key":"zhuClassWeightsRandom2018","container-title":"IEEE Access","DOI":"10.1109/ACCESS.2018.2789428","ISSN":"2169-3536","issued":{"date-parts":[[2018]]},"page":"4641-4652","source":"IEEE Xplore","title":"Class Weights Random Forest Algorithm for Processing Class Imbalanced Medical Data","type":"article-journal","volume":"6"},
  {"id":"zitnikModelingPolypharmacySide2018","abstract":"AbstractMotivation.  The use of drug combinations, termed polypharmacy, is common to treat patients with complex diseases or co-existing conditions. However, a","accessed":{"date-parts":[[2019,3,25]]},"author":[{"family":"Zitnik","given":"Marinka"},{"family":"Agrawal","given":"Monica"},{"family":"Leskovec","given":"Jure"}],"citation-key":"zitnikModelingPolypharmacySide2018","container-title":"Bioinformatics","container-title-short":"Bioinformatics","DOI":"10.1093/bioinformatics/bty294","ISSN":"1367-4803","issue":"13","issued":{"date-parts":[[2018,7,1]]},"language":"en","page":"i457-i466","source":"academic.oup.com","title":"Modeling polypharmacy side effects with graph convolutional networks","type":"article-journal","URL":"https://academic.oup.com/bioinformatics/article/34/13/i457/5045770","volume":"34"}
]
